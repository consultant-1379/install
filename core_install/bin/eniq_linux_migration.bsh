#!/bin/bash
# ********************************************************************
# Ericsson Radio Systems AB                                     SCRIPT
# ********************************************************************
#
# (c) Ericsson Radio Systems AB 2021 - All rights reserved.
#
# The copyright to the computer program(s) herein is the property
# of Ericsson Radio Systems AB, Sweden. The programs may be used
# and/or copied only with the written permission from Ericsson Radio
# Systems AB or in accordance with the terms and conditions stipulated
# in the agreement/contract under which the program(s) have been
# supplied.
#
# ********************************************************************
#
# Name    : eniq_linux_migration.bsh
# Date    : 08/09/2021
# Revision: \main\59
#
# Purpose : 1. This script will support migration from Solaris 11 OS to
#           RHEL
#           2. This script will support Pre-recovery on RHEL
# Usage   : eniq_linux_migration.bsh -a <action> [-l <logfile>]
#
# ********************************************************************
#
#   Command Section
#
# ********************************************************************
AWK=/usr/bin/awk
BASENAME=/usr/bin/basename
BASH=/usr/bin/bash
BC=/usr/bin/bc
CAT=/usr/bin/cat
CHMOD=/usr/bin/chmod                
CUT=/usr/bin/cut
CP=/usr/bin/cp
CPIO=/usr/bin/cpio
DATE=/usr/bin/date
DF=/usr/bin/df
DIFF=/usr/bin/diff
DIRNAME=/usr/bin/dirname
DRACUT=/usr/sbin/dracut
DU=/usr/bin/du
ECHO='/usr/bin/echo -e'
EGREP=/usr/bin/egrep
EXPECT=/usr/bin/expect
EXPR=/usr/bin/expr
FIND=/usr/bin/find
GETENT=/usr/bin/getent
GREP=/usr/bin/grep
HEAD=/usr/bin/head
HOST=/usr/sbin/host
ID=/usr/bin/id
KILL=/usr/bin/kill
LVREMOVE=/usr/sbin/lvremove
LVS=/usr/sbin/lvs
LN=/usr/bin/ln
LS=/usr/bin/ls
LSOF=/usr/sbin/lsof
MYHOSTNAME=/usr/bin/hostname
MKDIR=/usr/bin/mkdir
MOUNT=/usr/bin/mount
OPENSSL=/usr/bin/openssl
PARTED=/usr/sbin/parted
PASTE=/usr/bin/paste
PERL=/usr/bin/perl
PING=/usr/sbin/ping
PRINTF=/usr/bin/printf
PYTHON=/usr/bin/python
PWD=/usr/bin/pwd
PS=/usr/bin/ps
RAW=/usr/bin/raw
REBOOT=/usr/sbin/reboot
RM=/usr/bin/rm
SED=/usr/bin/sed
SERVICES=/usr/bin/services
SORT=/usr/bin/sort
SLEEP=/usr/bin/sleep
SWAPOFF=/usr/sbin/swapoff
SYSTEMCTL=/usr/bin/systemctl
TAIL=/usr/bin/tail
TEE=/usr/bin/tee
TOUCH=/usr/bin/touch
TR=/usr/bin/tr
UDEVADM=/usr/sbin/udevadm
UNLINK=/usr/sbin/unlink
UNIQ=/usr/bin/uniq
VGCHANGE=/usr/sbin/vgchange
VGDISPLAY=/usr/sbin/vgdisplay
VGEXPORT=/usr/sbin/vgexport
VGIMPORT=/usr/sbin/vgimport
VGS=/usr/sbin/vgs
YES=/usr/bin/yes

# ********************************************************************
#
#       Configuration Section
#
# ********************************************************************

# Default user
DEFAULT_USER=root

if [ ! "${BACKUP}" ]; then
    # Cmd to exec a shell and drop user to it in case of an error
    EXEC_SHELL_CMD="exec /bin/bash -o emacs"
fi

# Name of the ini Files
IPMP_INI=ipmp.ini
STORAGE_INI=storage.ini
SYM_LINKS_INI=sym_links.ini
COORD_SYM_INI=coordinator_sym_links.ini
SUNOS_INI=SunOS.ini
BLK_STOR_INI=block_storage.ini
BACKUP_DATA_INI=backup_migration_data.ini
ENIQ_INI=niq.ini

# Version DB Properties file
VERSIONDB_PROPERTIES=versiondb.properties

# Service SMFs
HOSTSYNC_SMF_ID="hostsync.service"
DDC_SMF_ID="ddc.service"
SENTINEL_SMF_ID="licensing-sentinel.service"

# NAS SMF
NAS_MILESTONE_SMF_ID="NAS-online.service"
NASd_SMF_ID="NASd.service"

# Cron SMF
CRON_SMF_ID="svc:/system/cron:default"

# pool Information
ROOT_POOL="vg_root"

# Set REPLACEMENT default value
REPLACEMENT="NO"

# Setting no confirmation from user
NO_CONFIRM="YES"

# String denoting the start of a reader reference name.
READER_STR=dwh_reader_
# ********************************************************************
#
#   Functions
#
# ********************************************************************
### Function: abort_script ###
#
#   This will be called if the script is aborted by an error
#   which is encountered during runtime
#
# Arguments:
#       $1 - Error message from part of program (Not always used)
# Return Values:
#       none
abort_script()
{
_err_time_=`$DATE '+%Y-%b-%d_%H.%M.%S'`

if [ "$1" ]; then
    _err_msg_="${_err_time_} - $1"
else
    _err_msg_="${_err_time_} - ERROR : Script aborted.......\n"
fi

if [ "${LOGFILE}" ]; then
    $ECHO "\nERROR : ${_err_msg_}\n" | $TEE -a ${LOGFILE}
else
    $ECHO "\nERROR : ${_err_msg_}\n"
fi

if [[ ${BACKUP} ]] && [[ ${USER_STAGE} == "get_migration_data" ]];then
    if [ -f "${MIGRATION_CONF}"_bkp ];then
        $MV "${MIGRATION_CONF}"_bkp "${MIGRATION_CONF}"
    fi
fi

$RM -rf ${TEM_DIR}
$RM -rf ${conn_str_dba_enc}
$RM -rf ${conn_str_db_enc}
$RM -rf ${conn_str_db_stop_ping_enc}
$RM -rf ${conn_str_db_ping_enc}

if [ "$2" ]; then
    if [ ! "${CONTINUE}" ]; then 
        ${2}
    fi
    exit 1
else
   exit 1
fi
}

### Function: allow_root_access ###
#
# Updates to allow root to telnet/ftp access
#
# Arguments:
#   none
# Return Values:
#   none
allow_root_access()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling allow_root_access stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s allow_root_access ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - allow_root_access"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: change_engine_scheduler_profile ###
#
#       Checking the engine status and changing it to NoLoads
#       and checks the execution slots
#
# Arguments:
#   none
# Return Values:
#   none
change_engine_scheduler_profile()
{
_scheduler_action_=${1}
_engine_action_=${2}

_scheduler_status_=`$SU - $SYSUSER -c 'scheduler status'|$GREP -i "running OK"|$AWK '{print $3" "$4}'`
_engine_status_=`$SU - $SYSUSER -c 'engine status'|$GREP "running OK"|$AWK '{print $3" "$4}'`

if [ -n "${_scheduler_action_}" ]; then
     if [ "${_scheduler_status_}" == "running OK" ]; then
          _command_="scheduler ${_scheduler_action_}"
          log_msg -l ${LOGFILE} -t -s "Putting scheduler to ${_scheduler_action_}"
          $SU - $SYSUSER -c "${_command_1_}" >> /dev/null 2>&1
          if [ $? -ne 0 ];then
               _err_msg_="Could not put scheduler ${_scheduler_action_}"
               abort_script "${_err_msg_}"
          else
              _scheduler_change_=1
          fi
     fi
fi

if [ -n "${_engine_action_}" ]; then
    if [ "${_engine_status_}" == "running OK" ]; then
          _engine_profile_=`$SU - $SYSUSER -c 'engine status' | $GREP "Current Profile:" | $AWK {'print $3'}`
          if [ "${_engine_profile_}" ]; then
                  log_msg -l ${LOGFILE} -t -s "Engine current profile is ${_engine_profile_}"
                  if [[ "${_engine_profile_}" == "Normal" || ${_engine_profile_change_} -eq 1 ]] || [[ "${_engine_profile_}" == "NoLoads" && "${ACTION_TYPE}" == "postmigration" ]] ; then
                       _command_="engine -e changeProfile ${_engine_action_}"
                       log_msg -l ${LOGFILE} -t -s "Changing engine profile to ${_engine_action_}"
                       $SU - $SYSUSER -c "${_command_}" >> /dev/null 2>&1
                       if [ $? -ne 0 ];then
                            _err_msg_="Could not change engine profile to ${_engine_action_}"
                            abort_script "${_err_msg_}"
                       else
                            if [ "${_engine_action_}" == "NoLoads" ]; then
                                 _engine_profile_change_=1
                            elif [ "${_engine_action_}" == "Normal" ]; then
                                 _engine_profile_change_=0
                            fi
                       fi

                       # Check that there are no Loader and Aggregation sets.
                       _timeout_=0
                       while true ;do
                           _command_="engine -e showSetsInExecutionSlots | $EGREP 'Count|Loader'"
                           $SU - $SYSUSER -c "${_command_}"  >> /dev/null 2>&1
                           if [ $? -eq 0 ];then
                               log_msg -t -s "Waiting for Execution Slots to get empty" -l ${LOGFILE}
                               $SLEEP 5
                               (( _timeout_ = _timeout_ + 5 ))
                               if [ ${_timeout_} -eq 120 ]; then
                                   break
                               else
                                   continue
                               fi
                           else
                               log_msg -t -s "Execution slots are empty of Loader and Aggregation sets" -l ${LOGFILE}
                               break
                           fi
                       done
                  fi
          else
                  _err_msg_="Could not get the current Engine profile"
                  abort_script "${_err_msg_}"
          fi
    fi
fi
}

### Function: check_absolute_path ###
#
# Determine absolute path to software
#
# Arguments:
#   none
# Return Values:
#   none
check_absolute_path()
{
_dir_=`$DIRNAME $0`
SCRIPTHOME=`cd $_dir_ 2>/dev/null && pwd || $ECHO $_dir_`
}

### Function: check_and_manage_smf ###
#
#   Check service status and manage
#
# Arguments:
#   $1 : Service name
#   $2 : Action
# Return Values:
#   none
check_and_manage_smf()
{
# Check argument count
if [ $# -ne 2 ];then
    _err_msg_="Incorrect number of argument passed to check_and_manage_smf."
    abort_script "${_err_msg_}"
fi

_svc_str_=$1
_svc_action_=$2

# Check status of SMF
_load_status_=`$SYSTEMCTL show -p LoadState ${_svc_str_} | $CUT -f2 -d=`
if [ "${_load_status_}" != "loaded" ];then
    _err_msg_="Could not find service ${_svc_str_}"
    abort_script "${_err_msg_}"
fi
_svc_status_=`$SYSTEMCTL show -p ActiveState ${_svc_str_} | $CUT -f2 -d=`

_svc_next_state_=""
case $_svc_action_ in
  enable) _svc_next_state_="active"
          _svc_next_action_="start"
     ;;
  disable) _svc_next_state_="inactive"
           _svc_next_action_="stop"
     ;;
  *) $ECHO "Invalid action"
    $RM -rf ${conn_str_dba_enc}
     $RM -rf ${conn_str_db_enc}
     $RM -rf ${conn_str_db_stop_ping_enc}
     $RM -rf ${conn_str_db_ping_enc}
     exit 1
     ;;
esac

if [ "${_svc_status_}" != "${_svc_next_state_}" ];then
    if [ "${_svc_status_}" == "failed" ];then
        $SYSTEMCTL reset-failed ${_svc_str_} >> /dev/null 2>&1
    fi
    $SYSTEMCTL ${_svc_action_} ${_svc_str_} >> /dev/null 2>&1
    if [ $? -ne 0 ];then
        _err_msg_="Could not $_svc_action_ $_svc_str_ service."
        abort_script "${_err_msg_}"
    fi
    $SYSTEMCTL ${_svc_next_action_} ${_svc_str_} >> /dev/null 2>&1
    if [ $? -ne 0 ];then
        _err_msg_="Could not $_svc_next_action_ $_svc_str_ service."
        abort_script "${_err_msg_}"
    fi
    
fi

# Wait for NAS milestone service if enabling NASd service 
if [ "${_svc_str_}" == "${NASd_SMF_ID}" -a "${_svc_action_}" == "enable" ];then
    _count_=0
    while [ 1 ];
    do
        _milestone_state_=`$SYSTEMCTL show -p ActiveState ${NAS_MILESTONE_SMF_ID} | $CUT -f2 -d=`
        if [ "${_milestone_state_}" == "active" ];then
            log_msg -q -s "${NAS_MILESTONE_SMF_ID} service is active." -l ${LOGFILE}
            break
        fi
        if [ $_count_ -eq 0 ]; then
            $ECHO "\nTrying to start NAS milestone service. It can take upto 2 to 5 minutes. Please wait...\n"
        fi
        $SLEEP 30
        let _count_=_count_+1
        if [ $_count_ -eq 5 ];then
            _err_msg_="NAS milestone ${NAS_MILESTONE_SMF_ID} service not online. Check ${ENIQ_LOG_DIR}/NASd/NASd.log"
            abort_script ${_err_msg_}
        fi
    done
fi
}

### Function: check_for_file ###
#
# To check whether file or directory exist or not and to test the basic file operations.
#
# Arguments:
#       $1 : File operations
#       $2 : File qualified path
# Return Values:
#         none
check_for_file()
{
if [ ! $1 $2 ]; then
    _err_msg_="$2 does not exist"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi
}

### Function: check_id ###
#
#   Check that the effective id of the user is correct
#   If not print error msg and exit.
#
# Arguments:
#       $1 : User ID name
# Return Values:
#       none
check_id()
{
_check_id_=`$ID | $AWK -F\( '{print $2}' | $AWK -F\) '{print $1}'`
if [ "$_check_id_" != "$1" ]; then
    _err_msg_="You must be $1 to execute this script."
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi
}

### Function: check_params ###
#
# Check Input Params
#
# Arguments:
#    none
# Return Values:
#    none
check_params()
{
# Check that we got the required action type
if [ ! "${ACTION_TYPE}" ]; then
    $ECHO "\nERROR: Required parameters not passed."
    usage_msg
    $RM -rf ${conn_str_dba_enc}
    $RM -rf ${conn_str_db_enc}
    $RM -rf ${conn_str_db_stop_ping_enc}
    $RM -rf ${conn_str_db_ping_enc}
    exit 1
fi

if [ "${ACTION_TYPE}" != "migration" -a "${ACTION_TYPE}" != "prerecovery" -a "${ACTION_TYPE}" != "cleanup" -a "${ACTION_TYPE}" != "post_migration"  ]; then
    $ECHO "\nERROR: Not a valid action type"
    usage_msg
    $RM -rf ${conn_str_dba_enc}
    $RM -rf ${conn_str_db_enc}
    $RM -rf ${conn_str_db_stop_ping_enc}
    $RM -rf ${conn_str_db_ping_enc}                                                    
    exit 1
fi

case $ACTION_TYPE in
  prerecovery) ACTIVITY="Pre-recovery for Linux OS Recovery"
     ;;
  migration) STOP_STAGE="cleanup_migration"
             ACTIVITY="procedure to migrate Linux OS"
             _base_sw_param_="MIG_BASE_SW_LOC"
             _om_sw_param_="MIG_OM_SW_LOC"
     ;;
  cleanup) ACTIVITY="procedure to clean temporary files/directories"
     ;;
  post_migration) ACTIVITY="procedure to configure the OSS and re-configure slots"
     ;;
 \?) $ECHO "Invalid action type"
     usage_msg
     $RM -rf ${conn_str_dba_enc}
     $RM -rf ${conn_str_db_enc}
     $RM -rf ${conn_str_db_stop_ping_enc}
     $RM -rf ${conn_str_db_ping_enc}
     exit 1
     ;;
esac

}


### Function: clear ###
#
# Clears the terminal screen
#
# Arguments:
#       none
# Return Values:
#       none
clear()
{
# Clearing the screen without removing scrollback buffer
$PRINTF '\33[H\33[2J'
}


### Function: cleanup_old_nas_content ###
#
# Start NASd & cleanup old NAS content
#
# Arguments:
#   none
# Return Values:
#   none
cleanup_old_nas_content()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

# Skip stage if not CO or Reader server
if [ "${CO_SERVER}" != "YES" ]; then
    insert_header_footer foot "Skipping ${ACTION_TYPE} stage for ${CURR_SERVER_TYPE} - ${NEXT_STAGE} " ${LOGFILE}
    set_next_stage `$EXPR ${ARRAY_ELEM}+1`
    return 0
fi

log_msg -s "\nCleaning up old NAS data specific to Solaris" -l ${LOGFILE}

# Getting list of directories and file which needs to be removed from backed up data
_old_nas_content_=`iniget OLD_NAS_CONTENT -f ${MIGRATION_TEMPL_DIR}/${BACKUP_DATA_INI}`
for _file_ in `$ECHO ${_old_nas_content_}`;do
    if [ -d ${_file_} ]; then
        $RM -rf ${_file_} >> /dev/null 2>&1
        if [ $? -ne 0 ]; then
            _err_msg_="Failed to remove the ${_file_} directory"
            abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
        fi
    elif [ -f ${_file_} ]; then 
        $RM -rf ${_file_} >> /dev/null 2>&1
        if [ $? -ne 0 ]; then
            _err_msg_="Failed to remove the ${_file_} file"
            abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
        fi
    else
        log_msg -s "\n${_file_} file or directory does not exists" -l ${LOGFILE}
    fi
done

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: cleanup_old_prechecks ###
#
# Clear the solaris related prechecks
#
# Arguments:
#       none
# Return Values:
#       none
cleanup_old_prechecks()
{
# Determine Rhel OS version
unset RHEL
OS_VERSION=`$UNAME`
if [ "${OS_VERSION}" == "Linux" ]; then
    RHEL=YES
fi
#Delete eniq_checks folder based on OS version
if [ "${RHEL}" ];then
    if [ -d ${ENIQ_CORE_INST_DIR}/eniq_checks_linux ]; then
        if [ -d ${ENIQ_CORE_INST_DIR}/eniq_checks ]; then
            $RM -rf ${ENIQ_CORE_INST_DIR}/eniq_checks
        fi
        $MV ${ENIQ_CORE_INST_DIR}/eniq_checks_linux ${ENIQ_CORE_INST_DIR}/eniq_checks
        if [ $? -ne 0 ]; then
            _err_msg_="Could not move ${ENIQ_CORE_INST_DIR}/eniq_checks_linux to ${ENIQ_CORE_INST_DIR}/eniq_checks.`$DATE '+%y%m%d'`"
            abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
        fi
        $ECHO "Linux eniq_checks copied." >> ${LOGFILE}
        $RM -rf ${ENIQ_CORE_INST_DIR}/eniq_checks_solaris
        $ECHO "Solaris eniq_checks Removed./n" >> ${LOGFILE}
    else
        $ECHO "Linux eniq_checks directory not found." >> ${LOGFILE}
        _err_msg_="Could not find ${ENIQ_CORE_INST_DIR}/eniq_checks_linux directory .`$DATE '+%y%m%d'`"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi
else
    if [ -d ${ENIQ_CORE_INST_DIR}/eniq_checks_solaris ]; then
        if [ -d ${ENIQ_CORE_INST_DIR}/eniq_checks ]; then
            $RM -rf ${ENIQ_CORE_INST_DIR}/eniq_checks
        fi
        $MV ${ENIQ_CORE_INST_DIR}/eniq_checks_solaris ${ENIQ_CORE_INST_DIR}/eniq_checks
        if [ $? -ne 0 ]; then
            _err_msg_="Could not move ${ENIQ_CORE_INST_DIR}/eniq_checks_solaris to ${ENIQ_CORE_INST_DIR}/eniq_checks.`$DATE '+%y%m%d'`"
            abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
        fi
        $ECHO "Solaris eniq_checks copied." >> ${LOGFILE}
        $RM -rf ${ENIQ_CORE_INST_DIR}/eniq_checks_linux
        $ECHO "Linux eniq_checks Removed./n" >> ${LOGFILE}
    else
        $ECHO "Solaris eniq_checks directory not found." >> ${LOGFILE}
        _err_msg_="Could not find ${ENIQ_CORE_INST_DIR}/eniq_checks_solaris directory .`$DATE '+%y%m%d'`"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi
fi
}


### Function: configure_backup_vlan ###
#
# To configure the Backup VLAN interface
#
# Arguments:
#        none
# Return Values:
#         none
configure_backup_vlan()
{
# Check if backup vlan info exists in migration conf
$CAT ${MIGRATION_CONF} | $GREP "^BKUP_VLAN_EXIST_${HNAME}" >> /dev/null 2>&1
if [ $? -ne 0 ]; then
    log_msg -s "Migration config file doesn't contain Backup VLAN information. Skipping step." -l ${LOGFILE} 
    return 0
fi

# Check if backup vlan configuration required
_backup_vlan_status_=`read_value BKUP_VLAN_EXIST_${HNAME} ${MIGRATION_CONF}` || abort_script "${_backup_vlan_status_}"
if [ "${_backup_vlan_status_}" == "NO" ]; then
    log_msg -s "Backup VLAN configuration not required." -l ${LOGFILE}
    return 0
fi

# Get interface information from conf file
_backup_vlan_name_=`read_value BKUP_VLAN_INTF_NAME_${HNAME} ${MIGRATION_CONF}` || abort_script "${_backup_vlan_name_}"
_backup_vlan_ip_=`read_value BKUP_VLAN_INTF_IP_${HNAME} ${MIGRATION_CONF}` || abort_script "${_backup_vlan_ip_}"
_backup_vlan_netmask_=`read_value BKUP_VLAN_INTF_NETMASK_${HNAME} ${MIGRATION_CONF}` || abort_script "${_backup_vlan_netmask_}"

# Create the interface 
create_interface ${_backup_vlan_name_} ${_backup_vlan_ip_} ${_backup_vlan_netmask_}
if [ $? -ne 0 ]; then
    _err_msg_="Failed to create Backup VLAN on $HNAME."
    abort_script "${_err_msg_}"
fi
}

### Function: configure_storage_api ###
#
# Configure storage API
#
# Arguments:
#   none 
# Return Values:
#    none
configure_storage_api()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

if [ "${STORAGE_TYPE}" == "fs" ]; then
    insert_header_footer foot "Rack Server - Skipping Linux ${ACTION_TYPE} Stage - ${NEXT_STAGE} " ${LOGFILE}
    set_next_stage `$EXPR ${ARRAY_ELEM}+1`
    return 0
fi

# Checking if blkcli command is executable or not
if [ ! -x ${_stor_api_cmd_} ]; then
    _err_msg_="${_stor_api_cmd_} is not found or is not executable"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

# Check if storage is configured
log_msg -s "Checking if storage is already configured." -l ${LOGFILE}
_storage_conf_file_=${ERICSSON_STOR_DIR}/san/plugins/${SAN_DEVICE}/etc/clariion.conf
if [ -s "${_storage_conf_file_}" ];then
    log_msg -s "Storage is configured.\n" -l ${LOGFILE}
    set_next_stage `$EXPR ${ARRAY_ELEM}+1`
    return 0
else    
    # Read location of storage API command
    _stor_api_cmd_=${ERICSSON_STOR_DIR}/san/bin/blkcli
    if [ ! -x ${_stor_api_cmd_} ]; then
        _err_msg_="${_stor_api_cmd_} is not found or is not executable"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi

    # Get storage data from migration conf file
    _no_of_san_=`$CAT ${MIGRATION_CONF} | $GREP "^STORAGE_NAME_" | $WC -l`
    _stor_det_file_=${TEM_DIR}/store_api_det_file
    $RM -rf ${_stor_det_file_}

    for (( _count_=1; $_count_<=$_no_of_san_; _count_++ ));do
        log_msg -q -s "INFO: Configuring Storage device ${_count_}" -l ${LOGFILE}
        # Get required SAN details from migration conf file
        _stor_name_=`read_value STORAGE_NAME_${_count_} ${MIGRATION_CONF}` || abort_script "${_stor_name_}" "${EXEC_SHELL_CMD}"
        _stor_admin_=`read_value STORAGE_ADMIN_${_count_} ${MIGRATION_CONF}` || abort_script "${_stor_admin_}" "${EXEC_SHELL_CMD}"
        _stor_pass_=`read_value STORAGE_PASS_${_count_} ${MIGRATION_CONF}` || abort_script "${_stor_pass_}" "${EXEC_SHELL_CMD}"
        
        #Decrypting Storage password
        _stor_pass_=`$ECHO ${_stor_pass_} | $OPENSSL enc -base64 -d`
        if [ $? -ne 0 ]; then
            _err_msg_="Unable to decrypt the storage password."
            abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
        fi
        
        _stor_spa_=`read_value STORAGE_SPA_${_count_} ${MIGRATION_CONF}` || abort_script "${_stor_spa_}" "${EXEC_SHELL_CMD}"
        _stor_spb_=`read_value STORAGE_SPB_${_count_} ${MIGRATION_CONF}` || abort_script "${_stor_spb_}" "${EXEC_SHELL_CMD}"
        _stor_group_=`read_value STORAGE_GROUP_${_count_} ${MIGRATION_CONF}` || abort_script "${_stor_group_}" "${EXEC_SHELL_CMD}"

        if [ ! -s ${_stor_det_file_} ]; then
            $ECHO "agentip=${HOST_AGENT_IP}" > ${_stor_det_file_}
        fi
        $ECHO "${SAN_DEVICE}=${_stor_name_}:${_stor_admin_}:${_stor_pass_}:${_stor_spa_}:${_stor_spb_}:${_stor_group_}" >> ${_stor_det_file_}
    done

    # Check stor api file
        if [ ! -s ${_stor_det_file_} ];then
           _err_msg_="Unable to store SAN data in ${_stor_det_file_} file."
           abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
        fi

    # Register the server with the SAN and see the Luns
    log_msg -q -s "Executing command:\n${_stor_api_cmd_} --action configure --plugin ${SAN_DEVICE} --config ${_stor_det_file_}\n" -l ${LOGFILE}
    ${_stor_api_cmd_} --action configure -plugin ${SAN_DEVICE} --config ${_stor_det_file_}
    if [ $? -ne 0 ]; then
        _error_msg_="Unable to configure SAN."
        abort_script "${_error_msg_}" "${EXEC_SHELL_CMD}" 
    fi
    log_msg -s "INFO: Successfully configured Storage API.\n" -l ${LOGFILE}

    insert_header_footer foot "Successfully completed Migration Stage - ${NEXT_STAGE}" ${LOGFILE}
    set_next_stage `$EXPR ${ARRAY_ELEM} + 1`
fi
}

### Function: create_admin_dir ###
#
# Creates the admin directory
#
# Arguments:
#   none
# Return Values:
#   none
create_admin_dir()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

local _san_ddc_collection_script_=manageSanDataCollection.bsh

# Skip stage on non-Coordinator blades
if [ ! "${CO_SERVER}" ]; then
    insert_header_footer foot "INFO: Skipping ${ACTION_TYPE} Stage - ${NEXT_STAGE} for ${CURR_SERVER_TYPE}" ${LOGFILE}
    set_next_stage `$EXPR ${ARRAY_ELEM}+1`
    return 0
fi

# Ensuring that the NAS filesystem with backup data is mounted
mount_nas_fs

# Calling create_admin_dir stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s create_admin_dir -u ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - create_admin_dir"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

#Restoring the configuration files from portbackup to eniq/admin/etc directory
if [ "${CURR_SERVER_TYPE}" == "stats_coordinator" -o "${CURR_SERVER_TYPE}" == "eniq_stats" ]; then
      log_msg -t -s "Restoring configuration files at ${ENIQ_ADMIN_DIR}/etc\n" -l ${LOGFILE}
      $CP -pr ${ENIQ_PORTBACKUP}/${HNAME}/NAS/${ENIQ_ADMIN_DIR}/etc/*.env ${ENIQ_ADMIN_DIR}/etc
      if [ $? -ne 0 ]; then
           _err_msg_="Could not restore configuration files"
            abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
      fi
    log_msg -t -s "Successfully restored configuration files at ${ENIQ_ADMIN_DIR}/etc\n" -l ${LOGFILE}
    
    log_msg -t -s "Removing ${_san_ddc_collection_script_} file from ${ENIQ_ADMIN_BIN_DIR} directory \n" -l ${LOGFILE}
    $RM -rf ${ENIQ_ADMIN_BIN_DIR}/${_san_ddc_collection_script_}
    
    log_msg -t -s "Copying ${_san_ddc_collection_script_} file from ${DDC_MONITOR} to ${ENIQ_ADMIN_BIN_DIR} directory \n" -l ${LOGFILE}
    $CP -p ${DDC_MONITOR}/${_san_ddc_collection_script_} ${ENIQ_ADMIN_BIN_DIR}
    if [ $? -ne 0 ]; then
        _err_msg_="Failed to copy ${_san_ddc_collection_script_} file"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi
    
    # Setting permission 755
    $CHMOD 755 ${ENIQ_ADMIN_BIN_DIR}/${_san_ddc_collection_script_}
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: create_directories ###
#
# Creates all required Directories
#
# Arguments:
#   none
# Return Values:
#   none
create_directories()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

# Calling create_directories stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s create_directories ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - create_directories"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: create_disk_partition_stats_pool ###
#
# To Create partition only on the merged LUN
#
# Arguments:
#   none
# Return Values:
#   none
create_disk_partition_stats_pool()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

# Get the mpath value
_mpath_val_=`${_stor_api_cmd_} --action listluns | $GREP -w "${SAN_DEVICE_NAME}@${RECREATED_LUN_ID}" | $AWK -F";" '{print $2}'`

# Calling create_disk_partition stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s create_disk_partition ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - create_disk_partition"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

# Check if the partition created
$PARTED -s /dev/mapper/${_mpath_val_} print >>/dev/null 2>&1
if [ $? -ne 0 ]; then
    _err_msg_="Failed to create partition"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: create_groups ###
#
# Creates all required Groups
#
# Arguments:
#   none
# Return Values:
#   none
create_groups()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling create_groups stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s create_groups ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - create_groups"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: create_interface ###
#
# To configure interface  
#
# Arguments:
#        $1 : Interface Name
#        $2 : Interface IP
#        $3 : Interface Netmask IP
# Return Values:
#         none
create_interface()
{
# Check if required parameters are passed
if [ $# -ne 3 ]; then
    _err_msg_="Inadequate information passed to configure interface."
    abort_script "${_err_msg_}"
fi

_intf_name_=$1
_intf_ip_=$2
_intf_netmask_=$3

# Calculate subnet if required
_intf_subnet_=""
if [ ! "${SOLARIS_10}" ]; then
    _intf_subnet_=`get_network_from_netmask ${_intf_netmask_}`
fi

_add_intf_=0

# Get list of interfaces available
_intf_list_file_=${TEM_DIR}/available_interface_list
log_msg -s "\nCreating list of interfaces available on current server." -l ${LOGFILE}
if [ ! "${SOLARIS_10}" ];then
    $DLADM show-link -p -o LINK | $SORT -u > ${_intf_list_file_}
else
    $DLADM show-dev | $AWK '{print $1}' > ${_intf_list_file_}
fi

if [ ! -s ${_intf_list_file_} ];then
    _err_msg_="Could not fetch available interfaces."
    log_msg -s "${_err_msg_}" -l ${LOGFILE}
    return 1
fi

# Check if interface name valid
$GREP ${_intf_name_} ${_intf_list_file_} >> /dev/null 2>&1
if [ $? -ne 0 ]; then
    if [ ! "${SOLARIS_10}" ];then
        $DLADM show-phys | $GREP ${_intf_name_} >> /dev/null 2>&1
        if [ $? -ne 0 ]; then
            _err_msg_="Invalid interface name ${_intf_name_} provided."
            log_msg -s "${_err_msg_}" -l ${LOGFILE}
            return 1
        fi
        _intf_name_=`$DLADM show-phys | $GREP ${_intf_name_} | $AWK '{print $1}'`
    else
        _err_msg_="Invalid interface name ${_intf_name_} provided during premigration."
        log_msg -s "${_err_msg_}" -l ${LOGFILE}
        return 1
    fi
fi

# Check if the interface is already configured
_assigned_ip_=""
if [ ! "${SOLARIS_10}" ]; then
    $IPADM show-if -p -o IFNAME ${_intf_name_} >> /dev/null 2>&1
    if [ $? -eq 0 ]; then
        _assigned_ip_=`$IPADM show-addr -p -o ADDR ${_intf_name_}/v4 | $CUT -f1 -d'/'`
    fi
else
    $LS /etc/hostname.${_intf_name_} >> /dev/null 2>&1
    if [ $? -eq 0 ]; then
        _assigned_ip_=`$CAT /etc/hostname.${_intf_name_} | $AWK '{print $1}'`
    fi
fi

if [ "${_assigned_ip_}" == "${_intf_ip_}" ]; then
    log_msg -s "\nInterface ${_intf_name_} is already configured on server." -l ${LOGFILE}
    return 0
else
    _add_intf_=1
fi

# Configure the interface
if [ $_add_intf_ -eq 1 ]; then
    # Check if we have all the relevant information
    if [ ! "${_intf_name_}" -o ! "${_intf_ip_}" -o ! "${_intf_netmask_}" ]; then
        _err_msg_="Required details to create interface not available"
        log_msg -s "${_err_msg_}" -l ${LOGFILE}
        return 1
    fi
    if [ ! "${SOLARIS_10}" ]; then
        if [ ! "${_intf_subnet_}" ]; then
            _err_msg_="Required subnet to create interface not available"
            log_msg -s "${_err_msg_}" -l ${LOGFILE}
            return 1
        fi
    fi

    # Create the interface with the details
    if [ ! "${SOLARIS_10}" ]; then
        # Re-create the interface if exists
        $IPADM delete-ip ${_intf_name_} >> /dev/null 2>&1
        $IPADM create-ip ${_intf_name_} >> /dev/null 2>&1
        if [ $? -ne 0 ]; then
             _err_msg_="Unable to create interface ${_intf_name_}."
            log_msg -s "${_err_msg_}" -l ${LOGFILE}
            return 1
        fi

        # Assign IP to the interface
        $IPADM create-addr -T static -a ${_intf_ip_}/${_intf_subnet_} ${_intf_name_}
        if [ $? -ne 0 ]; then
            _err_msg_="Unable to assign IP to ${_intf_name_}." 
            log_msg -s "${_err_msg_}" -l ${LOGFILE}
            return 1
        fi
        log_msg -l ${LOGFILE} -s "Successfully created interface ${_intf_name_}"
    else
        # Configure temporary interface hostname file
        $ECHO "${_intf_ip_} netmask ${_intf_netmask_} broadcast + up" > ${TEM_DIR}/hostname.${_intf_name_}
        if [ ! -s ${TEM_DIR}/hostname.${_intf_name_} ]; then
            _err_msg_="Could not write to temporary hostname.${_intf_name_} file."
            log_msg -s "${_err_msg_}" -l ${LOGFILE}
            return 1
        fi

        # Plumb the interface
        ${IFCONFIG} ${_intf_name_} unplumb >> /dev/null 2>&1
        ${IFCONFIG} ${_intf_name_} plumb >> /dev/null 2>&1
        sleep 5

        # Assign IP to the interface 
        ${IFCONFIG} ${_intf_name_} ${_intf_ip_} netmask ${_intf_netmask_}  >> /dev/null 2>&1
        if [  $? -ne 0 ]; then
            _err_msg_="Failed to Configure Interface [ ${_intf_name_} ]"
            log_msg -s "${_err_msg_}" -l ${LOGFILE}
            return 1
        fi
        sleep 5

        ${IFCONFIG} ${_intf_name_} up >> /dev/null 2>&1
        if [ $? -ne 0 ]; then
            _err_msg_="Failed to activate Interface [ ${_intf_name_} ]"
            log_msg -s "${_err_msg_}" -l ${LOGFILE}
            return 1
        fi
        $CP ${TEM_DIR}/hostname.${_intf_name_} /etc/hostname.${_intf_name_}
        if [ ! -s ${TEM_DIR}/hostname.${_intf_name_} ]; then
            _err_msg_="Could not save hostname.${_intf_name_} file."
            log_msg -s "${_err_msg_}" -l ${LOGFILE}
            return 1
        fi
    fi
fi
}

### Function: create_logical_volume_filesystem ###
#
# Creates all required Filesystems
#
# Arguments:
#   none
# Return Values:
#   none
create_logical_volume_filesystem()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

if [ "${CURR_SERVER_TYPE}" == "stats_iqr" ]; then
     _reader_alias_=`$CAT /etc/hosts | $GREP -vw loghost | $GREP -w $HNAME | $AWK '{print $3}'| $SORT -u`

     $ECHO "${_reader_alias_}" | $EGREP "^${READER_STR}[1-9][0-9]*$" >> /dev/null 2>&1
      if [ $? -ne 0 ]; then
          _err_msg_="Reader alias is not in proper format"
          abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
      fi

      $ECHO "${_reader_alias_}" > ${ENIQ_CONF_DIR}/install_reader_type
fi

#Calling create_logical_volume_filesystem stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s create_logical_volume_filesystem -n -l ${LOGFILE}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - create_logical_volume_filesystem"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: create_lun_map ###
#
# Create LUN MAP ini file
#
# Arguments:
#   none
# Return Values:
#   none
create_lun_map()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling create_lun_map stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s create_lun_map ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - create_lun_map"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: create_nas_users ###
#
#Create NAS users
#
# Arguments:
#       none
# Return Values:
#       none
create_nas_users()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling create_nas_users stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s create_nas_users ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - create_nas_users"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

log_msg -s "\nSetting up SSH connection for NAS." -l ${LOGFILE}

# Check required files and scripts exist
local _ssh_input_file_="${ENIQ_CONF_DIR}/ssh_input_file"
check_for_file -s ${_ssh_input_file_} 

local _setup_ssh_FileStore_script_="${ERICSSON_BIN_DIR}/setup_ssh_FileStore.sh"
check_for_file -s ${_setup_ssh_FileStore_script_} 

$ECHO "\nExecuting command: $BASH ${ERICSSON_BIN_DIR}/setup_ssh_FileStore.sh ${ENIQ_CONF_DIR}/ssh_input_file" >> ${LOGFILE}
$BASH ${ERICSSON_BIN_DIR}/setup_ssh_FileStore.sh ${ENIQ_CONF_DIR}/ssh_input_file
if [ $? -ne 0 ];then
     _err_msg_="Could not setup SSH connectivity. Please check logfile ${ERICSSON_STOR_DIR}/log/setup_ssh_FileStore.log for further details."
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: create_rbac_roles ###
#
# Create RBAC roles
#
# Arguments:
#   none
# Return Values:
#   none
create_rbac_roles()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling create_rbac_roles stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s create_rbac_roles ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - create_rbac_roles"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: create_users ###
#
# Creates all required Users
#
# Arguments:
#   none
# Return Values:
#   none
create_users()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

log_msg -s "\nChecking if dcuser is created." -l ${LOGFILE}
$CAT /etc/passwd | $GREP "^dcuser" >> /dev/null 2>&1
if [ $? -ne 0 ]; then
    # Remove dcuser ssh keys
    if [ "${CO_SERVER}" ];then
         local _eniq_home_mount_=0

         _nfs_host_=`iniget Storage_NAS_HOME -f ${ENIQ_CONF_DIR}/storage.ini -v NFS_HOST`
         _share_path_=`iniget Storage_NAS_HOME -f ${ENIQ_CONF_DIR}/storage.ini -v SHARE_PATH`
         _mount_path_=`iniget Storage_NAS_HOME -f ${ENIQ_CONF_DIR}/storage.ini -v MOUNT_PATH`
 
         # Ensuring that the NAS_HOME Filesystem is mounted
         log_msg -t -s "Ensuring that the NAS_HOME Filesystem is mounted before proceeding further"

         # Create the mount point if its not there
         if [ ! -d ${_mount_path_} ]; then
             log_msg -s "\nCreating mount point - ${_mount_path_}" -l ${LOGFILE}
             $MKDIR -p ${_mount_path_} >> /dev/null 2>&1
             if [ $? -ne 0 ]; then
                 _err_msg_="Could not create mount point ${_mount_path_}"
                 abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
             fi
         fi

         _mount_exists_=`$MOUNT | $GREP "${_mount_path_}" | $AWK '{print $1}'`
         if [ ! "${_mount_exists_}" ]; then
              _eniq_home_mount_=1
         fi

         if [ ${_eniq_home_mount_} -eq 1 ]; then
             log_msg -s "Mounting ${_nfs_host_}:${_share_path_} on ${_mount_path_}" -l ${LOGFILE}
             $MOUNT -t nfs ${_nfs_host_}:${_share_path_} ${_mount_path_} >> /dev/null 2>&1
             if [ $? -ne 0 ]; then
                 _err_msg_="Could not mount ${_nfs_host_}:${_share_path_} on ${_mount_path_}"
                 abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
             else
                 log_msg -s "\nSuccessfully mounted NAS_HOME Filesystem"
             fi
         else
             log_msg -s "${_mount_path_} is already mounted" -l ${LOGFILE}
         fi

         log_msg -s "\nTaking backup of dcuser .ssh keys." -l ${LOGFILE}
         $CP -rf ${DCUSER}.ssh ${DCUSER}.ssh_migbkup >> /dev/null 2>&1

         log_msg -s "\nRemoving dcuser .ssh keys." -l ${LOGFILE}
         $RM -rf ${DCUSER}.ssh >> /dev/null 2>&1
    fi
fi

# Remove CO root ssh keys if they exist
if [ "${CO_SERVER}" ]; then
    $CP -rf ${SSH_DIR} ${SSH_DIR}_migbkup >> /dev/null 2>&1
    log_msg -s "\nRemoving root .ssh keys." -l ${LOGFILE}
    $RM -rf ${SSH_DIR} >> /dev/null 2>&1
fi

#Calling create_users stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s create_users ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - create_users"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

# Remove backup of .ssh directories
$RM -rf ${SSH_DIR}_migbkup /eniq/home/dcuser/.ssh_migbkup >> /dev/null 2>&1

# Get the System User/Group. All directories are owned by this
SYSUSER=`iniget ENIQ_INSTALL_CONFIG -f ${ENIQ_CONF_DIR}/${SUNOS_INI} -v ENIQ_SYSUSER`
if [ ! "${SYSUSER}" ]; then
    _err_msg_="Could not read SYSUSER param from ${ENIQ_CONF_DIR}/${SUNOS_INI}"
    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

SYSGRP=`$ID ${SYSUSER}|$AWK '{print $2}'|$AWK -F\( '{print $2}'|$AWK -F\) '{print $1}'`
if [ ! "${SYSGRP}" ]; then
    _err_msg_="Could not read SYSGRP param from ${ENIQ_CONF_DIR}/${SUNOS_INI}"
    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

# Change ownership of /eniq/home/dcuser/.ssh
$CHOWN -R $SYSUSER:$SYSGRP ${DCUSER}.ssh
if [ $? -ne 0 ]; then
     _err_msg_="Could not change ownership of ${DCUSER}.ssh" 
     abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

## changing password for root user.
_host_=$HNAME
_R_PWD_1=`$CAT ${MIGRATION_CONF} | $GREP ^ROOT_PASSWORD_${_host_}= | $AWK -F"ROOT_PASSWORD_\${_host_}=" '{print $2}'`
if [ ! "${_R_PWD_1}" ]; then
    _err_msg_="Could not read value of ROOT_PASSWORD from ${MIGRATION_CONF}"
    abort_script "${_err_msg_}"
fi
_R_PWD_2=`$ECHO ${_R_PWD_1} | $OPENSSL enc -base64 -d`
if [ ! "${_R_PWD_2}" ]; then
    err_msg_="Could not decrypt password ROOT_PASSWORD"
    abort_script "${_err_msg_}"
fi
_R_PWD_=$(/usr/bin/perl -e 'print quotemeta shift(@ARGV)' "${_R_PWD_2}")
if [ $? -ne 0 ]; then
    _err_msg_="Could not run perl command on ROOT_PASSWORD"
    abort_script "${_err_msg_}"
fi
expect <<EOF >>${LOGFILE} 2>&1
set timeout 60
spawn su root -c "passwd"
expect {
"New password:" {send -- "$_R_PWD_\r";exp_continue}
"Retype new password:" {send -- "$_R_PWD_\r"}
timeout {send user "\nTIMEOUT\n"; exit 9}
}
expect eof
EOF
log_msg -s "\nSuccessfully changed the password for root user" -l "${LOGFILE}"
#Please do not add any spaces before EOF

## Changing password for dcuser.
_DC_PWD_1=`$CAT ${MIGRATION_CONF} | $GREP ^DC_PASSWORD_${_host_}= | $AWK -F"DC_PASSWORD_\${_host_}=" '{print $2}'`
if [ ! "${_DC_PWD_1}" ]; then
    _err_msg_="Could not read value of DC_PASSWORD from ${MIGRATION_CONF}"
    abort_script "${_err_msg_}"
fi
_DC_PWD_2=`$ECHO ${_DC_PWD_1} | $OPENSSL enc -base64 -d`
if [ ! "${_R_PWD_2}" ]; then
    err_msg_="Could not decrypt password DC_PASSWORD"
    abort_script "${_err_msg_}"
fi
_DC_PWD_=$(/usr/bin/perl -e 'print quotemeta shift(@ARGV)' "${_DC_PWD_2}")
if [ $? -ne 0 ]; then
    _err_msg_="Could not run perl command on DC_PASSWORD"
    abort_script "${_err_msg_}"
fi
expect <<EOF >>${LOGFILE} 2>&1
set timeout 60
spawn su root -c "passwd dcuser"
expect {
"New password:" {send -- "$_DC_PWD_\r";exp_continue}
"Retype new password:" {send -- "$_DC_PWD_\r"}
timeout {send user "\nTIMEOUT\n"; exit 9}
}
expect eof
EOF
log_msg -s "\nSuccessfully changed the password for dcuser" -l "${LOGFILE}"
#Please do not add any spaces before EOF

# Ensuring that the NAS filesystem with backup data is mounted
mount_nas_fs

#Restoring the configuration files from portbackup to eniq/home/dcuser/enmcertificate directory
if [ -d ${ENIQ_PORTBACKUP}/${HNAME}/NAS/${DCUSER}/enmcertificate ]; then
    if [ "${CURR_SERVER_TYPE}" == "stats_coordinator" -o "${CURR_SERVER_TYPE}" == "eniq_stats" ]; then
        log_msg -t -s "Restoring configuration files at ${DCUSER}/enmcertificate\n" -l ${LOGFILE}
        if [ -d ${DCUSER}/enmcertificate ]; then
        log_msg -t -s "${DCUSER}/enmcertificate already exist\n" -l ${LOGFILE}
        else
            $CP -pr ${ENIQ_PORTBACKUP}/${HNAME}/NAS/${DCUSER}/enmcertificate ${DCUSER}
            if [ $? -ne 0 ]; then
                _err_msg_="Could not restore configuration files"
                abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
            fi
            log_msg -t -s "Successfully restored configuration files at ${DCUSER}/enmcertificate\n" -l ${LOGFILE}
        fi
    fi
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: create_volume_group ###
#
# Destroys any existing volume groups and creates
# the new ones
#
# Arguments:
#   none
# Return Values:
#   none
create_volume_group()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

_disk_layout_=`iniget SunOS_FS_POOL_1 -f ${ENIQ_CONF_DIR}/SunOS.ini  -v disk_layout`
if [ -z ${_disk_layout_} ]; then

     _mpath_val_=`${_stor_api_cmd_} --action listluns | $GREP -w "${SAN_DEVICE_NAME}@${RECREATED_LUN_ID}" | $AWK -F";" '{print $2}'`
     if [ $? -ne 0 ]; then
          _err_msg_="Could not get the required parameter mpath value for ${SAN_DEVICE_NAME}@${RECREATED_LUN_ID}"
           abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
     fi

     log_msg -t -s "Setting the required parameter ${_mpath_val_} in the ${ENIQ_CONF_DIR}/SunOS.ini file" -l ${LOGFILE}
     iniset SunOS_FS_POOL_1 -f ${ENIQ_CONF_DIR}/SunOS.ini  disk_layout="${_mpath_val_}"
     if [ $? -ne 0 ]; then
          _err_msg_="Could not set the required parameter ${_mpath_val_} in the ${ENIQ_CONF_DIR}/SunOS.ini file"
           abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
     fi
fi

#Calling create_volume_group stage from eniq_core_install.bsh
log_msg -t -s "Creating volume group" -l ${LOGFILE}
$BASH ${ENIQ_CORE_INST_SCRIPT} -s create_volume_group ${ENIQ_CORE_INST_ARG} >> ${LOGFILE}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - create_volume_group"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: database_start_stop ###
#
#   Creates disable_OSS for each oss mounts
#
# Arguments:
#          $1 = Database (dwhdb/repdb)
#          $2 = Action (start/stop)
#
# Return Values: Exit status of administrator script
database_start_stop()
{
local _db_=$1
local _action_=$2

$SU - $SYSUSER -c "$BASH ${ENIQ_ADMIN_DIR}/bin/${_db_} ${_action_}"
return $?
}

### Function: drop_loginpolicies ###
#
# Drop Login Policies 
#
# Arguments: none
# 
# Return Values: none
drop_loginpolicies()
{
log_msg -q -s "Drop Login policies" -l ${LOGFILE}

# Create hushlogin hidden file to suppress messages we get when doing switch user
$TOUCH /eniq/home/dcuser/.hushlogin > /dev/null 2>&1 

$SU - $SYSUSER -c "$DBISQL @${conn_str_dba_enc} -nogui  \"select user_name from sysuser, sysloginpolicy where sysuser.login_policy_id = sysloginpolicy.login_policy_id and sysloginpolicy.login_policy_name = 'locked_users';OUTPUT TO ${TEM_DIR}/locked_users FORMAT TEXT \" 1>/dev/null 2>/tmp/error_locked_user.log"
if [ $? -ne 0 ] ; then
    $CAT /tmp/error_locked_user.log >> ${LOGFILE}
    $RM    /tmp/error_locked_user.log
    _err_msg_="Could not query the users assigned to the locked_users Login policy"
    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi
$RM /tmp/error_locked_user.log


$SU - $SYSUSER -c "$DBISQL @${conn_str_dba_enc} -nogui  \"select user_name from sysuser, sysloginpolicy where sysuser.login_policy_id = sysloginpolicy.login_policy_id and sysloginpolicy.login_policy_name = 'unlocked_users';OUTPUT TO ${TEM_DIR}/unlocked_users FORMAT TEXT \" 1>/dev/null 2>/tmp/error_unlocked_user.log"
if [ $? -ne 0 ] ; then
    $CAT /tmp/error_unlocked_user.log >> ${LOGFILE}
    $RM    /tmp/error_unlocked_user.log
    _err_msg_="Could not query the users assigned to the unlocked_users Login policy"
    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi
$RM /tmp/error_unlocked_user.log

_locked_users_=` $CAT ${TEM_DIR}/locked_users | $SED "s/^'//g"| $SED "s/'$//g" `
_unlocked_users_=` $CAT ${TEM_DIR}/unlocked_users | $SED "s/^'//g"| $SED "s/'$//g"`

_users_list_=( ${_locked_users_} ${_unlocked_users_} )

for _user_ in "${_users_list_[@]}"; do
    log_msg -s "Assigning user ${_user_} to root Login Policy" -l ${LOGFILE}
    $SU - $SYSUSER -c "$DBISQL @${conn_str_dba_enc} -nogui  \"set temporary option ON_ERROR='EXIT';ALTER USER ${_user_} LOGIN POLICY root;\" "
    if [ $? -ne 0 ] ; then
        _err_msg_="Could not assign user ${_user_} to root Login Policy"
        abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
    fi
done

$SU - $SYSUSER -c "$DBISQL @${conn_str_dba_enc} -nogui  \"set temporary option ON_ERROR='EXIT';drop login policy locked_users;\" "
if [ $? -ne 0 ] ; then
    _err_msg_="Could not drop login policy locked_users"
    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

$SU - $SYSUSER -c "$DBISQL @${conn_str_dba_enc} -nogui  \"set temporary option ON_ERROR='EXIT';drop login policy unlocked_users;\" "
if [ $? -ne 0 ] ; then
    _err_msg_="Could not drop login policy unlocked_users"
    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

# remove the hushlogin hidden file
$RM -f /eniq/home/dcuser/.hushlogin > /dev/null 2>&1  
}

### Function: enable_oss_mounts ###
#
#   Deletes disable_OSS for each oss mounts
#
# Arguments:
#   none
# Return Values:
#   none
enable_oss_mounts()
{
log_msg -s "\nChecking for OSS mount info directories." -l ${LOGFILE}
_oss_mount_dir_="${ENIQ_BASE_DIR}/connectd/mount_info"
if [ ! -d ${_oss_mount_dir_} ];then
    _err_msg_="Couldn't find ${_oss_mount_dir_} directory."
    abort_script "${_err_msg_}"
fi
_oss_list_=`$LS -1 ${_oss_mount_dir_} 2> /dev/null`

if [ "${_oss_list_}" ];then
    for _dir_ in ${_oss_list_}
    do
        log_msg -q -s "\nRemoving disable_OSS file from ${_oss_mount_dir_}/${_dir_}" -l ${LOGFILE}
        $RM -f ${_oss_mount_dir_}/${_dir_}/disable_OSS
    done
else
    log_msg -s "\nNo OSS mount present to enable on ${HNAME}" -l ${LOGFILE}
fi
}

### Function: export_pools ###
#
#   Exports pools during prerecovery activity
#
# Arguments:
#   none
# Return Values:
#   none
export_pools()
{
log_msg -s "\nExporting VGs during ${ACTION_TYPE}" -l ${LOGFILE}
cd /

# Check pools are healthy before export
_health_status_="r/w"
# Get the list of all available VG on the server
_vg_list_=`$VGS -o name --noheading`

# Check the health status of all fetched VG's
for _vg_ in ${_vg_list_}
do
    _vg_health_status_=`${VGDISPLAY} ${_vg_} -c  | $AWK -F":" '{print $2}' `
    if [ "${_vg_health_status_}" != "r/w" ];then
        _err_msg_="VGs are not in proper state. Please check."
         abort_script "${_err_msg_}"
    fi
    log_msg -s "\n${_vg_} VG is online." -l ${LOGFILE}
done

if [ ! "${NO_CONFIRM}" ];then
    $ECHO "\n\nWARNING: You are about to export the pools from system"
    user_confirm
    $ECHO "\nYou have selected $_response_"
    if [ "${_response_}" != "YES" ];then
        log_msg -s "Exiting from script as user selected NOT to proceed." -l ${LOGFILE}
        $ECHO "Please export pools manually."
        return 0
    fi
fi

# Check and deactivate SWAP files
$GREP swap /etc/fstab | $AWK '{print $1}' >> /dev/null 2>&1
if [ $? -eq 0 ];then
    _swap_file_=`$GREP swap /etc/fstab |$AWK '{print $1}' |$GREP _pool`
    log_msg -s "\nDeactivating ${_swap_file_} from ${_pool_list_}" -l ${LOGFILE}
    $SWAPOFF  ${_swap_file_} >> /dev/null 2>&1
fi

log_msg -s "\nExporting following VGs:" -l ${LOGFILE}
log_msg -s "${_pool_list_}" -l ${LOGFILE}

for _exp_vg_ in ${_pool_list_}
do
    $VGCHANGE -an ${_exp_vg_} >> /dev/null 2>&1
    if [ $? -ne 0 ];then
        _err_msg_="Can't deactivated VG ${_exp_vg_}"
        mount_lvm
        abort_script "${_err_msg_}"
    fi

    $VGEXPORT  ${_pool_list_} >> /dev/null 2>&1
    if [ $? -ne 0 ];then
        _err_msg_="VG ${_exp_vg_} not exported. Resolve the issue(s) and re-run the script again."
        abort_script "${_err_msg_}"
    else
        log_msg -s "\nExported VG: ${_exp_vg_}" -l ${LOGFILE}
    fi
done

log_msg -s "\nAll VGs have been exported." -l ${LOGFILE}
}

### Function: generate_keys ###
#
# Generate ssh keys for root
#
# Arguments:
#    none
# Return Values:
#    none
generate_keys()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling generate_keys stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s generate_keys -u ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - generate_keys"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: get_array_element ###
#
# Get the current array element number
#
# Arguments:
#   none
# Return Values:
#   none
get_array_element()
{
_num_elements_=${#ENIQ_CORE_STAGES[*]}
_array_length_=`${EXPR} ${_num_elements_} - 1`

for (( _elem_=0; _elem_<=${_array_length_}; _elem_++ )); do
    $ECHO ${ENIQ_CORE_STAGES[${_elem_}]} | $GREP -w ${NEXT_STAGE} >> /dev/null 2>&1
    if [ $? -eq 0 ]; then
        ARRAY_ELEM=${_elem_}
        break
    fi
done
}

### Function: get_backup_vlan_data ###
#
# get detail for backup vlan configuration
#
# Arguments:
#   none 
# Return Values:
#   none
get_backup_vlan_data()
{
_disp_file_=${TEM_DIR}/disp_file
$RM -rf ${_disp_file_}

if [ ! "$1" ];then
    _err_msg_="File name is required"
    abort_script "${_err_msg_}"
fi
_temp_backup_vlan_file_=$1

unset _backup_vlan_exist_ _backup_interface_name_ _backup_interface_ip_ _backup_interface_netmask_

# Return if MZ blade
if [ "${CURR_SERVER_TYPE}" == "eniq_mz" ]; then
    log_msg -s "\nSkipping for MZ blade $HNAME " -l ${LOGFILE}
    return 0
fi
# Return if not CO blade
if [ ! "${CO_SERVER}" ]; then
    log_msg -s "\nGetting Backup VLAN information for $HNAME ..." -l ${LOGFILE}
    _host_=$HNAME
    # Check if CO migration conf is created
    if [ -s ${MIGR_CO_CONF} ]; then
        # Check if BKUP_VLAN_EXIST parameter is there
        $CAT ${MIGR_CO_CONF} | $GREP ^BKUP_VLAN_EXIST_${_host_}= >> /dev/null 2>&1
        if [ $? -eq 0 ]; then
            _backup_vlan_exist_=`read_value BKUP_VLAN_EXIST_${_host_} ${MIGR_CO_CONF}` || abort_script "${_backup_vlan_exist_}"
            _backup_interface_name_=`read_value BKUP_VLAN_INTF_NAME_${_host_} ${MIGR_CO_CONF}` || abort_script "${_backup_interface_name_}"
            _backup_interface_ip_=`read_value BKUP_VLAN_INTF_IP_${_host_} ${MIGR_CO_CONF}` || abort_script "${_backup_interface_ip_}"
            _backup_interface_netmask_=`read_value BKUP_VLAN_INTF_NETMASK_${_host_} ${MIGR_CO_CONF}` || abort_script "${_backup_interface_netmask_}"
       fi

       # Check if backup VLAN info need to be saved in conf file
       if [ "${_backup_vlan_exist_}" -a "${_backup_interface_name_}" -a "${_backup_interface_ip_}" -a "${_backup_interface_netmask_}" ]; then
           # Set value in migration conf
           set_conf_value BKUP_VLAN_EXIST_${_host_} ${_backup_vlan_exist_} ${_temp_backup_vlan_file_}
           set_conf_value BKUP_VLAN_INTF_NAME_${_host_} ${_backup_interface_name_} ${_temp_backup_vlan_file_}
           set_conf_value BKUP_VLAN_INTF_IP_${_host_} ${_backup_interface_ip_} ${_temp_backup_vlan_file_}
           set_conf_value BKUP_VLAN_INTF_NETMASK_${_host_} ${_backup_interface_netmask_} ${_temp_backup_vlan_file_}
           log_msg -s "\nSuccessfully saved Backup VLAN information on ${_host_}." -l ${LOGFILE}
       fi
    fi
else
    # Creating available interface list to vaidate user input interface name
    if [ ! "${SOLARIS_10}" ];then
        $DLADM show-link -p -o LINK | $SORT -u > ${TEM_DIR}/interface_list
    else
        $DLADM show-dev | $AWK '{print $1}' > ${TEM_DIR}/interface_list
    fi
    if [ ! -s ${TEM_DIR}/interface_list ];then
        _err_msg_="Could not fetch available interfaces."
        abort_script "${_err_msg_}"
    fi

    # Loop through to get backup VLAN info for each blade
    for _line_ in `$CAT ${ORDER_FILE}`; do
      _host_=`$ECHO ${_line_} | $AWK -F'::' '{print $2}'`
      _srv_name_=`$ECHO ${_line_} | $AWK -F'::' '{print $3}'`
      while true
      do
        clear
        log_msg -s "\nGetting Backup VLAN information for ${_host_} [${_srv_name_}]..." -l ${LOGFILE}

        # Ask if Backup VLAN is configured
        while [ 1 ]
        do
            ask_for_input "whether Backup VLAN is configured on ${_host_} (YES/NO) : \n"
            _backup_vlan_exist_=${USER_VALUE}
            case ${_backup_vlan_exist_} in
                y|Y|Yes|YES) _response_="YES"
                break
                ;;
                n|N|No|NO) _response_="NO"
                break
                ;;
                *) $ECHO "Invalid input. Enter again."
                ;;
            esac
        done

        # Check response from user 
        if [ "${_response_}" == "NO" ];then
            log_msg -s "\nUser selected Backup VLAN as NOT configured." -l ${LOGFILE}  
            break
        else
            log_msg -q -s "\nUser selected Backup VLAN as configured. Continuing." -l ${LOGFILE}

            # Ask for Backup VLAN interface name
            while true
            do
                ask_for_input "Name of Backup VLAN interface on ${_host_}: \n"
                $CAT ${TEM_DIR}/interface_list | $GREP -w ${USER_VALUE} >> /dev/null 2>&1
                if [ $? -eq 0 ]; then
                    _backup_interface_name_=${USER_VALUE}
                    break
                else
                    $ECHO "not valid interface name ${USER_VALUE}"
                    continue
                fi
            done
            # Ask for Backup VLAN interface IP 
            while true
            do
                ask_for_input "IP of Backup VLAN interface on ${_host_}: \n"
                validate_ip ${USER_VALUE}
                if [ $? -eq 0 ]; then
                    _backup_interface_ip_=${USER_VALUE}
                    break
                fi
            done
            # Ask for Backup VLAN interface netmask IP
            while true
            do
                ask_for_input "Netmask of Backup VLAN interface on ${_host_}: \n"
                validate_ip ${USER_VALUE}
                if [ $? -eq 0 ]; then
                    _backup_interface_netmask_=${USER_VALUE}
                    break
                fi
            done

            $ECHO "\nDisplaying Backup VLAN information for ${_host_}" > ${_disp_file_}
            $ECHO "------------------------------------------------\n" >> ${_disp_file_}
            $ECHO "Backup VLAN interface exists on ${_host_}\t : ${_backup_vlan_exist_}" >> ${_disp_file_}
            $ECHO "Backup VLAN interface name to be configured on ${_host_}\t : ${_backup_interface_name_}" >> ${_disp_file_}
            $ECHO "Backup VLAN interface IP to be configured on ${_host_}\t : ${_backup_interface_ip_}" >> ${_disp_file_}
            $ECHO "Backup VLAN Netmask to be configured on ${_host_}\t : ${_backup_interface_netmask_}" >> ${_disp_file_}

            # Displaying data to user
            clear
            $CAT ${_disp_file_}
            user_confirm
            if [ "${_response_}" != "YES" ];then
                log_msg -s "\nBackup VLAN details will be asked again as user selected NOT to proceed." -l ${LOGFILE}
                continue
            fi

            set_conf_value BKUP_VLAN_EXIST_${_host_} ${_backup_vlan_exist_} ${_temp_backup_vlan_file_}
            set_conf_value BKUP_VLAN_INTF_NAME_${_host_} ${_backup_interface_name_} ${_temp_backup_vlan_file_}
            set_conf_value BKUP_VLAN_INTF_IP_${_host_} ${_backup_interface_ip_} ${_temp_backup_vlan_file_}
            set_conf_value BKUP_VLAN_INTF_NETMASK_${_host_} ${_backup_interface_netmask_} ${_temp_backup_vlan_file_}
            log_msg -s "\nSuccessfully taken Backup VLAN information for ${_host_} [${_srv_name_}]" -l ${LOGFILE}
            break
        fi
      done
    done
fi

# Removing temporary file
$RM -rf ${_disp_file_} >> /dev/null 2>&1

log_msg -s "\nSuccessfully completed step to get Backup VLAN information." -l ${LOGFILE}
}

### Function: get_database_info ###
#
# Retrieve information for required database
#
# Arguments:
#       $1 = Database
#       $2 = Section in SunOS.ini file
#
# Return Values: none
get_database_info()
{
local _db_=$1
local _ini_sect_=$2

# Get the System User/Group. All directories are owned by this
SYSUSER=`iniget ENIQ_INSTALL_CONFIG -f ${ENIQ_CONF_DIR}/${SUNOS_INI} -v ENIQ_SYSUSER`
if [ ! "${SYSUSER}" ]; then
    _err_msg_="Could not read SYSUSER param from ${ENIQ_CONF_DIR}/${SUNOS_INI}"
    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

SYSGRP=`$ID ${SYSUSER}|$AWK '{print $2}'|$AWK -F\( '{print $2}'|$AWK -F\) '{print $1}'`
if [ ! "${SYSGRP}" ]; then
    _err_msg_="Could not read SYSGRP param from ${ENIQ_CONF_DIR}/${SUNOS_INI}"
    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi 

# Get the DBA password for the database
_dba_pass_=`inigetpassword DB -f ${ENIQ_CONF_DIR}/${ENIQ_INI} -v DBAPassword`
if [ ! ${_dba_pass_} ]; then
     err_msg_="`$DATE +%d.%m.%y_%H:%M:%S` - Could not read DBA password from ${CLI_CONF_DIR}/${ENIQ_INI}"
     abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

# Get the port number associated with the database
_db_port_=`iniget ${_ini_sect_} -f ${ENIQ_CONF_DIR}/${ENIQ_INI} -v PortNumber`
if [ ! "${_db_port_}" ]; then
        _err_msg_="Could not read port number of ${_db_} from ${ENIQ_CONF_DIR}/${ENIQ_INI}"
        abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

# Get the database engine associated with the database
_db_eng_=`iniget ${_ini_sect_} -f ${ENIQ_CONF_DIR}/${ENIQ_INI} -v ServerName`
if [ ! "${_db_port_}" ]; then
        _err_msg_="Could not read port number of ${_db_} from ${ENIQ_CONF_DIR}/${ENIQ_INI}"
        abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi
}

### Function: get_next_stage ###
#
# Get the stage to be run
#
# Arguments:
#   $1 : Stage to be set to. Either numeric value or 'done'
# Return Values:
#   none
get_next_stage()
{
ARRAY_ELEM=0

if [ -s $STAGEFILE ]; then

    NEXT_STAGE=`$CAT $STAGEFILE | $EGREP -v '^[[:blank:]]*#' | $SED -e 's| ||g'`

    if [ ! "${NEXT_STAGE}" ]; then
        _err_msg_="Failed to read stage from ${STAGEFILE}, exiting."
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi

    if [ "${NEXT_STAGE}" == "${STOP_STAGE}" ]; then
        return 0
    else
        $ECHO ${ENIQ_CORE_STAGES[*]} | $GREP -w ${NEXT_STAGE} >> /dev/null 2>&1
        if [ $? -ne 0 ]; then
            _err_msg_="Specified stage ${NEXT_STAGE} is not a valid stage"
            abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
        fi
    fi

    # Get the element number so we can move along the array
    get_array_element
else
    $MKDIR -p `$DIRNAME $STAGEFILE`
    if [ $? -ne 0 ]; then
        _err_msg_="Failed to create directory `$DIRNAME ${STAGEFILE}`, exiting."
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi

    NEXT_STAGE=${ENIQ_CORE_STAGES[${ARRAY_ELEM}]}
fi
}

### Function: get_storage_info ###
#
#   Copy Storage information to temporary file before zpool(s) are exported
#
# Arguments:
#   none 
# Return Values:
#   none
get_storage_info()
{
if [ "${STORAGE_TYPE}" == "raw" ]; then
    if [ ! -s ${ENIQ_CONF_DIR}/${SUNOS_INI} ]; then
        _err_msg_="Could not locate file ${ENIQ_CONF_DIR}/${SUNOS_INI}."
        abort_script "$_err_msg_"
    fi

    if [ ! -s ${ENIQ_CONF_DIR}/${BLK_STOR_INI} ]; then
        _err_msg_="Could not locate file ${ENIQ_CONF_DIR}/${BLK_STOR_INI}."
        abort_script "$_err_msg_"
    fi

    _file_list_="${ENIQ_CONF_DIR}/${SUNOS_INI}
    ${ENIQ_CONF_DIR}/${BLK_STOR_INI}
    ${MIGRATION_CONF}"
 
    for _file_ in ${_file_list_}; do
        if [ ! -s ${_file_} ]; then
            _err_msg_="Could not locate file ${_file_}."
            abort_script "$_err_msg_"
        fi
    done

    log_msg -s "\nCopying necessary storage and pool information into temporary file..." -l ${LOGFILE}
    _temp_storage_info_="${TEM_DIR}/temp_storage_info"
    $RM -rf ${_temp_storage_info_}
    log_msg -q -s "INFO: Storage information will be stored in ${_temp_storage_info_}" -l ${LOGFILE}
    $TOUCH ${_temp_storage_info_}
    if [ $? -ne 0 ]; then
    _err_msg_="Could not create ${_temp_storage_info_}"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi

    # Copy SAN device type (vnx/clariion) to temporary file
    _san_device_=`iniget SAN_DEV -f ${ENIQ_CONF_DIR}/${SUNOS_INI} -v SAN_DEVICE`
    if [ ! "${_san_device_}" ]; then
        _err_msg_="Could not read SAN_DEVICE value from ${SUNOS_INI}."
        abort_script "${_err_msg_}"
    fi
    $ECHO "SAN_DEVICE_TYPE=${_san_device_}" >> ${_temp_storage_info_} 
    log_msg -s "\nCopying SAN device type in ${_temp_storage_info_}" -l ${LOGFILE}
    
    # Determine number of storages
    log_msg -s "\nDetermining number of SAN connected" -l ${LOGFILE}
    _stor_count_=`iniget BLK_STORAGE_DEV_DETAILS -f ${ENIQ_CONF_DIR}/${BLK_STOR_INI} | $WC -l`
    if [ ${_stor_count_} -eq 0 ]; then
        _err_msg_="Unable to get connected SAN count from ${BLK_STOR_INI}."
        abort_script "${_err_msg_}"
    fi

    count=1
    while [ $count -le $_stor_count_ ]; do
        _spa_ip_=`iniget BLK_STORAGE_DEV_DETAILS_$count -f ${ENIQ_CONF_DIR}/${BLK_STOR_INI} -v BLK_STORAGE_IP_SPA`
        if [ ! "${_spa_ip_}" ]; then
            _err_msg_="Could not read BLK_STORAGE_IP_SPA value from ${BLK_STOR_INI}."
               abort_script "${_err_msg_}"
        fi
            
        _stor_grp_=`iniget BLK_STORAGE_DEV_DETAILS_$count -f ${ENIQ_CONF_DIR}/${BLK_STOR_INI} -v BLK_STORAGE_GROUP_NAME`
    if [ ! "${_stor_grp_}" ]; then
            _err_msg_="Could not read BLK_STORAGE_GROUP_NAME value from ${BLK_STOR_INI}."
            abort_script "${_err_msg_}"
        fi
        
        $ECHO "STORAGE_SPA_$count=${_spa_ip_}" >> ${_temp_storage_info_}
    log_msg -q -s "\nCopying STORAGE_SPA_$count in ${_temp_storage_info_}" -l ${LOGFILE}
        $ECHO "STORAGE_GROUP_$count=${_stor_grp_}" >> ${_temp_storage_info_}
        log_msg -q -s "Copying STORAGE_GROUP_$count in ${_temp_storage_info_}" -l ${LOGFILE}
        count=$((count+1))
     done
fi
}

### Function: get_update_server_netmask ###
#
# Get the server netmask info and update if necessary
#
# Arguments:
#   none
# Return Values:
#   none
get_update_server_netmask()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Start NetworkManager Service
$ECHO -e "Starting NetworkManager Service"

$SYSTEMCTL enable NetworkManager >> /dev/null 2>&1
if [ $? -ne 0 ]; then
    _err_msg_="Failed to enable NetworkManager Service"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

$SYSTEMCTL start NetworkManager
if [ $? -ne 0 ]; then
    _err_msg_="Failed to start NetworkManager Service"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

#Removing /etc/inet directory
if [ -s /etc/inet ]; then
     $RM -rf /etc/inet
     if [ $? -ne 0 ]; then
          _err_msg_="Could not remove /etc/inet directory"
          abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
     fi
fi

#Creating /etc/inet directory
$MKDIR -p /etc/inet
if [ $? -ne 0 ]; then
    _err_msg_="Could not create directory /etc/inet"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

# Removing symbolic link to /etc/inet/netmasks
if [ -L /etc/netmasks ]; then
     $RM -rf /etc/netmasks
     if [ $? -ne 0 ]; then
          _err_msg_="Could not remove /etc/netmasks Symbolic link"
          abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
     fi
fi

#Restoring netmasks file
if [ -s /etc/netmasks ]; then
    $MV /etc/netmasks /etc/inet/netmasks >> /dev/null 2>&1
    if [ $? -ne 0 ]; then
        _err_msg_="Could not rename file"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi
else
    if [ -s ${ENIQ_PORTBACKUP}/${HNAME}/ROOT/etc/netmasks ]; then
        $CP -p ${ENIQ_PORTBACKUP}/${HNAME}/ROOT/etc/netmasks /etc/inet/ >> /dev/null 2>&1
            if [ $? -ne 0 ]; then
            _err_msg_="Could not copy netmasks file to /etc/inet/"
            abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
        fi
        else
        _err_msg_="Required file is not present for restore"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
        fi
fi

# Creating symbolic link to /etc/inet/netmasks file
log_msg -s "\nCreating symbolic link to /etc/inet/netmasks file." -l ${LOGFILE}
$LN -s /etc/inet/netmasks /etc/netmasks
if [ $? -ne 0 ]; then
    _err_msg_="Failed to create symbolic link to /etc/inet/netmasks"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: host_disconnect ###
#
#   Disconnects the SAN
#
# Arguments:
#   none
# Return Values:
#   none
host_disconnect()
{
if [ "${STORAGE_TYPE}" == "raw" ]; then
    # Check temp_storage_data file exists with neccessary information
    log_msg -s "\nGetting required storage information." -l ${LOGFILE}
    if [ ! -s ${_temp_storage_info_} ]; then
        _err_msg_="Unable to get required storage information. ${_temp_storage_info_} file doesn't exists."
        abort_script "${_err_msg_}"
    fi
    
    _navisec_options_=""

    # Check storage device type (vnx/Unity) 
    _san_device_type_=`$CAT ${_temp_storage_info_} | $GREP "SAN_DEVICE_TYPE" | $CUT -d'=' -f2` 
    if [ ! ${_san_device_type_} ]; then
        _err_msg_="Unable to get SAN_DEVICE_TYPE information from ${_temp_storage_info_}"
        abort_script "${_err_msg_}"
    fi    

    # Check storage count
    _str_cnt_=`$CAT ${_temp_storage_info_} | $EGREP "^STORAGE_SPA_[1-9]=" | $WC -l`
     if [ ! ${_str_cnt_} ]; then
        _err_msg_="Unable to get the count of connected SAN from ${_temp_storage_info_}"
        abort_script "${_err_msg_}"
    fi    

    # Loop through the information and disconnect host from storage
    count=1
    while [ $count -le $_str_cnt_ ]; do
        # Get specific values from storage data file
        _str_spa_=`$CAT ${_temp_storage_info_} | $GREP "^STORAGE_SPA_$count=" | $CUT -d'=' -f2`
        if [ ! ${_str_spa_} ]; then
            _err_msg_="Unable to get the STORAGE_SPA_$count from ${_temp_storage_info_}"
            abort_script "${_err_msg_}"
        fi

        _str_grp_=`$CAT ${_temp_storage_info_} | $GREP "^STORAGE_GROUP_$count=" | $CUT -d'=' -f2`
        if [ ! ${_str_grp_} ]; then
            _err_msg_="Unable to get the STORAGE_GROUP_$count from ${_temp_storage_info_}"
            abort_script "${_err_msg_}"
        fi

        # Set options to pass to naviseccli command
        _navisec_options_="-h ${_str_spa_} -secfilepath ${ERICSSON_SAN_PLUGINS_DIR}/${_san_device_type_}/cred/ storagegroup -disconnecthost -host ${HNAME} -gname ${_str_grp_}"
        log_msg -s "Disconnecting Storage..." -l ${LOGFILE}
        log_msg -q -s "Executing the command:\n"  -l ${LOGFILE}
        # Run command to disconnect hosts
        $EXPECT <<EOF >>${LOGFILE} 2>&1
        set timeout 60
        spawn ${NAVISPHERE}/naviseccli ${_navisec_options_}
        expect {
        "Please input your selection" {send "2\r";exp_continue}
        "(y/n)" {send "y\r"}
        timeout {send_user "\nTIMEOUT!\n"; exit 9}
        }
        expect eof
EOF
#Please do not add any spaces before EOF 
        
        if [ $? -ne 0 ];then
            _err_msg_="Could not Disconnect Storage for $HNAME. Please disconnect the SAN manually."
            log_msg -s "Disconnecting Storage failed... Importing pools again" -l ${LOGFILE} 
            
            # Get current VG list from server
            _curr_pools_=`$VGS --no-headings -o name | $EGREP -v "${ROOT_POOL}"`

            # Import VGs
            $VGIMPORT ${_curr_pools_}
            if [ $? -ne 0 ];then
                _err_msg_="Could not import Volume Group ${_curr_pools_}."
                abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
            fi
            
            $VGCHANGE -ay ${_curr_pools_} >> /dev/null 2>&1
            if [ $? -ne 0 ];then
                _err_msg_="VGCHANGE of $_curr_pools_ is not done properly."
                abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
            fi
            _err_msg_="Rectify the issue and re-run the script again."
            abort_script "${_err_msg_}"
        else
            log_msg -s "\nSuccessfully disconnected SAN for $HNAME." -l ${LOGFILE}        
        fi
        count=`$EXPR $count + 1`
    done
    
fi
}

### Function: install_backup_sw ###
#
# Installs scripts into /eniq/bkup_sw
#
# Arguments:
#   none
# Return Values:
#   none
install_backup_sw()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling install_backup_sw stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s install_backup_sw ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - install_backup_sw"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: install_connectd_sw ###
#
# Installs scripts into /eniq/connectd
#
# Arguments:
#   none
# Return Values:
#   none
install_connectd_sw()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

# Ensuring that the NAS filesystem with backup data is mounted
mount_nas_fs

#Calling install_connectd_sw stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s install_connectd_sw ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - install_connectd_sw"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

# Restoring the configuration files from portbackup to eniq/connectd/mount_info directory
if [ "${CURR_SERVER_TYPE}" == "stats_engine" -o "${CURR_SERVER_TYPE}" == "eniq_stats" ]; then
      log_msg -t -s "Restoring configuration files at ${ENIQ_CONNECTD_DIR}/mount_info\n" -l ${LOGFILE}
      $CP -pr ${ENIQ_PORTBACKUP}/${HNAME}/ZFS/${ENIQ_CONNECTD_DIR}/mount_info/ ${ENIQ_CONNECTD_DIR}/
      if [ $? -ne 0 ]; then
           _err_msg_="Could not restore configuration files"
            abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
      fi
    log_msg -t -s "Successfully restored configuration files at ${ENIQ_CONNECTD_DIR}/\n" -l ${LOGFILE}
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}
set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: install_ENIQ_platform ###
#
# RUN ENIQ CLI PROGRAM
#
# Arguments:
#   none
# Return Values:
#   none
install_ENIQ_platform()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

# Skip stage if not CO server
if [ "${CO_SERVER}" != "YES" ]; then
    insert_header_footer foot "Skipping ${ACTION_TYPE} stage for ${CURR_SERVER_TYPE} - ${NEXT_STAGE} " ${LOGFILE}
    set_next_stage `$EXPR ${ARRAY_ELEM}+1`
    return 0
fi

# Removing content from PF and runtime directory
_dir_list_="${ENIQ_SW_PF_DIR} ${ENIQ_SW_RUNTIME_DIR}"

for _dir_ in `$ECHO ${_dir_list_}`; do
    log_msg -s "Cleaning up ${_dir_} directory content\n" -l ${LOGFILE}
    $RM -rf ${_dir_}/* >> /dev/null 2>&1
    if [ $? -ne 0 ]; then
        _err_msg_="Failed to remove ${_dir_} directory content"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi
done

# Truncating versiondb.properties of file
> ${ENIQ_SW_INSTALLER_DIR}/${VERSIONDB_PROPERTIES}
if [ -s "${ENIQ_SW_INSTALLER_DIR}/${VERSIONDB_PROPERTIES}" ]; then
    _err_msg_="Failed to truncate ${ENIQ_SW_INSTALLER_DIR}/${VERSIONDB_PROPERTIES} file"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

# Calling install_ENIQ_platform stage from eniq_core_install.bsh script
$BASH ${ENIQ_CORE_INST_SCRIPT} -s install_ENIQ_platform -u ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - install_ENIQ_platform"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

# Ensuring that the NAS filesystem with backup data is mounted
mount_nas_fs

#Restoring the configuration files from portbackup to eniq/sw/ directories
if [ -d ${ENIQ_PORTBACKUP}/${HNAME}/NAS/${DCUSER}/enmcertificate ] && [ -f ${ENIQ_PORTBACKUP}/${HNAME}/NAS/${ENIQ_SW_JDK_SEC_DIR}/truststore.ts ] && [ -d ${ENIQ_PORTBACKUP}/${HNAME}/NAS/${ENIQ_SW_RUNTIME_DIR}/apache-tomcat-*/ssl ]; then
    #Restoring the configuration files from portbackup to eniq/sw/runtime/jdk/jre/lib/security/truststore.ts file
    if [ "${CURR_SERVER_TYPE}" == "stats_coordinator" -o "${CURR_SERVER_TYPE}" == "eniq_stats" ]; then
        log_msg -t -s "Restoring configuration files at ${ENIQ_SW_JDK_SEC_DIR}\n" -l ${LOGFILE}
        if [ -f ${ENIQ_SW_JDK_SEC_DIR}/truststore.ts ] ; then
            log_msg -t -s "${ENIQ_SW_JDK_SEC_DIR}/truststore.ts already exist\n" -l ${LOGFILE}
        else
            $CP -p ${ENIQ_PORTBACKUP}/${HNAME}/NAS/${ENIQ_SW_JDK_SEC_DIR}/truststore.ts ${ENIQ_SW_JDK_SEC_DIR}
            if [ $? -ne 0 ]; then
                _err_msg_="Could not restore truststore.ts files"
                abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
            fi
            log_msg -t -s "Successfully restored configuration files at ${ENIQ_SW_JDK_SEC_DIR}\n" -l ${LOGFILE}
        fi

        log_msg -t -s "Restoring configuration files at ${ENIQ_SW_RUNTIME_DIR}/tomcat/\n" -l ${LOGFILE}
        $RM -rf ${ENIQ_SW_RUNTIME_DIR}/tomcat/ssl
        if [ $? -ne 0 ]; then
            _err_msg_="Could not remove ${ENIQ_SW_RUNTIME_DIR}/tomcat/ssl directories"
            abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
        fi

        $CP -pr ${ENIQ_PORTBACKUP}/${HNAME}/NAS/${ENIQ_SW_RUNTIME_DIR}/apache-tomcat-*/ssl ${ENIQ_SW_RUNTIME_DIR}/tomcat/
        if [ $? -ne 0 ]; then
            _err_msg_="Could not restore configuration files"
            abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
        fi
        log_msg -t -s "Successfully restored configuration files at ${ENIQ_SW_RUNTIME_DIR}/tomcat/\n" -l ${LOGFILE}
    fi
    
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: install_extra_fs ###
#
# Installs extra file systems if required
#
# Arguments:
#   none
# Return Values:
#   none
install_extra_fs()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling install_extra_fs stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s install_extra_fs ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - install_extra_fs"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

# Ensuring that the NAS filesystem with backup data is mounted
mount_nas_fs

if [ ! -f ${VAR_TMP_DIR}/local_logs_sucess ]; then
    #calculating size of local_logs in porbackup excluding files which are already copied during continue_eniq_migration
    _size_local_ext4_=`$DF -k ${ENIQ_LOG_DIR} |$AWK 'NR==2{print $4}'`
    _size_used_local_logs_=`$DU -sk ${ENIQ_LOG_DIR} |$AWK '{print $1}'`
    _size_local_port_=`$DU -sk ${ENIQ_PORTBACKUP}/${HNAME}/ZFS/${ENIQ_LOG_DIR} |$AWK '{print $1}'`
    _size_local_logs_port_exclude_=`$EXPR ${_size_local_port_} - ${_size_used_local_logs_}`

    #Copying all the directories of local_logs excluding the directories that are already copied during continue_eniq_migration
    if [ ${_size_local_logs_port_exclude_} -lt ${_size_local_ext4_} ]; then
        EXLUD_LOG_DIR="-e installation -e migration -e iq -e esm -e hostsync -e rolling_snapshot_logs -e connectd -e NASd -e snapshot_logs -e eniq_services_log -e replacement -e sw_log"
        _log_dir_=`$LS ${ENIQ_PORTBACKUP}/${HNAME}/ZFS/${ENIQ_LOG_DIR} |$GREP -vw ${EXLUD_LOG_DIR}`
            for _dir_ in `$ECHO ${_log_dir_}`; do
                if [ -d ${ENIQ_PORTBACKUP}/${HNAME}/ZFS/${ENIQ_LOG_DIR}/${_dir_} ] || [ -f ${ENIQ_PORTBACKUP}/${HNAME}/ZFS/${ENIQ_LOG_DIR}/${_dir_} ]; then
                    log_msg -s "\nCopying ${ENIQ_LOG_DIR}/${_dir_} fro NAS backup" -l ${LOGFILE}
                    $CP -pr ${ENIQ_PORTBACKUP}/${HNAME}/ZFS/${ENIQ_LOG_DIR}/${_dir_} ${ENIQ_LOG_DIR}
                    if [ $? -ne 0 ]; then
                        _err_msg_="unable to copy ${_dir_}"
                        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
                    fi
                fi
            done
    else
        log_msg -s "\nWARNING:Sufficient space is not available on the file system. Unable to copy some of the directories of local_logs from portbackup." -l ${LOGFILE}
    fi
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: insert_header_footer ###
#
#   Insert a stage header/footer message
#
# Arguments:
#   $1 : head/foot
#   $2 : Message
#   $3 : Logfile
# Return Values:
#   none
insert_header_footer()
{
if [ $# -ne 3 ]; then
    _err_msg_="3 Parameters must be passed to header/footer function"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

if [ "$1" != "head" -a "$1" != "foot" ]; then
    _err_msg_="Only Param of head/foot is allowed...exiting!"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi
_type_=$1

_msg_=$2

_logfile_=$3
$MKDIR -p `$DIRNAME ${_logfile_}`
if [ $? -ne 0 ]; then
    _err_msg_="Could not create directory `$DIRNAME ${_logfile_}`"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

$TOUCH -a ${_logfile_}
if [ $? -ne 0 ]; then
    _err_msg_="Could not write to file ${_logfile_}"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

_time_=`$DATE '+%Y-%b-%d_%H.%M.%S'`
if [ "$_type_" == "head" ]; then
    $ECHO "\n=====================================================" | $TEE -a ${_logfile_}
    $ECHO "-----------------------------------------------------" | $TEE -a ${_logfile_}
    $ECHO "$_time_ : $_msg_" | $TEE -a ${_logfile_}
    $ECHO "-----------------------------------------------------" | $TEE -a ${_logfile_}
fi

if [ "$_type_" == "foot" ]; then
    $ECHO "\n-----------------------------------------------------" | $TEE -a ${_logfile_}
    $ECHO "$_time_ : $_msg_" | $TEE -a ${_logfile_}
    $ECHO "-----------------------------------------------------" | $TEE -a ${_logfile_}
    $ECHO "=====================================================\n" | $TEE -a ${_logfile_}
fi
}

### Function: install_host_syncd ###
#
# Install the service and daemon to sync hosts file
#
# Arguments:
#   none
# Return Values:
#   none
#
install_host_syncd()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling install_host_syncd stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s install_host_syncd ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - install_host_syncd"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}
set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: install_nasd ###
#
# Install the nas daemon
#
# Arguments:
#   none
# Return Values:
#   none
#
install_nasd()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling install_nasd stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s install_nasd ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - install_nasd"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: install_nas_sw ###
#
# Install NAS software
#
# Arguments:
#   none
# Return Values:
#   none
install_nas_sw()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling install_nas_sw stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s install_nas_sw ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - install_nas_sw"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

if [ "${STORAGE_TYPE}" == "raw" ]; then
storadm_pass=`$CAT ${ENIQ_CONF_DIR}/ssh_input_file | $GREP -w L_PW_A | $AWK -F= '{print $2}'`    
if [ "${storadm_pass}" != "\$SAPASSWD" ]; then
    master_pass=`$CAT ${ENIQ_CONF_DIR}/ssh_input_file | $GREP -w R_PW_M | $AWK -F= '{print $2}' | $AWK -F\" '{print $2}'`  
    support_pass=`$CAT ${ENIQ_CONF_DIR}/ssh_input_file | $GREP -w R_PW_S | $AWK -F= '{print $2}' | $AWK -F\" '{print $2}'`  
    if [ ! "${master_pass}" -a ! "${support_pass}" ]; then
        _err_msg_="Password in File ${ENIQ_CONF_DIR}/ssh_input_file not found"
        abort_script "$_err_msg_"
    fi
    # Updating the source_file with master and support passwords
    $EGREP  "${master_pass}|${support_pass}" ${source_file} >> /dev/null 2>&1
    if [ $? -ne 0 ]; then
        $ECHO "Updating ${source_file} with NAS passwords" >> ${LOGFILE}
        # Taking backup of the source file
        $CP ${source_file} ${source_file}_backup
        if [ $? -ne 0 ]; then
            _err_msg_="Could not backup file ${source_file}"
            abort_script "$_err_msg_"
        fi

        $ECHO "Updating ${source_file} with MASTER user password" >> ${LOGFILE}
        $ECHO "export MPASSWD='${master_pass}'" >> ${source_file}
        if [ $? -ne 0 ]; then
            _err_msg_="Could not write master password to the file ${source_file}"
            #Reverting back to original source file
            $MV ${source_file}_backup ${source_file}
            abort_script "$_err_msg_"
        fi
        $ECHO "Updating ${source_file} with SUPPORT user password" >> ${LOGFILE}
        $ECHO "export SPASSWD='${support_pass}'" >> ${source_file}
        if [ $? -ne 0 ]; then
            _err_msg_="Could not write support password to the file ${source_file}"
            #Reverting back to original source file
            $MV ${source_file}_backup ${source_file}
            abort_script "$_err_msg_"
        fi
    fi


    if [  -s ${ENIQ_CONF_DIR}/ssh_input_file ]; then
         $RM -rf ${ENIQ_CONF_DIR}/ssh_input_file
        if [ $? -ne 0 ]; then
            _err_msg_="Failed to delete ${ENIQ_CONF_DIR}/ssh_input_file}"
            abort_script "$_err_msg_"
        fi
        $CP ${NEW_TEMPL_DIR}/ssh_input_file ${ENIQ_CONF_DIR}
        if [ $? -ne 0 ]; then
            _err_msg_="Failed to copy ${NEW_TEMPL_DIR}/ssh_input_file to ${ENIQ_CONF_DIR}"
            abort_script "$_err_msg_"
        fi
        
    fi
fi
fi

# Delete sourcefile_backup if exist
if [ -f ${source_file}_backup ]; then
    $RM -rf ${source_file}_backup 
    if [ $? -ne 0 ]; then
        _err_msg_="Failed to delete ${source_file}_backup"
        abort_script "$_err_msg_"
    fi
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: install_parser ###
#
# Install parsers
#
# Arguments:
#   none
# Return Values:
#   none
#
install_parser()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

# Skip stage if not CO server
if [ "${CO_SERVER}" != "YES" ]; then
    insert_header_footer foot "Skipping ${ACTION_TYPE} stage for ${CURR_SERVER_TYPE} - ${NEXT_STAGE} " ${LOGFILE}
    set_next_stage `$EXPR ${ARRAY_ELEM}+1`
    return 0
fi

# Get feature sw location
MIG_FEAT_SW_LOC=`read_value MIG_FEAT_SW_LOC ${MIGRATION_CONF}` || abort_script "${MIG_FEAT_SW_LOC}" "${EXEC_SHELL_CMD}"

# Getting sysuser from SunOS.ini file
SYSUSER=`iniget ENIQ_INSTALL_CONFIG -f ${ENIQ_CONF_DIR}/${SUNOS_INI} -v ENIQ_SYSUSER`
if [ ! "${SYSUSER}" ]; then
    _err_msg_="Could not read parameter ENIQ_SYSUSER from ${ENIQ_CONF_DIR}/${SUNOS_INI} file"
    abort_script "${_err_msg_}"
fi

_eniq_parser_src_dir_=`iniget ENIQ_CLI -f ${ENIQ_CONF_DIR}/${SUNOS_INI} -v ENIQ_PARSERS_DIR`
_eniq_parser_inst_prog_=`iniget ENIQ_CLI -f ${ENIQ_CONF_DIR}/${SUNOS_INI} -v ENIQ_PARSERS_INST_PROG`

# Install ENIQ parsers if eniq_parsers and install_parsers.bsh exist
if [ -d "${MIG_FEAT_SW_LOC}/${_eniq_parser_src_dir_}" -a -x "${ENIQ_SW_INSTALLER_DIR}/${_eniq_parser_inst_prog_}" ]; then

    log_msg -l ${LOGFILE} -s "\nInstalling parsers using command"
 
    log_msg -l ${LOGFILE} -s "${SU} - ${SYSUSER} -c \"${BASH} ${ENIQ_SW_INSTALLER_DIR}/${_eniq_parser_inst_prog_} ${MIG_FEAT_SW_LOC}/${_eniq_parser_src_dir_}\""
    ${SU} - ${SYSUSER} -c "${BASH} ${ENIQ_SW_INSTALLER_DIR}/${_eniq_parser_inst_prog_} ${MIG_FEAT_SW_LOC}/${_eniq_parser_src_dir_}"
    if [ $? -ne 0 ]; then
        _err_msg_="Failed to install parsers"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    else
        log_msg -l ${LOGFILE} -s "\nParsers installed successfully" 
    fi 
fi

# Creating no_features flag to copy latest feature files
$TOUCH ${NO_FEATURE_SELECTED}
if [ $? -ne 0 ]; then
    _err_msg_="Failed to create ${NO_FEATURE_SELECTED} file." 
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

local _check_command_="${ENIQ_ADMIN_BIN_DIR}/manage_features.bsh"
check_for_file -s ${_check_command_}

log_msg -l ${LOGFILE} -s "\nCopying latest ENIQ feature files"
    
$BASH ${ENIQ_ADMIN_BIN_DIR}/manage_features.bsh -a update -d ${MIG_FEAT_SW_LOC}
if [ $? -ne 0 ]; then
    _err_msg_="Failed to copy latest feature files. \n"

    # Removing no feature selected flag
    $RM -rf ${NO_FEATURE_SELECTED}

    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
else
    log_msg -s "\nSuccessfully copied latest ENIQ feature files" -l ${LOGFILE}
    # Removing no feature selected flag
    $RM -rf ${NO_FEATURE_SELECTED}
fi

# Ensuring that the NAS filesystem with backup data is mounted
mount_nas_fs

#Restoring /eniq/data/mapping/ossidMapping.txt
if [ -f ${ENIQ_PORTBACKUP}/${HNAME}/ROOT/${ENIQ_DATA_MAPPING_DIR}/ossidMapping.txt ]; then
    log_msg -s "\nCopying ${ENIQ_DATA_MAPPING_DIR} from NAS Backup " -l ${LOGFILE}
    $CP -pr ${ENIQ_PORTBACKUP}/${HNAME}/ROOT/${ENIQ_DATA_MAPPING_DIR} ${ENIQ_DATA_DIR}
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: install_rolling_snapshot ###
#
# Create installation filesystem/rolling snapshots
#
# Arguments:
#   none
# Return Values:
#   none
install_rolling_snapshot()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling install_rolling_snapshot stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s install_rolling_snapshot ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - install_rolling_snapshot"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: install_san_sw ###
#
# Install EMC SW
#
# Arguments:
#   none
# Return Values:
#   none
install_san_sw()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling install_san_sw stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s install_san_sw  ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - install_san_sw"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: install_sap_asa_binaries ###
#
# Installs the SAP ASA binaries
#
# Arguments:
#   none
# Return Values:
#   none
install_sap_asa_binaries()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

if [ "${CURR_SERVER_TYPE}" == "stats_coordinator" -o "${CURR_SERVER_TYPE}" == "eniq_stats" ]; then

     # NAS service should be online
     log_msg -t -s "Checking if NASd is online before proceeding further\n" -l ${LOGFILE}
     check_nasd_milestone_online ${ENIQ_CONF_DIR} ${SUNOS_INI} ${ENIQ_BASE_DIR}
     if [ $? -ne 0 ]; then
         _err_msg_="NASd not in a correct state to continue"
         abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
     fi

     #Calling install_sybase_asa stage from eniq_core_install.bsh
     log_msg -t -s "Installing SQL Anywhere binaries from the software bundle." -l ${LOGFILE}
     $BASH ${ENIQ_CORE_INST_SCRIPT} -s install_sybase_asa -u ${ENIQ_CORE_INST_ARG} >> ${LOGFILE}
     if [ $? -ne 0 ]; then
         _err_msg_="Failed in ${ACTION_TYPE} stage - install_sap_asa_binaries"
         abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
     fi
else
    insert_header_footer foot "Skipping ${ACTION_TYPE} stage - ${NEXT_STAGE} for ${CURR_SERVER_TYPE} " ${LOGFILE}
    set_next_stage `$EXPR ${ARRAY_ELEM}+1`
    return 0
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: install_sap_iq_binaries ###
#
# Installs the SAP IQ binaries
#
# Arguments:
#   none
# Return Values:
#   none
install_sap_iq_binaries()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

if [ "${CURR_SERVER_TYPE}" == "stats_coordinator" -o "${CURR_SERVER_TYPE}" == "eniq_stats" ]; then

     # NAS service should be online
     log_msg -t -s "Checking if NASd is online before proceeding further\n" -l ${LOGFILE}
     check_nasd_milestone_online ${ENIQ_CONF_DIR} ${SUNOS_INI} ${ENIQ_BASE_DIR}
     if [ $? -ne 0 ]; then
         _err_msg_="NASd not in a correct state to continue"
         abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
     fi

     SYBIQ_TGT_DIR=`iniget SYBASE_IQ -f ${ENIQ_CONF_DIR}/${SUNOS_INI} -v SYBASE_IQ_TARGET_DIR`
     if [ ! "${SYBIQ_TGT_DIR}" ]; then
         _err_msg_="Could not read SYBASE_IQ_TARGET_DIR parameter from ${ENIQ_CONF_DIR}/${SUNOS_INI}"
         abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
     fi

     # Backup the interface file
     if [ -s ${SYBIQ_TGT_DIR}/interfaces ]; then
         log_msg -t -s "Backing up the SAP IQ interfaces file" -l ${LOGFILE}
         $CP -p ${SYBIQ_TGT_DIR}/interfaces ${TEM_DIR}/interfaces
         if [ $? -ne 0 ]; then
             _err_msg_="Failed to backup file ${SYBIQ_TGT_DIR}/interfaces"
             abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
         fi
     else
         log_msg -t -s "No SAP IQ interfaces file found to backup" -l ${LOGFILE}
     fi

     #Calling install_sybaseiq stage from eniq_core_install.bsh
     log_msg -t -s "Installing SAP IQ binaries from the software bundle." -l ${LOGFILE}
     $BASH ${ENIQ_CORE_INST_SCRIPT} -s install_sybaseiq -u ${ENIQ_CORE_INST_ARG} >> ${LOGFILE}
     if [ $? -ne 0 ]; then
         _err_msg_="Failed in ${ACTION_TYPE} stage - install_sap_iq_binaries"
         abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
     fi

     # Restore the SAP IQ interfaces file
     if [ -s ${TEM_DIR}/interfaces ];then
         log_msg -t -s "Restoring the SAP IQ interfaces file" -l ${LOGFILE} 
         $ECHO ""
         $CP ${TEM_DIR}/interfaces ${SYBIQ_TGT_DIR}/interfaces
         if [ $? -ne 0 ]; then
             _err_msg_="Failed to restore file ${TEM_DIR}/interfaces"
             abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
         fi
     fi
else
     insert_header_footer foot "Skipping ${ACTION_TYPE} stage - ${NEXT_STAGE} for ${CURR_SERVER_TYPE} " ${LOGFILE}
     set_next_stage `$EXPR ${ARRAY_ELEM}+1`
     return 0
fi
insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: install_storage_api ###
#
# Install Storage API
#
# Arguments:
#   none
# Return Values:
#   none
install_storage_api()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling install_storage_api stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s install_storage_api ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - install_storage_api"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: install_service_scripts ###
#
# Installs scripts into /eniq/smf
#
# Arguments:
#   none
# Return Values:
#   none
install_service_scripts()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling install_service_scripts stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s install_service_scripts ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - install_service_scripts"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: lock_unlock_user_iq_db ###
#
#   This function (un)locks user in iq.
#   
# Arguments:
#           $1 = IQ Database DBA password
#           $2 = IQ Database port 
#           $3 = IQ Database User (dc,dcbo,dcpublic)
#           $4 = Action (lock/unlock)
#
# Return Values: none
lock_unlock_user_iq_db()
{
local _dba_pass_=$1
local _db_port_=$2
local user=$3
local action=$4

$SU - $SYSUSER -c "$DBISQL -nogui @${conn_str_db_enc} \"set temporary option ON_ERROR='EXIT'; CALL sp_iqlocklogin('${user}','${action}')\""
if [ $? -ne 0 ]; then
    _err_msg_="Issue ${action}ing ${user} in the ${_db_}"
    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi
}

### Function: merge_config_files ###
#
# To merge config files
#
# Arguments:
#   none
# Return Values:
#   none
#
merge_config_files()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

CONFIG_FILE_LIST=(SunOS.ini:Y niq.ini:N niq.rc:N storage.ini:N RBAC.ini:Y ipmp.ini:Y)
TEMPLATE_FILE_LIST=(${SUNOS_INI_TEMPLATE} ${NIQ_INI_TEMPLATE} ${NIQ_RC_TEMPLATE} ${STORAGE_INI_TEMPLATE} ${RBAC_INI_TEMPLATE} ${IPMP_INI_TEMPLATE})

if [ -x ${ENIQ_CORE_INST_DIR}/lib/iniadd.pl ]; then
    INIADD=${ENIQ_CORE_INST_DIR}/lib/iniadd.pl
else
    _err_msg_="${ENIQ_CORE_INST_DIR}/lib/iniadd.pl is not found, or is not executable"
    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

_nas_sw_mount_=0

_nfs_host_=`iniget Storage_NAS_SW -f ${ENIQ_CONF_DIR}/storage.ini -v NFS_HOST`
_share_path_=`iniget Storage_NAS_SW -f ${ENIQ_CONF_DIR}/storage.ini -v SHARE_PATH`
_mount_path_=`iniget Storage_NAS_SW -f ${ENIQ_CONF_DIR}/storage.ini -v MOUNT_PATH`

#Ensuring that the NAS filesystem with backup data is mounted
mount_nas_fs

# Ensuring that the ENIQ NAS Software filesystem is mounted
log_msg -t -s "Ensuring that the ENIQ NAS Software filesystem is mounted before proceeding further" -l ${LOGFILE}

# Create the mount point if its not there
if [ ! -d ${_mount_path_} ]; then
    log_msg -s "\nCreating mount point - ${_mount_path_}" -l ${LOGFILE}
    $MKDIR -p ${_mount_path_} >> /dev/null 2>&1
    if [ $? -ne 0 ]; then
        _err_msg_="Could not create mount point ${_mount_path_}"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi
fi

_mount_exists_=`$MOUNT | $GREP "${_mount_path_}" | $AWK '{print $1}'`
if [ ! "${_mount_exists_}" ]; then
     _nas_sw_mount_=1
fi

if [ ${_nas_sw_mount_} -eq 1 ]; then
    log_msg -s "Mounting ${_nfs_host_}:${_share_path_} on ${_mount_path_}" -l ${LOGFILE}
    $MOUNT -t nfs ${_nfs_host_}:${_share_path_} ${_mount_path_} >> /dev/null 2>&1
    if [ $? -ne 0 ]; then
        _err_msg_="Could not mount ${_nfs_host_}:${_share_path_} on ${_mount_path_}"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    else
        log_msg -s "\nSuccessfully mounted ${ENIQ_PORTBACKUP}"
    fi
else
    log_msg -s "${_mount_path_} is already mounted" -l ${LOGFILE}
fi


for ((i=0;i<${#CONFIG_FILE_LIST[@]};++i)); do
   
    _merge_flag_=`$ECHO ${CONFIG_FILE_LIST[i]}|$CUT -d: -f2`
    _config_file_=`$ECHO ${CONFIG_FILE_LIST[i]}|$CUT -d: -f1`
     
    if [ -s ${ENIQ_CONF_DIR}/${_config_file_} ]; then
         log_msg -l ${LOGFILE} -s "Creating backup of the ${ENIQ_CONF_DIR}/${_config_file_} file"
         $CP -pf ${ENIQ_CONF_DIR}/${_config_file_} ${ENIQ_CONF_DIR}/${_config_file_}_${TIMESTAMP}
         if [ $? -ne 0 ]; then
               _err_msg_="Could not backup the ${ENIQ_CONF_DIR}/${_config_file_} file."
               abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
         fi
    fi

    if [ -s ${CLI_CONF_DIR}/${_config_file_} ]; then
         log_msg -l ${LOGFILE} -s "Creating backup of the ${CLI_CONF_DIR}/${_config_file_} file"
         $CP -pf ${CLI_CONF_DIR}/${_config_file_} ${CLI_CONF_DIR}/${_config_file_}_${TIMESTAMP}
         if [ $? -ne 0 ]; then
               _err_msg_="Could not backup the ${CLI_CONF_DIR}/${_config_file_} file."
               abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
         fi
    fi

    log_msg -l ${LOGFILE} -s "Creating temporary copy of ${INI_TEMPLATE_DIR}/${TEMPLATE_FILE_LIST[i]} in ${TEM_DIR}"
    $CP ${INI_TEMPLATE_DIR}/${TEMPLATE_FILE_LIST[i]} ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}
    if [ $? -ne 0 ]; then
          _err_msg_="Could not create temporary copy of ${TEMPLATE_FILE_LIST[i]}"
          abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
    fi

    NEW_TEMPLATE_INI_FILE="${TEMPLATE_FILE_LIST[i]}" 
    log_msg -l ${LOGFILE} -s "Creating temporary copy of ${INI_TEMPLATE_DIR}/${NEW_TEMPLATE_INI_FILE} in ${TEM_DIR}"
    $CP ${INI_TEMPLATE_DIR}/${NEW_TEMPLATE_INI_FILE} ${TEM_DIR}/${NEW_TEMPLATE_INI_FILE}_new
    if [ $? -ne 0 ]; then
          _err_msg_="Could not create temporary copy of ${NEW_TEMPLATE_INI_FILE}"
          abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
    fi

    $GREP "<CHANGE><UNIQUE_POOL>" ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} >> /dev/null 2>&1
    if [ $? -eq 0 ]; then
         log_msg -l ${LOGFILE} -s "Setting unique pool name in ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}"
         $SED -i "s/<CHANGE><UNIQUE_POOL>/${UNIQUE_POOL_NAME}/g" ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} 
         if [ $? -ne 0 ]; then
              _err_msg_="Could not set unique pool name in the ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} file."
              abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
         fi 
    fi

    $GREP "<CHANGE><ENIQ_BASE_DIR>" ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} >> /dev/null 2>&1
    if [ $? -eq 0 ]; then
         log_msg -l ${LOGFILE} -s "Setting the ENIQ base directory in ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}"
         $SED -i "s/<CHANGE><ENIQ_BASE_DIR>/\/eniq/g" ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}
         if [ $? -ne 0 ]; then
              _err_msg_="Could not set the ENIQ base directory in the ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} file."
              abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
         fi
    fi

    $GREP -w "<CHANGE><ENIQ_POOL_ID>\|<CHANGE><ENIQ_SEC_POOL_ID>" ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} >> /dev/null 2>&1
    if [ $? -eq 0 ]; then
         NAS_POOL_ID=`iniget Storage_NAS_GENERAL -f ${ENIQ_CONF_DIR}/${_config_file_} -v SYS_ID` 
         log_msg -l ${LOGFILE} -s "Setting the ENIQ Pool ID in ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}"
         $CAT ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} | $SED -e "s|<CHANGE><ENIQ_POOL_ID>|${NAS_POOL_ID}|g" \
                                                                              -e "s|<CHANGE><ENIQ_SEC_POOL_ID>|${NAS_POOL_ID}|g" > ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}.$$.$$
        if [ $? -ne 0 ]; then
            _err_msg_="Could not set the ENIQ Pool ID in ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}.$$.$$"
            abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
        fi

        $CP ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}.$$.$$ ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}
        if [ $? -ne 0 ]; then
             _err_msg_="Could not copy ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}.$$.$$ to ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}"
             abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
        fi
    fi

    if [ ${_merge_flag_} == "Y" ]; then
         log_msg -l ${LOGFILE} -s "Getting the block list from ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}"
         $CAT ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}|$GREP '^\['|$CUT -d"[" -f2|$CUT -d"]" -f1 > ${TEM_DIR}/block_list
         if [ ! -s ${TEM_DIR}/block_list ]; then
               _err_msg_="Could not get list of blocks from ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}"
               abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
         fi

        for _block_ in `$CAT ${TEM_DIR}/block_list`
        do
            iniget ${_block_} -f ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} > ${TEM_DIR}/parameter_list
            for _param_ in `$CAT ${TEM_DIR}/parameter_list|$AWK -F"=" '{print $1}'`
            do
                     _param_value_=`iniget ${_block_} -f ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} -v ${_param_}`
                     if [ -z "${_param_value_}" -o "${_config_file_}" == "niq.ini" ]; then
                          _sol_param_value_=`iniget ${_block_} -f ${ENIQ_CONF_DIR}/${_config_file_} -v ${_param_}`
                          if [ ! -z "${_sol_param_value_}" ]; then
                               iniset ${_block_} -f ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} ${_param_}="${_sol_param_value_}"
                               if [ $? -ne 0 ]; then
                                    _err_msg_="Could not set the required parameter ${_sol_param_value_} in the ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} file."
                                    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
                               fi
                          fi
                     fi
           done
       done
    fi

    if [ "${_config_file_}" == "niq.ini" ]; then
         update_niq_ini
    fi

    # Migrating storage.ini or SunOS.ini in case FLS is enabled for any ENM
    if [ "${_config_file_}" == "storage.ini" -o "${_config_file_}" == "SunOS.ini" ]; then
         _config_=`$ECHO ${_config_file_} | $CUT -d"." -f1`
         if [ "${STORAGE_TYPE}" == "raw" ]; then
             if [ -s "${FLS_CONFIG_FILE}" ];then
                 $CAT ${FLS_CONFIG_FILE} > ${TEM_DIR}/merge_input_file
             fi
         
             if [ -s "${TEM_DIR}/merge_input_file" ];then
                  while read _line_; do
                      _item_="${_line_}"
                      log_msg -l ${LOGFILE} -s "Merging existing block for ${_line_} in ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}"
                      merge_ini ${_line_} ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} ${ENIQ_CONF_DIR}/${_config_file_} ${_config_}
                      if [ "${_config_file_}" == "SunOS.ini" ]; then
                           merge_ini ${_line_} ${TEM_DIR}/${NEW_TEMPLATE_INI_FILE}_new ${ENIQ_PORTBACKUP}/${HNAME}/ZFS/${INI_TEMPLATE_DIR}/${OLD_SUNOS_INI_TEMPLATE} ${_config_}
                      else
                           merge_ini ${_line_} ${TEM_DIR}/${NEW_TEMPLATE_INI_FILE}_new ${ENIQ_PORTBACKUP}/${HNAME}/ZFS/${INI_TEMPLATE_DIR}/${OLD_STORAGE_INI_TEMPLATE} ${_config_} 
                      fi
                  done < ${TEM_DIR}/merge_input_file
             fi
         fi
    fi

    # Updating ipmp.ini with required interface information
    if [ "${_config_file_}" == "ipmp.ini" ]; then
          update_ipmp_ini
    fi

    # Updating config file at /eniq/installation/config
    if [ "${_config_file_}" != "niq.ini" ]; then
         if [ -s ${ENIQ_CONF_DIR}/${_config_file_} ]; then
              log_msg -l ${LOGFILE} -s "Merging content of ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} in ${ENIQ_CONF_DIR}/${_config_file_}"
              $CP -pf ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} ${ENIQ_CONF_DIR}/${_config_file_}
              if [ $? -ne 0 ]; then
                    log_msg -l ${LOGFILE} -s "Restoring ${ENIQ_CONF_DIR}/${_config_file_} from backup ${ENIQ_CONF_DIR}/${_config_file_}_${TIMESTAMP}"
                    $MV ${ENIQ_CONF_DIR}/${_config_file_}_${TIMESTAMP} ${ENIQ_CONF_DIR}/${_config_file_}
                    _err_msg_="Could not merge content of ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} in ${ENIQ_CONF_DIR}/${_config_file_}"
                    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
              else
                    $RM -f ${ENIQ_CONF_DIR}/${_config_file_}_${TIMESTAMP}
              fi
         fi

         # Updating config file at /eniq/sw/conf
         if [ -s ${CLI_CONF_DIR}/${_config_file_} ]; then
              log_msg -l ${LOGFILE} -s "Merging content of ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} in ${CLI_CONF_DIR}/${_config_file_}\n"
              $CP -pf ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} ${CLI_CONF_DIR}/${_config_file_}
              if [ $? -ne 0 ]; then
                    log_msg -l ${LOGFILE} -s "Restoring ${CLI_CONF_DIR}/${_config_file_} from backup ${CLI_CONF_DIR}/${_config_file_}_${TIMESTAMP}"
                    $MV ${CLI_CONF_DIR}/${_config_file_}_${TIMESTAMP} ${CLI_CONF_DIR}/${_config_file_}
                    _err_msg_="Could not merge content of ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} in ${CLI_CONF_DIR}/${_config_file_}"
                    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
              else
                    $RM -f ${CLI_CONF_DIR}/${_config_file_}_${TIMESTAMP}
              fi
         fi

         if [ -s ${TEM_DIR}/${NEW_TEMPLATE_INI_FILE}_new ]; then
              log_msg -l ${LOGFILE} -s "Merging content of ${TEM_DIR}/${NEW_TEMPLATE_INI_FILE}_new in ${INI_TEMPLATE_DIR}/${TEMPLATE_FILE_LIST[i]}\n"
              $CP -pf ${TEM_DIR}/${NEW_TEMPLATE_INI_FILE}_new ${INI_TEMPLATE_DIR}/${TEMPLATE_FILE_LIST[i]} 
              if [ $? -ne 0 ]; then
                    _err_msg_="Could not merge content of ${TEM_DIR}/${NEW_TEMPLATE_INI_FILE}_new in ${INI_TEMPLATE_DIR}/${TEMPLATE_FILE_LIST[i]}"
                    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
              fi
         else
              _err_msg_="${TEM_DIR}/${NEW_TEMPLATE_INI_FILE}_new file not found"
              abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
         fi
    fi

done

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}


### Function: merge_ini_block ###
#
# Merging the extra filesystem and directory in Sunos.ini file.
#
# Arguments:
#   none
# Return Values:
#   none
merge_ini_block()
{
$ECHO "[${ptag}]" > ${TEM_DIR}/new_ini_block
iniget $old_tag -f ${old_template_ini} >> ${TEM_DIR}/new_ini_block
if [ $? -ne 0 ]; then
        _err_msg_="Failed to get $old_tag from ${old_template_ini}"
        abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

log_msg -l ${LOGFILE} -q -s "Executing command: \n$INIADD -g $gtag -p $ptag -i ${new_template_ini} -d ${TEM_DIR}/new_ini_block -o ${TEM_DIR}/output_file"
$INIADD -g $gtag -p $ptag -i ${new_template_ini} -d ${TEM_DIR}/new_ini_block -o ${TEM_DIR}/output_file
if [ $? -ne 0 ]; then
        _err_msg_="Error in migrating block ${_item_} from ${old_template_ini}"
        abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

$CP ${TEM_DIR}/output_file ${new_template_ini}
if [ $? -ne 0 ]; then
         _err_msg_="Failed to migrate ${old_template_ini}"
         abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi
$RM -rf ${TEM_DIR}/output_file
log_msg -l ${LOGFILE} -s "Successfully migrated block ${_item_} to ${new_template_ini}."

}

### Function: merge_ini ###
#
# Merging the extra filesystem and directory in Sunos.ini and storage.ini file
#
# Arguments: none
#
# Return Values: none
merge_ini()
{
new_fs_name=$1
new_template_ini=$2
old_template_ini=$3
ini_type=$4

if [ "${ini_type}" == "SunOS" ];then
      if [ "${STORAGE_TYPE}" == "fs" ];then
           old_tag=`$CAT ${old_template_ini} | $EGREP -B1 $new_fs_name |$HEAD -1 |$TR -d "[" |$TR -d "]"`
           _last_used_=`$CAT ${new_template_ini} |$GREP SunOS_ZFS_FS_ |$GREP -v "\[*\]" | $TAIL -1 |$SED 's/[^0-9]*//g'`
           ((_last_used_++))
           gtag="SunOS_ZFS_FS"
           ptag="SunOS_ZFS_FS_${_last_used_}"
           merge_ini_block

           # Adding directory block
           old_tag=`$CAT ${old_template_ini} | $EGREP -B1 $new_fs_name |$GREP SunOS_DIRECTORY_DIR_ | $HEAD -1 |$TR -d "[" |$TR -d "]"`
           _last_used_=`$CAT ${new_template_ini} |$GREP SunOS_DIRECTORY_DIR_ |$GREP -v "\[*\]" | $TAIL -1 |$SED 's/[^0-9]*//g'`
           ((_last_used_++))
           gtag="SunOS_DIRECTORY"
           ptag="SunOS_DIRECTORY_DIR_${_last_used_}"
           merge_ini_block
      
      elif  [ "${STORAGE_TYPE}" == "raw" ];then
              old_tag=`$CAT ${old_template_ini} | $EGREP -B1 $new_fs_name |$HEAD -1 |$TR -d "[" |$TR -d "]"`
              _last_used_=`$CAT ${new_template_ini} |$GREP SunOS_DIRECTORY_DIR_ |$GREP -v "\[*\]" | $TAIL -1 |$SED 's/[^0-9]*//g'`
              ((_last_used_++))
              gtag="SunOS_DIRECTORY"
              ptag="SunOS_DIRECTORY_DIR_${_last_used_}"
              merge_ini_block
      fi

elif [ "${ini_type}" == "storage" ];then

        gtag=Storage_NAS_FS_LIST
        ptag=Storage_NAS_`$ECHO $new_fs_name |$TR "[:lower:]" "[:upper:]" `

        $ECHO "[${ptag}]" > ${TEM_DIR}/new_ini_block
        iniget $ptag -f ${old_template_ini} >> ${TEM_DIR}/new_ini_block
        if [ $? -ne 0 ]; then
                _err_msg_="Failed to get $ptag from ${old_template_ini}"
                abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
        fi

        log_msg -l ${LOGFILE} -q -s "Executing command: \n$INIADD -g $gtag -p $ptag -i ${new_template_ini} -d ${TEM_DIR}/new_ini_block -o ${TEM_DIR}/output_file"
        $INIADD -g $gtag -p $ptag -i ${new_template_ini} -d ${TEM_DIR}/new_ini_block -o ${TEM_DIR}/output_file
        if [ $? -ne 0 ]; then
           _err_msg_="Error in migrating block ${_item_} from ${old_template_ini}"
           abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
        fi

        $CP ${TEM_DIR}/output_file ${new_template_ini}
        if [ $? -ne 0 ]; then
           _err_msg_="Failed to migrate ${old_template_ini}"
           abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
        fi

        $RM -rf ${TEM_DIR}/output_file
        log_msg -l ${LOGFILE} -s "Successfully migrated block ${_item_} to ${new_template_ini}."

fi
}

### Function: merge_platform_content ###
#
# To merge PF config files
#
# Arguments: none
#
# Return Values: none
merge_platform_content()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: migrate_sentinel ###
#
# Installs sentinel Server
#
# Arguments: none
#
# Return Values: none
migrate_sentinel()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

local _sentinel_service_str_="licensing-sentinel"
local _sentinel_mount_=0

_nfs_host_=`iniget Storage_NAS_SENTINEL -f ${ENIQ_CONF_DIR}/storage.ini -v NFS_HOST`
_share_path_=`iniget Storage_NAS_SENTINEL -f ${ENIQ_CONF_DIR}/storage.ini -v SHARE_PATH`
_mount_path_=`iniget Storage_NAS_SENTINEL -f ${ENIQ_CONF_DIR}/storage.ini -v MOUNT_PATH`

#Ensuring that the NAS filesystem with backup data is mounted
mount_nas_fs

# Ensuring that the Sentinel filesystem is mounted
log_msg -t -s "Ensuring that the Sentinel filesystem is mounted before proceeding further" -l ${LOGFILE}

# Create the mount point if its not there
if [ ! -d ${_mount_path_} ]; then
    log_msg -s "\nCreating mount point - ${_mount_path_}" -l ${LOGFILE}
    $MKDIR -p ${_mount_path_} >> /dev/null 2>&1
    if [ $? -ne 0 ]; then
        _err_msg_="Could not create mount point ${_mount_path_}"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi
fi

_mount_exists_=`$MOUNT | $GREP "${_mount_path_}" | $AWK '{print $1}'`
if [ ! "${_mount_exists_}" ]; then
    _sentinel_mount_=1
fi

if [ ${_sentinel_mount_} -eq 1 ]; then
    log_msg -s "Mounting ${_nfs_host_}:${_share_path_} on ${_mount_path_}" -l ${LOGFILE}
    $MOUNT -t nfs ${_nfs_host_}:${_share_path_} ${_mount_path_} >> /dev/null 2>&1
    if [ $? -ne 0 ]; then
        _err_msg_="Could not mount ${_nfs_host_}:${_share_path_} on ${_mount_path_}"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    else
        log_msg -s "\nSuccessfully mounted Sentinel filesystem"
    fi
else
    log_msg -s "${_mount_path_} is already mounted" -l ${LOGFILE}
fi

if [ ! -s ${ENIQ_BASE_DIR}/sentinel/migrate_${HNAME}.complete ]; then
    log_msg -t -s "Ensuring that the license server is shutdown before proceeding further" -l ${LOGFILE} 
    _sentinel_pid_=`$PS -eaf|$GREP lserv|$GREP -v grep|$AWK '{print $2}'`
    if [ ${_sentinel_pid_} ]; then
        $KILL ${_sentinel_pid_}
        if [ $? -eq 0 ]; then
            log_msg -t -q -s "Sentinel shutdown successfully" -l ${LOGFILE}
        fi
    fi

    if [ "${CO_SERVER}" ]; then
        log_msg -t -s "Removing the ${ENIQ_BASE_DIR}/sentinel directory content" -l ${LOGFILE} 
        $RM -rf ${ENIQ_BASE_DIR}/sentinel/*
    fi

    log_msg -t -s "Installing Sentinel binaries from the software bundle" -l ${LOGFILE} 
    $BASH ${ENIQ_CORE_INST_SCRIPT} -s install_sentinel ${ENIQ_CORE_INST_ARG}
    if [ $? -ne 0 ]; then
        _err_msg_="Failed in ${ACTION_TYPE} stage - install_sentinel"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi

    SENTINEL_DATE=`$DATE '+%y%m%d_%H%M%S'`
    $ECHO ${SENTINEL_DATE} > ${ENIQ_BASE_DIR}/sentinel/migrate_${HNAME}.complete
    $CHMOD 440 ${ENIQ_BASE_DIR}/sentinel/migrate_${HNAME}.complete
    if [ $? -ne 0 ]; then
        _err_msg_="Could not change permissions of ${ENIQ_BASE_DIR}/sentinel/migrate_${HNAME}.complete to -r--r-----"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi
else
    log_msg -t -s "Sentinel binaries have already been updated" -l ${LOGFILE}
fi

if [ "${CO_SERVER}" ]; then
    local _service_state_=`$SYSTEMCTL show ${_sentinel_service_str_} -p ActiveState | $AWK -F= '{print $2}'`
    if [ ${_service_state_} == "inactive" ]; then
        _sentinel_pid_=`$PS -eaf|$GREP lserv|$GREP -v grep|$AWK '{print $2}'`
        if [ ${_sentinel_pid_} ]; then
            log_msg -t -s "Shutting down licensing server using the lsrvdown utility" -l ${LOGFILE} 
            ${ENIQ_BASE_DIR}/sentinel/bin/lsrvdown localhost
            if [ $? -eq 0 ]; then
                log_msg -s "Sentinel shutdown successfully" -l ${LOGFILE}
            fi
        fi
    fi

    #Ensuring that the NAS filesystem with backup data is mounted
    mount_nas_fs
    #Merge the solaris license file with current license file
    merge_lic_file
    check_and_manage_smf ${_sentinel_service_str_} enable
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}
set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: merge_lic_file ###
#
# Merge sentinel license
#
# Arguments: none
#
# Return Values: none
merge_lic_file()
{

update_lic_file=${VAR_TMP_DIR}/backup_lservrc
ENIQ_BACKUP_LIC=${ENIQ_PORTBACKUP}/${HNAME}/NAS/eniq/sentinel/lic/lservrc
ENIQ_LIC_FILE=${ENIQ_SENTINEL_DIR}/lic/lservrc

log_msg -t -s "Merging the Eniq feature license file" -l ${LOGFILE}
if [ -f ${ENIQ_BACKUP_LIC} ]; then
    if [ -f ${ENIQ_LIC_FILE} ]; then
             $DIFF ${ENIQ_BACKUP_LIC} ${ENIQ_LIC_FILE} | $SED 's/< //g' | $SED '1d' | $EGREP -v '>|---'  > ${update_lic_file}
            if [ $? -ne 0 ]; then
                _err_msg_="Could not merge lservrc file."
                abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
            else
                $CAT ${update_lic_file} >> ${ENIQ_LIC_FILE}
                if [ $? -ne 0 ]; then
                    _err_msg_="Could not replace ${ENIQ_LIC_FILE}."
                    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
                fi
            fi
    else
        _err_msg_="Could not find ${ENIQ_LIC_FILE}."
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi
else
    _err_msg_="Could not find ${ENIQ_BACKUP_LIC}."
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi


#Remove the temporary merge licenses file
$RM -rf ${update_lic_file}
if [ $? -ne 0 ]; then
    _err_msg_="Could not remove ${update_lic_file}."
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

}

### Function: migrate_sap_asa ###
#
# Migrate SQL Anywhere Database
#
# Arguments: none
#       
# Return Values: none
migrate_sap_asa()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

if [ "${CURR_SERVER_TYPE}" == "stats_coordinator" -o "${CURR_SERVER_TYPE}" == "eniq_stats" ]; then
     _db_="repdb"
     _ini_sect_="REP"

     if [ "${STORAGE_TYPE}" = raw ]; then
         # NAS service should be online
         log_msg -t -s "Checking if NASd is online before proceeding further\n" -l ${LOGFILE}
         check_nasd_milestone_online ${ENIQ_CONF_DIR} ${SUNOS_INI} ${ENIQ_BASE_DIR}
         if [ $? -ne 0 ]; then
             _err_msg_="NASd not in a correct state to continue"
             abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
         fi
     fi

     # Retrieve information for required database
     get_database_info "${_db_}" "${_ini_sect_}"

     # Setup the SAP environment
     setup_sap_env

     if [ ! -s ${REP_DIR}/upgrade.complete ]; then
          log_msg -t -s "Stopping Database ${_db_}" -l ${LOGFILE}
          database_start_stop "${_db_}" "stop" >> ${LOGFILE}
          stop_return=$?
          if [ ${stop_return} -ne 0 ]; then
              _err_msg_="Could not stop ${_db_}"
              abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
          fi

          # Update the database configuration files
          update_database_config_file "${_db_}" "${REP_DIR}"

          log_msg -t -s "Starting Database ${_db_}" -l ${LOGFILE}
          database_start_stop "${_db_}" "start" >> ${LOGFILE}
          start_return=$?
          if [ ${start_return} -ne 0 ]; then
              _err_msg_="Could not start ${_db_}"
              abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
          fi

          log_msg -t -s "Upgrading database ${_db_}" -l ${LOGFILE}
          $SU - $SYSUSER -c ". /eniq/sybase_iq/SYBASE.sh;$DBISQL @${conn_str_dba_enc} -onerror exit -nogui \"ALTER DATABASE UPGRADE;\" " > ${TEM_DIR}/alter_repdb_output.txt 2>&1
          _sqlcode_val_=`$CAT ${TEM_DIR}/alter_repdb_output.txt | $GREP SQLCODE | $CUT -d',' -f1 |  $CUT -d'=' -f2`
          if [[ "${_sqlcode_val_}" && ${_sqlcode_val_} -ne "-308" ]]; then
              _err_msg_="Database ${_db_} not upgraded"
              abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
          fi

          REPDATE=`$DATE '+%y%m%d_%H%M%S'`
          $ECHO ${REPDATE} > ${REP_DIR}/upgrade.complete
          $CHMOD 440 ${REP_DIR}/upgrade.complete
          if [ $? -ne 0 ]; then
              _err_msg_="Could not change permissions of ${REP_DIR}/upgrade.complete to -r--r-----"
              abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
          fi
     else
          log_msg -t -s "Skipping ${_db_} upgrade as upgrade has already been completed."  -l ${LOGFILE}
     fi

     # Update dboptions
     log_msg -t -s "Running default ENIQ options into the database."  -l ${LOGFILE}
     update_dboptions "${_db_}"

     # Truncating the repdb transaction log and renaming from repdb.log to repdb.tran
     log_msg -t -s "Truncating the ${_db_} transaction log & renaming to ${_db_}.tran if needed." -l ${LOGFILE}
     truncate_transaction_log "${_db_}" "${_db_}.cfg" "${REP_DIR}" "${_db_port_}" "${_dba_pass_}" "${SQLANY}"
else
     insert_header_footer foot "Skipping ${ACTION_TYPE} stage - ${NEXT_STAGE} for ${CURR_SERVER_TYPE} " ${LOGFILE}
     set_next_stage `$EXPR ${ARRAY_ELEM}+1`
     return 0
fi
insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: migrate_sap_iq ###
#
# Migrate SAP IQ Database
#
# Arguments: none
#
# Return Values: none
migrate_sap_iq()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

if [ "${CURR_SERVER_TYPE}" == "stats_coordinator" -o "${CURR_SERVER_TYPE}" == "eniq_stats" ]; then
     _db_="dwhdb"
     #removed the repdb from the list, since need repdb online to create the IQ_PwdHistory_table in repdb
     _db_list_="dwhdb"
     _ini_sect_="DWH"
     if [ "${STORAGE_TYPE}" = raw ]; then
         # NAS service should be online
         log_msg -t -s "Checking if NASd is online before proceeding further\n" -l ${LOGFILE}
         check_nasd_milestone_online ${ENIQ_CONF_DIR} ${SUNOS_INI} ${ENIQ_BASE_DIR}
         if [ $? -ne 0 ]; then
             _err_msg_="NASd not in a correct state to continue"
             abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
         fi
     fi

     # Retrieve information for required database
     get_database_info "${_db_}" "${_ini_sect_}"

     # Setup the SAP environment
     setup_sap_env

     if [ ! -s ${DWH_DIR}/upgrade.complete ]; then
          for _database_ in $($ECHO ${_db_list_} | $SED "s/,/ /g")
          do
              log_msg -t -s "Ensuring database ${_database_} is stopped before performing upgrade" -l ${LOGFILE}
              database_start_stop "${_database_}" "stop" >> ${LOGFILE}
              stop_return=$?
              if [ ${stop_return} -ne 0 ]; then
                  _err_msg_="Could not stop ${_database_}"
                  abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
              fi
          done

          # Updates the database configuration files
          update_database_config_file "${_db_}" "${DWH_DIR}"

          # Update the IQ Caches 
          $BASH ${MIGRATION_BIN}/set_core_memcache.bsh -m -f -z -l ${LOGFILE}
          if [ $? -ne 0 ]; then
              _err_msg_="Failed to update the IQ Caches"
              abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
          fi

          if [ "${CURR_SERVER_TYPE}" == "stats_coordinator" ]; then

                $CP -p ${DWH_DIR}/${_db_}.cfg ${DWH_DIR}/${_db_}.cfg_${RUN_TIME}
                if [ $? -ne 0 ]; then
                    _err_msg_="Could not make backup of ${DWH_DIR}/${_db_}.cfg"
                    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
                fi
            
                log_msg -t -s "Adding single node mode option in ${_db_}.cfg" -l ${LOGFILE}
                $ECHO -iqmpx_sn 1 >> ${DWH_DIR}/${_db_}.cfg
                if [ $? -ne 0 ]; then
                    _err_msg_="Could not add single node mode option in ${DWH_DIR}/${_db_}.cfg"
                    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
                fi

                log_msg -t -s "Starting the ${_db_} in single node mode (-iqmpx_sn 1)" -l ${LOGFILE}
                log_msg -t -q -s "Starting Database ${_db_}" -l ${LOGFILE}
                database_start_stop "${_db_}" "start" >> ${LOGFILE}
                start_return=$?
                if [ ${start_return} -ne 0 ]; then
                    _err_msg_="Could not start ${_db_}"
                    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
                fi

                # Check if server is up
                $SU - ${SYSUSER} -c "${IQDIR}/bin64/dbping @${conn_str_db_stop_ping_enc}" >> ${LOGFILE} 2>&1
                if [ $? -eq 0 ] ; then
                     log_msg -s "Database ${_db_} successfully started in single node mode (-iqmpx_sn 1)" -l ${LOGFILE}
                else
                    _err_msg_="IQ server ${_db_eng_} start failed"
                    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
                fi
          fi

          log_msg -t -s "Starting Database ${_db_}" -l ${LOGFILE}
          database_start_stop "${_db_}" "start" >> ${LOGFILE}
          start_return=$?
          if [ ${start_return} -ne 0 ]; then
              _err_msg_="Could not start ${_db_}"
              abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
          fi

          log_msg -t -s "Locking  'dc', 'dcpublic' & 'dcbo' in the ${_db_}." -l ${LOGFILE}
          lock_unlock_user_iq_db "${_dba_pass_}" "${_db_port_}" "dc" "lock"
          lock_unlock_user_iq_db "${_dba_pass_}" "${_db_port_}" "dcpublic" "lock"
          lock_unlock_user_iq_db "${_dba_pass_}" "${_db_port_}" "dcbo" "lock"
          
          log_msg -t -s "Restarting DWHDB to kick off any existing database connections before performing upgrade" -l ${LOGFILE}

          log_msg -t -q -s "Stopping Database ${_db_}" -l ${LOGFILE}
          database_start_stop "${_db_}" "stop" >> ${LOGFILE}
          stop_return=$?
          if [ ${stop_return} -ne 0 ]; then
              _err_msg_="Could not stop ${_db_}"
              abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
          fi

          log_msg -t -q -s "Starting Database ${_db_}" -l ${LOGFILE}
          database_start_stop "${_db_}" "start" >> ${LOGFILE}
          start_return=$?
          if [ ${start_return} -ne 0 ]; then
              _err_msg_="Could not start ${_db_}"
              abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
          fi

          # Check if server is up
          $SU - ${SYSUSER} -c "${IQDIR}/bin64/dbping @${conn_str_db_stop_ping_enc}" >> ${LOGFILE} 2>&1
          if [ $? -eq 0 ] ; then
              log_msg -t -q -s "Database ${_db_} successfully started" -l ${LOGFILE}
          else
              _err_msg_="IQ server ${_db_eng_} start failed"
              abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
          fi

          if [ -f "${DWH_DIR}/${_db_}.cfg_${RUN_TIME}" ]; then
                log_msg -s "Setting database config file to original" -l ${LOGFILE}
                $CP -p ${DWH_DIR}/${_db_}.cfg_${RUN_TIME} ${DWH_DIR}/${_db_}.cfg
                if [ $? -ne 0 ]; then
                    _err_msg_="Could not set ${DWH_DIR}/${_db_}.cfg to original"
                    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
                else 
                    $RM -rf ${DWH_DIR}/${_db_}.cfg_${RUN_TIME}
                fi
          fi

          PID=`$PS -auxww | $EGREP -w "iqsrv" | $EGREP -v EGREP| $EGREP -w ${_db_eng_} | $AWK '{print $2}'`
          PID1=${PID}
          log_msg -t -s "Upgrading Database ${_db_}" -l ${LOGFILE}
          _retry_count_=1

          while [ ${_retry_count_} -le 3 ]
          do
              $SU - $SYSUSER -c "$DBISQL @${conn_str_dba_enc} -nogui -onerror exit \"ALTER DATABASE UPGRADE PROCEDURE ON;\" " > ${TEM_DIR}/alter_output.txt 2>&1    
              _sqlcode_val_=`$CAT ${TEM_DIR}/alter_output.txt | $GREP SQLCODE | $CUT -d',' -f1 |  $CUT -d'=' -f2`
              if [[ "${_sqlcode_val_}" && ${_sqlcode_val_} -ne "-308" ]]; then
                  _retry_count_=$(( _retry_count_ +1 ))
                  _err_msg_="Database ${_db_} has not been upgraded. Retrying alter database." 
                  log_msg -s "${_err_msg_}" -l ${LOGFILE}
              else
                  break
              fi
              sleep 10
          done

          if [ ${_retry_count_} -eq 4 ]; then
              _err_msg_="Alter Database Upgrade for ${_db_} failed"
              abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
          fi

          log_msg -t -s "Database restarts after upgrade. Hence waiting few seconds for completion of database restart before proceeding." -l ${LOGFILE}
          break_count=1
          while [ ${PID} -eq ${PID1} ]; do
              # sleep for 5 seconds
              sleep 5
              PID=`$PS -auxww | $EGREP -w "iqsrv" | $EGREP -v EGREP| $EGREP -w ${_db_eng_} | $AWK '{print $2}'`
              let break_count=${break_count}+1
              if [ ${break_count} -gt 61 ]; then
                  break
              fi
          done

          _count_=1
          _retry_=5
          $TOUCH /tmp/error_$$.log
          $CHMOD 777 /tmp/error_$$.log
          while [ ${_count_} -le ${_retry_} ]; do
              log_msg -s "Starting loop ${_count_} of ${_retry_} to ensure the database has restarted and can be queried." -l ${LOGFILE}
              $SU - $SYSUSER -c "$DBISQL @${conn_str_dba_enc} -nogui  -onerror exit \"sp_iqstatus\" >/dev/null 2>/tmp/error_$$.log"
              if [ $? -eq 0 ]; then
                  log_msg -s "Database ${_db_} is up, running and can be queried. Exit the loop" -l ${LOGFILE}
                  $RM /tmp/error_$$.log
                  break
              fi
              let _count_=${_count_}+1
              $CAT /tmp/error_$$.log >>${LOGFILE}
              $RM /tmp/error_$$.log
              # sleep for 5 seconds
              sleep 5
          done

          if [ ${_count_} -gt ${_retry_} ]; then
              _err_msg_="Database ${_db_} has not restarted successfully after upgrade"
              abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
          fi

          if [ "${CURR_SERVER_TYPE}" == "stats_coordinator" ]; then
              log_msg -t -s "Altering login policies due their reset during upgrade. " -l ${LOGFILE}
              drop_loginpolicies
          fi

          if [ "${CURR_SERVER_TYPE}" == "stats_coordinator" ]; then
          
              host_name_variable=$( $SU - $SYSUSER -c "$DBISQL @${conn_str_dba_enc} -nogui  -onerror exit \"select connection_info from sysiqmpxserver where server_name like '${_db_eng_}';\" " )
              if [ $? -ne 0 ]; then
                  _err_msg_="Failed to retrieve connection info for ${_db_eng_}"
                  abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
              fi

              $ECHO ${host_name_variable}  | $GREP ${_db_eng_} >/dev/null
              if [ $? -ne 0 ]; then
                   log_msg -t -q s "Starting Database ${_db_}" -l ${LOGFILE}
                   database_start_stop "${_db_}" "start" >> ${LOGFILE}
                   start_return=$?
                   if [ ${start_return} -ne 0 ]; then
                       _err_msg_="Could not start ${_db_}"
                       abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
                   fi

                   #abort on normal multiplex start issue
                   log_msg -t -s "Altering multiplex server host address to '${_db_eng_}'." -l ${LOGFILE}
                   $SU - $SYSUSER -c "$DBISQL @${conn_str_dba_enc} -nogui  -onerror continue \"ALTER MULTIPLEX SERVER ${_db_eng_} HOST '${_db_eng_}' PORT ${_db_port_};\" " >/dev/null 2>&1

                   sleep 10

                   log_msg -t -s "Stopping the ${_db_} database" -l ${LOGFILE}
                    $SU - $SYSUSER -c "${IQDIR}/bin64/dbstop -y @${conn_str_db_stop_ping_enc}"

                   PID=`$PS -auxww | $EGREP -w "iqsrv" | $EGREP -v EGREP| $EGREP -w ${_db_eng_} | $AWK '{print $2}'`
                   if [ -z "${PID}" ] ; then
                       log_msg -s  "Database is down" -l ${LOGFILE}
                   else
                       log_msg -s  "Database ${_db_eng_} refused to stop. Attempting to force kill it." -l ${LOGFILE}
                       $KILL -9 ${PID} >> ${LOGFILE} 2>&1
                       if [ $? -ne 0 ]; then
                           _err_msg_="Could not kill IQ SERVER PID ${PID}"
                           abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
                       fi
                       log_msg -s  "Database killed." -l ${LOGFILE}
                   fi
               fi
          fi

          log_msg -t -s "Starting Database ${_db_}" -l ${LOGFILE}
          database_start_stop "${_db_}" "start" >> ${LOGFILE}
          start_return=$?
          if [ ${start_return} -ne 0 ]; then
              _err_msg_="Could not start ${_db_}"
              abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
          fi

          if [ "${CURR_SERVER_TYPE}" == "stats_coordinator" ]; then
              log_msg -t -s "Assigning back the users to their respective login policies" -l ${LOGFILE}
              for _locked_user_ in ${_locked_users_}; do
                  log_msg -s "Assigning back user ${_locked_user_} to locked_users login policy" -l ${LOGFILE}
                  lock_unlock_user_iq_db ${_dba_pass_} ${_db_port_} ${_locked_user_} 'lock'
              done

              for _unlocked_user_ in ${_unlocked_users_}; do
                  log_msg -t -s "Assigning back user ${_unlocked_user_} to unlocked_users login policy" -l ${LOGFILE}
                  lock_unlock_user_iq_db ${_dba_pass_} ${_db_port_} ${_unlocked_user_} 'unlock'
              done
          fi
          
          log_msg -t -s "Unlocking  'dc', 'dcpublic' & 'dcbo' in the ${_db_}." -l ${LOGFILE}
          lock_unlock_user_iq_db ${_dba_pass_} ${_db_port_} 'dc' 'unlock'
          lock_unlock_user_iq_db ${_dba_pass_} ${_db_port_} 'dcpublic' 'unlock'
          lock_unlock_user_iq_db ${_dba_pass_} ${_db_port_} 'dcbo' 'unlock'

          DWHDATE=`$DATE '+%y%m%d_%H%M%S'`
          $ECHO ${DWHDATE} > ${DWH_DIR}/upgrade.complete
          $CHMOD 440 ${DWH_DIR}/upgrade.complete
          if [ $? -ne 0 ]; then
              _err_msg_="Could not change permissions of ${DWH_DIR}/upgrade.complete to -r--r-----"
              abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
          fi
     else
          log_msg -t -s "Starting Database ${_db_}" -l ${LOGFILE}
          database_start_stop "${_db_}" "start" >> ${LOGFILE}
          start_return=$?
          if [ ${start_return} -ne 0 ]; then
              _err_msg_="Could not start ${_db_}"
              abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
          fi
     fi

     # Update dboptions
     log_msg -t -s "Running default ENIQ options into the database."  -l ${LOGFILE}
     update_dboptions "${_db_}"

     # Truncating the dwhdb transaction log and renaming from dwhdb.log to dwhdb.tran
     log_msg -t -s "Truncating the ${_db_} transaction log & renaming to ${_db_}.tran if needed." -l ${LOGFILE}
     truncate_transaction_log "${_db_}" "${_db_}.cfg" "${DWH_DIR}" "${_db_port_}" "${_dba_pass_}" "${IQDIR}"
else
     insert_header_footer foot "Skipping ${ACTION_TYPE} stage - ${NEXT_STAGE} for ${CURR_SERVER_TYPE} " ${LOGFILE}
     set_next_stage `$EXPR ${ARRAY_ELEM}+1`
     return 0
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: mount_nas_fs ###
#
# Mounting NAS filesystem
#
# Arguments:
#   none
# Return Values:
#   none
mount_nas_fs()
{
# Get Migration backup NAS IP
MIG_BACKUP_NAS_IP=`read_value MIG_BACKUP_NAS_IP ${MIGRATION_CONF}` || abort_script "${MIG_BACKUP_NAS_IP}" "${EXEC_SHELL_CMD}"

# Get Migration backup NAS directory
MIG_BACKUP_NAS_DIR=`read_value MIG_BACKUP_NAS_DIR ${MIGRATION_CONF}` || abort_script "${MIG_BACKUP_NAS_DIR}" "${EXEC_SHELL_CMD}"

# Create the mount point if its not there
if [ ! -d ${ENIQ_PORTBACKUP} ]; then
    log_msg -s "\nCreating mount point - ${ENIQ_PORTBACKUP}" -l ${LOGFILE}
    $MKDIR -p ${ENIQ_PORTBACKUP} >> /dev/null 2>&1
    if [ $? -ne 0 ]; then
        _err_msg_="Could not create mount point ${ENIQ_PORTBACKUP}"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi
fi

# Flag to determine if a mount is required
_mount_=0

log_msg -s "Checking if ${ENIQ_PORTBACKUP} is already mounted\n" -l ${LOGFILE}
_mount_exists_=`$MOUNT | $GREP "${ENIQ_PORTBACKUP}" | $AWK '{print $1}'`
if [ ! "${_mount_exists_}" ]; then
    _mount_=1
fi

if [ ${_mount_} -eq 1 ]; then
    log_msg -s "Mounting ${MIG_BACKUP_NAS_IP}:${MIG_BACKUP_NAS_DIR} on ${ENIQ_PORTBACKUP}" -l ${LOGFILE}
    $MOUNT -t nfs ${MIG_BACKUP_NAS_IP}:${MIG_BACKUP_NAS_DIR} ${ENIQ_PORTBACKUP} >> /dev/null 2>&1
    if [ $? -ne 0 ]; then
        _err_msg_="Could not mount ${MIG_BACKUP_NAS_IP}:${MIG_BACKUP_NAS_DIR} on ${ENIQ_PORTBACKUP}"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    else
        log_msg -s "\nSuccessfully mounted ${ENIQ_PORTBACKUP}"
    fi
else
    log_msg -s "${ENIQ_PORTBACKUP} is already mounted\n" -l ${LOGFILE}
fi
}

### Function: mount_lvm ###
#
#   Mounting file-systems
#
# Arguments:
#   none
# Return Values:
#   none
mount_lvm()
{ 
#Check and mount file-systems
_file_="/etc/fstab" >> /dev/null 2>&1
    if [ -s  ${_file_} ]; then
       $MOUNT -a >> /dev/null 2>&1
        if [ $? -ne 0 ]; then
           _err_msg_="Could not mount file systems"
           abort_script "${_err_msg_}" 
        fi
        log_msg -s "Successfully Mounted all file-systems\n" -l ${LOGFILE}
    fi
}

### Function: populate_nasd_config ###
#
# Populate the NASd config file
#
# Arguments: none
#   
# Return Values: none
populate_nasd_config()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling populate_nasd_config stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s populate_nasd_config ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - populate_nasd_config"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: post_configuration ###
#
#   Post configuration after running migration stages
#
# Arguments:
#   none
# Return Values:
#   none
post_configuration()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

# Enable DDC service
log_msg -t -s "Starting DDC service." -l ${LOGFILE}
check_and_manage_smf ${DDC_SMF_ID} enable

# Enable Hostsync service
log_msg -t -s "Starting Hostsync service." -l ${LOGFILE}
check_and_manage_smf ${HOSTSYNC_SMF_ID} enable


# Clean-up Flag files
log_msg -t -s "Cleaning up flag ${MIGR_PROGRESS} used for migration." -l ${LOGFILE}
$RM -rf ${MIGR_PROGRESS} >> /dev/null 2>&1

# Touch the success flag
$TOUCH ${MIGR_SUCCESS}
if [ ! -f "${MIGR_SUCCESS}" ];then
    _err_msg_="Could not create ${MIGR_SUCCESS} during ${ACTION_TYPE}."
    abort_script "${_err_msg_}"
fi

# Moving /ericsson/config directory to clean leftovers of rhelonly kickstart
if [ -d "${ERICSSON_DIR}/config" ]; then
    log_msg -s "Moving ${ERICSSON_DIR}/config directory." -l ${LOGFILE}
    $MV ${ERICSSON_DIR}/config ${CONFIG_BACKUP_DIR}/ericsson_config
    if [ -d "${ERICSSON_DIR}/config" ]; then
        _err_msg_="Could not move ${ERICSSON_DIR}/config directory."
        abort_script "${_err_msg_}"
    fi
fi

log_msg -t -s "Updating eniq_status file" -l ${LOGFILE}

# Check the required scripts exist or not
_manage_eniq_status_script_="${ENIQ_ADMIN_BIN_DIR}/manage_eniq_status.bsh"
check_for_file -s ${_manage_eniq_status_script_}

log_msg -q -s "\nStarting to run $BASH ${_manage_eniq_status_script_} -d ${BASE_SW_DIR} -l ${LOGFILE}" -l ${LOGFILE}
$BASH ${_manage_eniq_status_script_} -d ${BASE_SW_DIR} -l ${LOGFILE}
if [ $? -ne 0 ]; then
    _err_msg_="Failed to update eniq_status file\n"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

log_msg -t -s "Post configuration completed." -l ${LOGFILE}

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}


### Function: recreate_db_symlinks ###
#
# To recreate DB symlinks
#
# Arguments:
#   none
# Return Values:
#   none
recreate_db_symlinks()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

# Skip if Rack
if [ "${STORAGE_TYPE}" != "raw" ]; then
    insert_header_footer foot "Rack Migration - Skipping - ${NEXT_STAGE}" ${LOGFILE}
    set_next_stage `$EXPR ${ARRAY_ELEM}+1`
    return 0
fi

# Skip stage if not CO or Reader server
if [ "${CO_SERVER}" != "YES" -a "${RD_SERVER}" != "YES" ]; then  
    insert_header_footer foot "Skipping ${ACTION_TYPE} stage for ${CURR_SERVER_TYPE} - ${NEXT_STAGE} " ${LOGFILE} 
    set_next_stage `$EXPR ${ARRAY_ELEM}+1`
    return 0
fi

# NAS service should be online
log_msg -t -s "Checking if NASd is online before repairing sym_links." -l ${LOGFILE}
check_nasd_milestone_online ${ENIQ_CONF_DIR} ${SUNOS_INI} ${ENIQ_BASE_DIR}
if [ $? -ne 0 ]; then
    _err_msg_="NASd not in a correct state to continue"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

# Update sym_links.ini
$BASH ${MIGRATION_BIN}/update_sym_links_ini.bsh -N -M 
if [ $? -ne 0 ]; then
    _err_msg_="Unable to update sym_links.ini file."
    abort_script "$_err_msg_"
fi

# Re-create DB sym_links
$BASH ${MIGRATION_BIN}/eniq_core_install.bsh -M -s create_db_sym_links -n -R -l ${LOGFILE}
if [ $? -ne 0 ]; then
    _err_msg_="Unable to repair the DB symbolic links"
    abort_script "$_err_msg_"
fi

# Verify sym links are correctly configured
_sym_links_check_="${MIGRATION_BIN}/check_sym_links.pl"
log_msg -t -s "Verifying if database symbolic links are correctly assigned" -l ${LOGFILE}
$PERL ${_sym_links_check_} ${ENIQ_CONF_DIR}/${SYM_LINKS_INI} >> /dev/null
_return_code_=$?
if [ ${_return_code_} -eq 0 ]; then
    log_msg -s "DB sym_links are correctly assigned." -l ${LOGFILE}
elif [ ${_return_code_} -eq 22 -o ${_return_code_} -eq 32 ]; then
    _err_msg_="DB sym_links are still incorrect. Please fix the sym_links manually."
    abort_script "$_err_msg_"
else
    _err_msg_="Failed to execute ${_sym_links_} script to verify the sym_links."
    abort_script "$_err_msg_"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: restore_databases ###
#
# Restores Catalog and Transaction Log for 
# RepDB and DWHDB databases
#
# Arguments:
#   none
# Return Values:
#   none
restore_databases()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

if [ "${CURR_SERVER_TYPE}" == "stats_engine" ]; then
    insert_header_footer foot "Skipping ${ACTION_TYPE} stage - ${NEXT_STAGE} for ${CURR_SERVER_TYPE} " ${LOGFILE}
    set_next_stage `$EXPR ${ARRAY_ELEM}+1`
    return 0
fi

#Ensuring that the NAS filesystem with backup data is mounted
mount_nas_fs

if [ "${CURR_SERVER_TYPE}" == "stats_coordinator" -o "${CURR_SERVER_TYPE}" == "eniq_stats" ]; then
      log_msg -t -s "Restoring database files for DWHDB\n" -l ${LOGFILE}
      $CP -pr ${ENIQ_PORTBACKUP}/${HNAME}/ZFS/${DWH_DIR}/* ${DWH_DIR}
      if [ $? -ne 0 ]; then
           _err_msg_="Could not restore database files for DWHDB"
            abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
      fi

      log_msg -t -s "Restoring database files for RepDB\n" -l ${LOGFILE}
      $CP -pr ${ENIQ_PORTBACKUP}/${HNAME}/ZFS/${REP_DIR}/* ${REP_DIR}
      if [ $? -ne 0 ]; then
           _err_msg_="Could not restore database files for RepDB"
            abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
      fi
elif [ "${CURR_SERVER_TYPE}" == "stats_iqr" ]; then
      log_msg -t -s "Restoring database files for DWH_READER_DIR\n" -l ${LOGFILE}
      $CP -pr ${ENIQ_PORTBACKUP}/${HNAME}/ZFS/${DWH_READER_DIR}/* ${DWH_READER_DIR}
      if [ $? -ne 0 ]; then
           _err_msg_="Could not restore database files for DWH_READER"
            abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
      fi

      ##set the reader memory
      log_msg -q -s "Updating updating Reader IQ Memory settings\n" -l ${LOGFILE}

      # Get the reader number
      local _reader_num_=`$CAT ${CLI_CONF_DIR}/service_names | $GREP "${HOST_IP}" | $GREP "dwh_" | $AWK -F"::" '{print $3}' | $AWK -F\_ '{print $NF}'`
      if [ ! "${_reader_num_}" ] ; then
          _err_msg_="Could not get reader number"
          abort_script "$_err_msg_"
      fi
      
      local _reader_name_="dwh_reader_${_reader_num_}"
      local _dwh_reader_child_="DWH_READER_${_reader_num_}"
      ${BASH} ${SCRIPTHOME}/update_iq_mem_settings.bsh -d ${CLI_CONF_DIR} -p ${_dwh_reader_child_} -r ${_reader_name_} -l ${LOGFILE} -N
      if [ $? -eq 0 ]; then
          $CP ${CLI_CONF_DIR}/${ENIQ_INI} ${ENIQ_CONF_DIR}/${ENIQ_INI}
          if [ $? -ne 0 ]; then
              _err_msg_="Could not copy ${CLI_CONF_DIR}/${ENIQ_INI} to ${ENIQ_CONF_DIR}/${ENIQ_INI}"
              abort_script "$_err_msg_"
          fi
      else
          _err_msg_="Could not update ${_dwh_reader_child_} cache values in ${CLI_CONF_DIR}/${ENIQ_INI}"
          abort_script "$_err_msg_"
      fi
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: register_raw_device ###
#
# To register raw devices
#
# Arguments:
#   none
# Return Values:
#   none
register_raw_device()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

# Skip if Rack
if [ "${STORAGE_TYPE}" != "raw" ]; then
    insert_header_footer foot "Rack Migration - Skipping - ${NEXT_STAGE}" ${LOGFILE}
    set_next_stage `$EXPR ${ARRAY_ELEM}+1`
    return 0
fi

# Skip stage if not CO or Reader server
if [ "${CO_SERVER}" != "YES" -a "${RD_SERVER}" != "YES" ]; then  
    insert_header_footer foot "Skipping ${ACTION_TYPE} stage for ${CURR_SERVER_TYPE} - ${NEXT_STAGE} " ${LOGFILE} 
    set_next_stage `$EXPR ${ARRAY_ELEM}+1`
    return 0
fi

$RM -rf ${TEM_DIR}/db_spaces.txt
if [ -s ${TEM_DIR}/db_spaces.txt ]; then
     _err_msg_="Failed to remove ${TEM_DIR}/db_spaces.txt"
     abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

INST_TYPE_FILE=${ENIQ_CONF_DIR}/ericsson_use_config
if [ ! -s "${INST_TYPE_FILE}" ]; then
      _err_msg_="ENIQ install type not defined in ${INST_TYPE_FILE}"
      abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

INST_TYPE=`$CAT ${INST_TYPE_FILE} | $AWK -F\= '{print $2}'`
if [ ! "${INSTALL_TYPE}" ]; then
      _err_msg_="Failed to get install type"
      abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

_ini_file_list_="lun_map.ini sym_links.ini niq.ini SunOS.ini"

for _ini_file_ in `$ECHO ${_ini_file_list_}`
do
   log_msg -t -s "Backing up ${_ini_file_} file to ${TEM_DIR}" -l ${LOGFILE} 
   if [ -s ${ENIQ_CONF_DIR}/${_ini_file_} ]; then
        $CP -p ${ENIQ_CONF_DIR}/${_ini_file_} ${TEM_DIR}
        if [ $? -ne 0 ]; then
           _err_msg_="Failed to backup ${ENIQ_CONF_DIR}/${_ini_file_} to ${TEM_DIR}"
           abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
        fi
   else
        _err_msg_="${ENIQ_CONF_DIR}/${_ini_file_} file not found"
        abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
   fi
done

if [ "${CURR_SERVER_TYPE}" == "stats_coordinator" -o "${CURR_SERVER_TYPE}" == "eniq_stats" ]; then
     _par_tag_list_="DWH_SYSTEM_MAIN DWH_DBSPACES_MAIN DWH_DBSPACES_TEMP"
elif [ "${CURR_SERVER_TYPE}" == "stats_iqr" ]; then
     _par_tag_list_="DWH_SYSTEM_MAIN DWH_DBSPACES_MAIN DWH_READER_1_DBSPACES_TEMP DWH_READER_2_DBSPACES_TEMP"
fi

if [ "${CURR_SERVER_TYPE}" == "stats_iqr" ]; then
     log_msg -t -s "Copying ${CLI_CONF_DIR}/coordinator_sym_links.ini to ${ENIQ_CONF_DIR}" -l ${LOGFILE}
     $CP -p ${CLI_CONF_DIR}/coordinator_sym_links.ini ${ENIQ_CONF_DIR}
     if [ $? -ne 0 ]; then
          _err_msg_="Failed to copy ${CLI_CONF_DIR}/coordinator_sym_links.ini to ${ENIQ_CONF_DIR}"
          abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
     fi
fi

_par_tag_list_="DWH_SYSTEM_MAIN DWH_DBSPACES_MAIN DWH_DBSPACES_TEMP"

for _lun_map_det_ in `iniget LUN_MAP_DETAILS -f  ${TEM_DIR}/lun_map.ini`
do
    _disk_id_=`iniget ${_lun_map_det_} -f  ${TEM_DIR}/lun_map.ini -v DISK_ID`
    _lun_id_=`iniget ${_lun_map_det_} -f  ${TEM_DIR}/lun_map.ini -v LUN_ID`
    
     for _par_tag_ in `$ECHO ${_par_tag_list_}`
     do
         for _dwh_dbspace_ in `iniget ${_par_tag_} -f ${TEM_DIR}/sym_links.ini`
         do
             _db_lun_id_=`iniget ${_dwh_dbspace_} -f ${TEM_DIR}/sym_links.ini -v Lun_ID`
             if [ "${_db_lun_id_}" == "${_lun_id_}" ]; then
                  $ECHO "${_dwh_dbspace_}=${_disk_id_}" >> ${TEM_DIR}/db_spaces.txt
             fi
        done
     done
done

MAINDB_DISKS=`$CAT ${TEM_DIR}/db_spaces.txt |$GREP "DWH_DBSPACES_MAIN"|$SORT -u -t_ -k4 -g|$CUT -d"=" -f2|$PASTE -sd" "`
if [ ! "${MAINDB_DISKS}" ]; then
      _err_msg_="Failed to get Main DB Disks"
      abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
else
     log_msg -t -s "Setting MAINDB_DISKS=${MAINDB_DISKS} in ${TEM_DIR}/sym_links.ini" -l ${LOGFILE} 
     iniset DB_DISK_ALLOC -f ${TEM_DIR}/sym_links.ini MAINDB_DISKS="${MAINDB_DISKS}"
     if [ $? -ne 0 ]; then
          _err_msg_="Failed to set Main DB Disks in ${TEM_DIR}/sym_links.ini"
          abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
     fi
fi

TEMPDB_DISKS=`$CAT ${TEM_DIR}/db_spaces.txt |$GREP "DWH_DBSPACES_TEMP"|$SORT -u -t_ -k4 -g|$CUT -d"=" -f2|$PASTE -sd" "`
if [ ! "${TEMPDB_DISKS}" ]; then
      _err_msg_="Failed to get Temp DB Disks"
      abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
else
     log_msg -t -s "Setting TEMPDB_DISKS=${TEMPDB_DISKS} in ${TEM_DIR}/sym_links.ini" -l ${LOGFILE} 
     iniset DB_DISK_ALLOC -f ${TEM_DIR}/sym_links.ini TEMPDB_DISKS="${TEMPDB_DISKS}"
     if [ $? -ne 0 ]; then
          _err_msg_="Failed to set Temp DB Disks in ${TEM_DIR}/sym_links.ini"
          abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
     fi
fi

IQ_SYS_MAIN_DB_DISKS=`$CAT ${TEM_DIR}/db_spaces.txt |$GREP "DWH_SYSTEM_MAIN"|$SORT -u -t_ -k4 -g|$CUT -d"=" -f2|$PASTE -sd" "`
if [ ! "${IQ_SYS_MAIN_DB_DISKS}" ]; then
      _err_msg_="Failed to get Sys_Main DB Disks"
      abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
else
     log_msg -t -s "Setting IQ_SYS_MAIN_DISKS=${IQ_SYS_MAIN_DB_DISKS} in ${TEM_DIR}/sym_links.ini" -l ${LOGFILE} 
     iniset DB_DISK_ALLOC -f ${TEM_DIR}/sym_links.ini IQ_SYS_MAIN_DISKS="${IQ_SYS_MAIN_DB_DISKS}"
     if [ $? -ne 0 ]; then
          _err_msg_="Failed to set Sys_Main DB Disks in ${TEM_DIR}/sym_links.ini"
          abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
     fi
fi

$ECHO "/usr/bin/bash $SCRIPTHOME/get_cell_count.bsh -b ${ENIQ_BASE_DIR} -d ${TEM_DIR} -t ${STORAGE_TYPE} -e ${INST_TYPE} -l $LOGFILE" >> ${LOGFILE}
$BASH $SCRIPTHOME/get_cell_count.bsh -b ${ENIQ_BASE_DIR} -d ${TEM_DIR} -t ${STORAGE_TYPE} -e ${INST_TYPE} -l $LOGFILE
if [ $? -ne 0 ]; then
     _err_msg_="Failed to execute $SCRIPTHOME/get_cell_count.bsh"
     abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

if [ -s ${TEM_DIR}/sym_links.ini ]; then
     log_msg -t -s "Restoring ${TEM_DIR}/sym_links.ini file to ${ENIQ_CONF_DIR}" -l ${LOGFILE} 
     $CP -p ${TEM_DIR}/sym_links.ini ${ENIQ_CONF_DIR}
     if [ $? -ne 0 ]; then
           _err_msg_="Failed to restore ${TEM_DIR}/sym_links.ini to ${ENIQ_CONF_DIR}"
           abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
     fi
else
     _err_msg_="${TEM_DIR}/sym_links.ini file not found"
     abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

# Check for udev rules file if exist or not
if [ ! -f ${UDEV_FILE} ]; then
    err_msg_="UDEV rules files does not exist"
    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

# Activate the raw device created in udev rules
$UDEVADM  control --reload-rules
if [ $? -ne 0 ]; then
    _err_msg_="Could not reload udev rules for raw device"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

$UDEVADM  trigger --type=devices --action=change
if [ $? -ne 0 ]; then
    _err_msg_="Could not trigger udev rules for raw device"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

$SLEEP 5

# Check if the raw devices are created or not
_count_=0

while :; do
    $RAW -qa | $GREP raw >> /dev/null 2>&1
    if [ $? -eq 0 ]; then
        break
    else
        $SLEEP 1
        _count_=`$EXPR ${_count_} + 1`
        if [ ${_count_} -eq 10 ]; then
            err_msg_="Could not create raw device"
            abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
        fi
        continue
    fi
done

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: regenerateslots ###
#
# Regenerates the slots for engine towards Sybase
#
# Arguments:
#   none
# Return Values:
#   none
regenerateslots()
{
if [ ! -s ${ENIQ_ADMIN_BIN_DIR}/regenerateslots ]; then
    _err_msg_="${ENIQ_ADMIN_BIN_DIR}/regenerateslots not found"
    abort_script "${_err_msg_}"  "${EXEC_SHELL_CMD}"
fi

# Get the System User/Group. All directories are owned by this
_sysuser_=`iniget ENIQ_INSTALL_CONFIG -f ${ENIQ_CONF_DIR}/${SUNOS_INI} -v ENIQ_SYSUSER`
if [ ! "${_sysuser_}" ]; then
    _err_msg_="Could not read parameter ENIQ_SYSUSER from file\n${ENIQ_CONF_DIR}/${ENIQ_INI}"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

$ECHO "$SU - ${_sysuser_} -c \"/usr/bin/bash ${ENIQ_ADMIN_BIN_DIR}/regenerateslots\"" >> ${LOGFILE}
$SU - ${_sysuser_} -c "/usr/bin/bash ${ENIQ_ADMIN_BIN_DIR}/regenerateslots"
if [ $? -ne 0 ]; then
    _err_msg_="Issue encountered while running ${ENIQ_ADMIN_BIN_DIR}/regenerateslots"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
else
    $ECHO "${ENIQ_ADMIN_BIN_DIR}/regenerateslots completed successfully" | $TEE -a ${LOGFILE}
fi
}

### Function: run_prerecovery ###
#
#   Pre Recovery steps
#
# Arguments:
#   none
# Return Values:
#   none
run_prerecovery()
{
log_msg -t -h -s "Starting ${ACTION_TYPE} activity on $HNAME" -l ${LOGFILE} 

migr_progress_indicator=${VAR_DIR}/tmp/linux_migration_in_progress
migr_success_indicator=${VAR_DIR}/tmp/linux_migration_success

# Check the status of OS migration activity
if [ -f "${migr_progress_indicator}" -o -f "${migr_success_indicator}" ];then
    
    # Stop ENIQ services if they exist
    stop_eniq_services

    # Disable SMF Services
    log_msg -s "\nStopping SMF services." -l ${LOGFILE}
    stop_smf_services

    # Remove logical volume created through cron
    $DF -hk /dev/mapper/${VOLUME_GROUP_FOR_BACKUP}-${BACKUP_REPLACE_DIR} >> /dev/null 2>&1
    if [ $? -eq 0 ]; then
        # Unmounting the replacement_root_backup file system
        $UMOUNT -l ${MOUNT_POINT_BKUP}

        # Destroying the replacement_root_backup file system
        log_msg -s "\nRemoving LVM filesystem ${BACKUP_REPLACE_DIR}" -l ${LOGFILE}
        $LVREMOVE -f /dev/mapper/${VOLUME_GROUP_FOR_BACKUP}-${BACKUP_REPLACE_DIR}
        if [ $? -ne 0 ];then
            _err_msg_="Could not destroy ${BACKUP_REPLACE_DIR}."
            abort_script "${_err_msg_}"
        fi
    fi

    # Check VG's are present or not
    _pool_list_=`$VGS --no-headings -o name | $EGREP -v "${ROOT_POOL}"`
    if [ "${_pool_list_}" ];then
        # Get storage data before exporting VG's
        get_storage_info
       
        #Unmount lvm's
        unmount_lvm

        # Export VG's
        export_pools
    
        # Disconnect the storage 
        host_disconnect
    else
        log_msg -s "No Vg's found on the ${HNAME}. " -l ${LOGFILE}
        log_msg -s "Disconnect storage manually before shutting down the server and perform Solaris OS Installation to recover." -l ${LOGFILE}
        $RM -rf ${conn_str_dba_enc}
        $RM -rf ${conn_str_db_enc}
        $RM -rf ${conn_str_db_stop_ping_enc}
        $RM -rf ${conn_str_db_ping_enc}
        exit 1
    fi
fi
}

### Function: rescan_reboot ###
#
# To rescan and reboot after configuring storage API
#
# Arguments:
#   none
# Return Values:
#   none
rescan_reboot()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

## Adding multipath module to initramfs before reboot
log_msg -s "Adding multipath module to initramfs" -l ${LOGFILE}

$DRACUT --force --add multipath --include /etc/multipath >> /dev/null 2>&1
if [ $? -ne 0 ]; then
    _err_msg_="Failed to add multipath module to initramfs using DRACUT"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}
set_next_stage `$EXPR ${ARRAY_ELEM}+1`

log_msg -s  "Rebooting the server after configuring san storage API" -l ${LOGFILE}
$REBOOT
}

### Function: restore_backup_file ###
#
# Restores the database configuration file
#
# Arguments:
#           $1 = Database configuration file path
#           $2 = Database configuration file along with absolute path
#           $3 = Database configuration file backup name
#
# Return Values: none
restore_backup_file()
{
local _cfg_path_db_=$1
local _cfg_full_filename_=$2
local _cfg_backup_filename_=$3

$LS ${_cfg_full_filename_} > /dev/null
if [ $? -eq 0 ];
then
    log_msg -t -s "Restoring original ${_cfg_full_filename_} file" -l ${LOGFILE}
    $SU - $SYSUSER -c "$MV -f ${_cfg_path_db_}/${_cfg_backup_filename_} ${_cfg_full_filename_}"
    restore_return=$?
    if [ ${restore_return} -ne 0 ]; then
        _err_msg_="Could not restore ${_cfg_full_filename_}"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi
else 
    log_msg -t -s "Backup file ${_cfg_path_db_}/${_cfg_backup_filename_} not found!"  -l ${LOGFILE}
    log_msg -t -s "Failed to restore file ${_cfg_full_filename_}" -l ${LOGFILE}
fi
}

### Function: setup_cron_for_cleanup ###
#
# Sets the cron for cleanup of root backup from ZFS pool
#
# Arguments:
#   none
# Return Values:
#   none
setup_cron_for_cleanup()
{
# Verify if the cronjob for cleanup is already present in crontab
crontab -l | $GREP "eniq_linux_migration.bsh -a cleanup" >> /dev/null 2>&1
if [ $? -ne 0 ]; then
    crontab -l > /tmp/crontab.tmp
    $ECHO "0 0 1 * * $FIND ${MIGR_SUCCESS} -mtime +30 -exec $BASH ${MIGRATION_BIN}/eniq_linux_migration.bsh -a cleanup \;" >> /tmp/crontab.tmp
    crontab /tmp/crontab.tmp
fi

# Verify if the cronjob is added
crontab -l | $GREP "eniq_linux_migration.bsh -a cleanup" >> /dev/null 2>&1
if [ $? -ne 0 ]; then
   _err_msg_="Failed to add the cronjob in crontab"
    abort_script "$_err_msg_"
fi
}

### Function: setup_ipmp ###
#
# Set up IPMP.
#
# Arguments: none
#   
# Return Values: none
setup_ipmp()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

# Calling setup_ipmp stage from eniq_core_install.bsh

$BASH ${ENIQ_CORE_INST_SCRIPT} -s setup_ipmp ${ENIQ_CORE_INST_ARG} >> ${LOGFILE}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - setup_ipmp"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: setup_sap_env ###
#
# Set up SAP environment
#
# Arguments: none
#
# Return Values: none
setup_sap_env()
{
$SU - ${SYSUSER} >> /dev/null -c "$ENV |$EGREP '^(SYBASE|ASDIR|IQDIR|ASALOGDIR|SQLANY)'" 1> $TEM_DIR/sybase_det.$$ 2>/dev/null

# Source the environment
set -a
. $TEM_DIR/sybase_det.$$ >> /dev/null 2>&1
set +a

if [ ! "${SYBASE}" ]; then 
    _err_msg_="Could not determine Sybase environment variable ${SYBASE}"
    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

DBISQL="$(ls /eniq/sybase_iq/IQ-*/bin64/dbisql)"
if [ ! -x "$DBISQL" ]; then
    _err_msg_="$DBISQL commands not found or not executable."
    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

ISQL="$(ls /eniq/sybase_iq/OCS-*/bin/isql)"
if [ ! -x "$ISQL" ]; then
    _err_msg_="$ISQL commands not found or not executable."
    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

IQLOGDIR="${SW_LOG_DIR}/iq"
if [ ! "${IQLOGDIR}" ]; then 
    _err_msg_="Could not determine IQ log directory path"
    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi
}

### Function: setup_env ###
#
# Set up environment variables for script.
#
# Arguments:
#   none
# Return Values:
#   none
setup_env()
{
# Define root user's home
ROOT_HOME=/
if [ ! "${SOLARIS_10}" ]; then
    ROOT_HOME=/root/

    # Setting the env HOME to /root for console run
    export HOME=/root
fi

# Configuration files
VFSTAB_FILE_LIST=vfstab
FSTAB=fstab
ETC_DIR=/etc

VAR_DIR=/var

# Temporary Directory
VAR_TMP_DIR=${VAR_DIR}/tmp/

# ENIQ SSH Directory
SSH_DIR=${ROOT_HOME}.ssh

# ENIQ Directories
if [ ! "${ENIQ_BASE_DIR}" ]; then
    # Directory on the root filesystem
    ENIQ_BASE_DIR=/eniq
fi

ENIQ_INST_DIR=${ENIQ_BASE_DIR}/installation
ENIQ_CORE_INST_DIR=${ENIQ_INST_DIR}/core_install
ENIQ_LOG_DIR=${ENIQ_BASE_DIR}/local_logs
ENIQ_CONF_DIR=${ENIQ_INST_DIR}/config
DEPLOYMENT=/extra_params/deployment
ENIQ_DATA_DIR=${ENIQ_BASE_DIR}/data
ENIQ_DATA_MAPPING_DIR=${ENIQ_DATA_DIR}/mapping

# ENIQ DCUSER Directory
DCUSER=/eniq/home/dcuser/

# Source file containing the NAS password
source_file=/ericsson/storage/etc/sourcefile

# Mount directory
ENIQ_PORTBACKUP=${ENIQ_BASE_DIR}/portbackup

# Core etc dir
ENIQ_CORE_ETC_DIR=${ENIQ_CORE_INST_DIR}/etc

# ENIQ Admin Directory
ENIQ_ADMIN_DIR=${ENIQ_BASE_DIR}/admin
ENIQ_SENTINEL_DIR=${ENIQ_BASE_DIR}/sentinel
ENIQ_BACKUP_DIR=${ENIQ_BASE_DIR}/backup
ENIQ_CONNECTD_DIR=${ENIQ_BASE_DIR}/connectd

# Admin bin dir
ENIQ_ADMIN_BIN_DIR=${ENIQ_ADMIN_DIR}/bin

# ENIQ Core install script
ENIQ_CORE_INST_SCRIPT=${ENIQ_CORE_INST_DIR}/bin/eniq_core_install.bsh

# ENIQ Log Directory 
LOG_DIR=${ENIQ_BASE_DIR}/log 
SW_LOG_DIR=${LOG_DIR}/sw_log 

# ENIQ SW conf directory
CLI_CONF_DIR=${ENIQ_BASE_DIR}/sw/conf

# ENIQ SW PF directory
ENIQ_SW_PF_DIR=${ENIQ_BASE_DIR}/sw/platform

# ENIQ SW PF directory
ENIQ_SW_RUNTIME_DIR=${ENIQ_BASE_DIR}/sw/runtime
ENIQ_SW_JDK_SEC_DIR=${ENIQ_SW_RUNTIME_DIR}/jdk/jre/lib/security

# ENIQ SW Installer Directory
ENIQ_SW_INSTALLER_DIR=${ENIQ_BASE_DIR}/sw/installer

# Sentinel dir
ENIQ_SENTINEL_BIN_DIR=${ENIQ_SENTINEL_DIR}/bin
ENIQ_SENTINEL_ENV=${ENIQ_SENTINEL_DIR}/etc/sentinel.env

# ENIQ Bkup SW dir 
ENIQ_BKUP_SW_DIR=${ENIQ_BASE_DIR}/bkup_sw 
ENIQ_BKUP_SW_BIN_DIR=${ENIQ_BKUP_SW_DIR}/bin 

# Set the log for Create Snapshots stage
SNAPSHOT_LOGFILE_DIR=${SW_LOG_DIR}/rolling_snapshot_logs
SNAPSHOT_LOGFILE=${SNAPSHOT_LOGFILE_DIR}/prep_eniq_snapshots.log

# Migration Directories
MIGRATION_CORE=`$DIRNAME ${SCRIPTHOME}`
if [ "${ACTION_TYPE}" != "premigration" -a "${ACTION_TYPE}" != "prerecovery" ]; then
    MIGRATION_CORE=${ENIQ_CORE_INST_DIR}
fi
MIGRATION_HOME=`$DIRNAME ${MIGRATION_CORE}`

MIGRATION_BIN=${MIGRATION_CORE}/bin
MIGRATION_LIB=${MIGRATION_CORE}/lib
MIGRATION_ETC=${MIGRATION_CORE}/etc
MIGRATION_LOGDIR=${MIGRATION_HOME}/log

# ERICSSON Directory
ERICSSON_DIR=/ericsson 
ERICSSON_STOR_DIR=${ERICSSON_DIR}/storage
ERICSSON_BIN_DIR=${ERICSSON_STOR_DIR}/bin
ERICSSON_SAN_PLUGINS_DIR=${ERICSSON_STOR_DIR}/san/plugins
ERICSSON_CONF_DIR=${ERICSSON_DIR}/config

# Navisphere bin directory
NAVISPHERE=/opt/Navisphere/bin

# DDC monitor directory
DDC_MONITOR=/opt/ericsson/ERICddc/monitor/appl/ENIQ

# ENIQ Crontab Directory
CRONTABS_DIR=${VAR_DIR}/spool/cron

# ENIQ SMF location
ENIQ_SMF_MANIFEST_LOC="${VAR_DIR}/svc/manifest/eniq/runtime"
AUTO_LU_SMF_MANIFEST="${VAR_DIR}/svc/manifest/lu/"

# Hostname Information
HNAME=`${MYHOSTNAME}`
HOST_IP=`$GETENT hosts ${HNAME} | $AWK '{print $1}' | $HEAD -1`

# Root ETC directory
ROOT_ETC=${ENIQ_PORTBACKUP}/${HNAME}/ROOT/etc/

# Source the common functions
_common_functions_list_="common_functions.lib common_core_install_functions.lib common_migration_functions.lib"
for lib_file in ${_common_functions_list_}; do
    if [ -s ${MIGRATION_LIB}/${lib_file} ]; then
        . ${MIGRATION_LIB}/${lib_file}
    else
        _err_msg_="File ${MIGRATION_LIB}/${lib_file} not found"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi
done


conn_str_dba="-c \"uid=dba;pwd=${_dba_pass_} -host localhost -port ${_db_port_}\""
conn_str_dba_enc=${VAR_TMP_DIR}/conn_str_encrypt_dba.$$

# encrypt the connection string.
get_encrypt_file "${conn_str_dba}" "${conn_str_dba_enc}"


conn_str_db="-c \"eng=${_db_};links=tcpip{host=localhost;port=${_db_port_}};uid=dba;pwd=${_dba_pass_}\""
conn_str_db_enc=${VAR_TMP_DIR}/con_str_encrypt_db.$$

# encrypt the connection string.
get_encrypt_file "${conn_str_db}" "${conn_str_db_enc}"

conn_str_db_stop_ping="-q -c \"con=${_db_eng_};eng=${_db_eng_};links=tcpip{host=${_db_eng_};port=${_db_port_};dobroadcast=none;verify=no};uid=dba;pwd=${_dba_pass_}\""
conn_str_db_stop_ping_enc=${VAR_TMP_DIR}/con_str_encrypt_db_stop_ping.$$

# encrypt the connection string.
get_encrypt_file "${conn_str_db_stop_ping}" "${conn_str_db_stop_ping_enc}"


conn_str_db_ping="-q -c \"con=${_db_};eng=${_db_};links=tcpip{host=localhost;port=${_db_port_};dobroadcast=none;verify=no};uid=dba;pwd=${_dba_pass_}\""
conn_str_db_ping_enc=${VAR_TMP_DIR}/con_str_encrypt_db_ping.$$

# encrypt the connection string.
get_encrypt_file "${conn_str_db_ping}" "${conn_str_db_ping_enc}"

# File to hold stage information
STAGEFILE=${MIGRATION_ETC}/eniq_linux_migr_stage

# Migration status files
MIGR_PROGRESS=${VAR_DIR}/tmp/linux_${ACTION_TYPE}_in_progress
MIGR_SUCCESS=${VAR_DIR}/tmp/linux_${ACTION_TYPE}_success

# Rack migration Flag
ENIQ_MIGR_DIR=/var/tmp/migration
RACK_MIGRATION_IN_PROG=${ENIQ_MIGR_DIR}/rack_migration_in_progress

#Server host/ip temp list
SERVER_IP_LIST="/tmp/server_ip_list"

# Check config dir is present
if [ ! -d "${ENIQ_CONF_DIR}" ]; then
    _err_msg_="${ENIQ_CONF_DIR} is required for $ACTIVITY"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

# Determine SAN Device type if raw
if [ "${STORAGE_TYPE}" == "raw" ];then
    SAN_DEVICE=`$CAT ${ENIQ_CONF_DIR}/san_details | $EGREP "^SAN_DEVICE=" | $AWK -F\= '{print $2}'`
    if [ ! "${SAN_DEVICE}" ]; then
        _err_msg_="Could not read SAN_DEVICE type from ${ENIQ_CONF_DIR}/san_details."
        abort_script "${_err_msg_}"
    fi
fi

# File containing the type of installation. Eg. events or statistics
INST_TYPE_FILE=${ENIQ_CONF_DIR}/ericsson_use_config
if [ ! -s "${INST_TYPE_FILE}" ]; then
    _err_msg_="ENIQ install type not defined in ${INST_TYPE_FILE}"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi
# Read the installation type - should be "events" or "stats"
INSTALL_TYPE=`$CAT ${INST_TYPE_FILE} | $AWK -F\= '{print $2}'`

# Templates Directory
MIGRATION_TEMPL_DIR="${MIGRATION_CORE}/templates/${INSTALL_TYPE}"

# Get current server type
CURR_SERVER_TYPE=`$CAT ${ENIQ_CONF_DIR}/installed_server_type | $EGREP -v  '^[[:blank:]]*#' | $SED -e 's/ //g'`
if [ ! "${CURR_SERVER_TYPE}" ]; then
    _err_msg_="Could not determine which server type this is"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

# Templates Directory
ENIQ_TEMPL_DIR="${ENIQ_CORE_INST_DIR}/templates/${INSTALL_TYPE}"
NEW_TEMPL_DIR="${ENIQ_CORE_INST_DIR}/templates/${INSTALL_TYPE}"

# Determine the Sun_OS.ini file to be used from templates
INI_TEMPLATE_DIR=${ENIQ_CORE_INST_DIR}/templates/${INSTALL_TYPE}
if [ ! -d "${INI_TEMPLATE_DIR}" ]; then
     _err_msg_="${INI_TEMPLATE_DIR} directory not found"
     abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

# Determine SunOS.ini template file based on storage type
if [ "${STORAGE_TYPE}" == "raw" ];then
        # SunOS.ini_vnx template file will be used for clariion
        if [ "${SAN_DEVICE}" == "clariion" ]; then
           SUNOS_INI_TEMPLATE="SunOS.ini_vnx"
        else
           SUNOS_INI_TEMPLATE="SunOS.ini_${SAN_DEVICE}"
        fi

     OLD_SUNOS_INI_TEMPLATE="SunOS.ini_raw"

     if [ ! -s ${INI_TEMPLATE_DIR}/${SUNOS_INI_TEMPLATE} ]; then
          _err_msg_="${SUNOS_INI_TEMPLATE} file not found or empty."
          abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
     fi
fi

# Determine storage.ini template file based on deployment type
if [ -s ${ENIQ_CONF_DIR}/extra_params/deployment ]; then
    _deployment_=`$CAT ${ENIQ_CONF_DIR}/extra_params/deployment | $TR '[:upper:]' '[:lower:]'`

    case ${_deployment_} in
        small)  STORAGE_INI_TEMPLATE="storage_ini.sml"
                ;;
        medium) STORAGE_INI_TEMPLATE="storage_ini.med"
                ;;
        large)  STORAGE_INI_TEMPLATE="storage_ini.lrg"
                ;;
        extralarge) STORAGE_INI_TEMPLATE="storage_ini.extralrg"
                   ;;
        ft)     STORAGE_INI_TEMPLATE="storage_ini.ft"
                ;;
        vm)     STORAGE_INI_TEMPLATE="storage_ini.vm"
                ;;
    esac

    OLD_STORAGE_INI_TEMPLATE="${STORAGE_INI_TEMPLATE}"

    if [ ! -s ${INI_TEMPLATE_DIR}/${STORAGE_INI_TEMPLATE} ]; then
        _err_msg_="${INI_TEMPLATE_DIR}/${STORAGE_INI_TEMPLATE} not found, or is empty"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi
fi

# Determine niq.rc template file
ENIQ_ENV="niq.rc"
NIQ_RC_TEMPLATE="niq.rc"
if [ ! -s ${INI_TEMPLATE_DIR}/${NIQ_RC_TEMPLATE} ]; then
     _err_msg_="${INI_TEMPLATE_DIR}/${NIQ_RC_TEMPLATE} file not found or empty."
     abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi


# Get niq.ini template file
NIQ_INI_TEMPLATE="niq.ini"
if [ ! -s ${INI_TEMPLATE_DIR}/${NIQ_INI_TEMPLATE} ]; then
     _err_msg_="${INI_TEMPLATE_DIR}/${NIQ_INI_TEMPLATE} file not found or empty."
     abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

# Get RBAC.ini template file
RBAC_INI_TEMPLATE="RBAC.ini"
if [ ! -s ${INI_TEMPLATE_DIR}/${RBAC_INI_TEMPLATE} ]; then
     _err_msg_="${INI_TEMPLATE_DIR}/${RBAC_INI_TEMPLATE} file not found or empty."
     abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

# Get IPMP.ini template file
IPMP_INI_TEMPLATE="ipmp.ini"
if [ ! -s ${INI_TEMPLATE_DIR}/${IPMP_INI_TEMPLATE} ]; then
     _err_msg_="${INI_TEMPLATE_DIR}/${IPMP_INI_TEMPLATE} file not found or empty."
     abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

#Get unique pool name
UNIQUE_POOL_NAME="${CURR_SERVER_TYPE}_pool"

# ENIQ RepDB database directory
REP_DIR="${ENIQ_BASE_DIR}/database/rep_main"

# ENIQ DWHDB database directory
DWH_DIR="${ENIQ_BASE_DIR}/database/dwh_main"

# ENIQ DWH_READER database directory
DWH_READER_DIR="${ENIQ_BASE_DIR}/database/dwh_reader"

# LUN MAP INI Configuration file
LUN_MAP_INI="lun_map.ini"

# FLS config file
FLS_CONFIG_FILE=${ENIQ_CONF_DIR}/fls_conf

#UDEV File
UDEV_FILE=/etc/udev/rules.d/99-iq-raw-devs.rules

# Get CO server hostname
SERVICE_NAME_FILE=${ENIQ_CONF_DIR}/service_names
if [ ! -f "${SERVICE_NAME_FILE}" ]; then
    _err_msg_="${SERVICE_NAME_FILE} not found on server."
    abort_script "${_err_msg_}"
fi
CO_HOSTNAME=`$CAT ${SERVICE_NAME_FILE} | $GREP "dwhdb$" | $AWK -F"::" '{print $2}'`

# Migration config file
MIGRATION_CONF_FILE=linux_migration_${HNAME}.conf
MIGRATION_CONF=${ENIQ_CONF_DIR}/${MIGRATION_CONF_FILE}

# Check if server is coordinator type
CO_SERVER=""
if [ "${CURR_SERVER_TYPE}" == "stats_coordinator" -o "${CURR_SERVER_TYPE}" == "eniq_coordinator" -o "${CURR_SERVER_TYPE}" == "eniq_stats" -o "${CURR_SERVER_TYPE}" == "eniq_events" ]; then 
    CO_SERVER="YES"
fi

# Check if server is Reader type
RD_SERVER=""
if [ "${CURR_SERVER_TYPE}" == "stats_iqr" -o "${CURR_SERVER_TYPE}" == "eniq_iqr" ]; then
    RD_SERVER="YES"
fi

# Zpool backup directory
ZPOOL_FOR_BACKUP=eniq_sp_1
BACKUP_DIR=${ZPOOL_FOR_BACKUP}/migration_root_backup

# Config files backup directory
CONFIG_BACKUP_DIR=${ENIQ_CONF_DIR}/conf_bkup_migration

# Migration SW backup directory
MIG_SW_DIR_NAME=migration_sw
MIG_SW_BACKUP_DIR=${ENIQ_BACKUP_DIR}/${MIG_SW_DIR_NAME}
MIGR_CO_CONF=${MIG_SW_BACKUP_DIR}/migration_${CO_HOSTNAME}.conf

# Healthcheck files
HEALTHCHECK_SCRIPT=${ENIQ_CORE_INST_DIR}/eniq_checks/bin/eniq_checks.bsh
HEALTH_SUMMARY_DIR=${ENIQ_BASE_DIR}/log/precheck/summary

# Configuration flags
MIGRATE_CO=${VAR_DIR}/tmp/migrate_co

if [ "${STORAGE_TYPE}" = raw ]; then
    # Host Agent IP
    HOST_AGENT_IP=`read_value HOST_AGENT_IP ${MIGRATION_CONF}` || abort_script "${HOST_AGENT_IP}" "${EXEC_SHELL_CMD}"
    
    # Get SAN device name
    SAN_DEVICE_NAME=`read_value STORAGE_NAME_1 ${MIGRATION_CONF}` || abort_script "${SAN_DEVICE_NAME}" "${EXEC_SHELL_CMD}"
    
    # Get newly create LUN ID
    RECREATED_LUN_ID=`read_value RECREATED_LUN_ID ${MIGRATION_CONF}` || abort_script "${RECREATED_LUN_ID}" "${EXEC_SHELL_CMD}"
fi

# Get installed server type
_installed_server_type_=`$CAT ${ENIQ_CONF_DIR}/installed_server_type`

# Read location of storage API command
_stor_api_cmd_=`iniget STOR_API -f ${ENIQ_CONF_DIR}/${SUNOS_INI} -v STOR_API_CMD`
if [ ! "${_stor_api_cmd_}" ]; then
    _err_msg_="Could not read STOR_API_CMD param from ${ENIQ_CONF_DIR}/${SUNOS_INI}"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

# BACKUP_REPLACE_DIR_NAME
BACKUP_REPLACE_DIR=replacement_root_backup
MOUNT_POINT_BKUP=/eniq/replacement

# Volume group backup directory
VOLUME_GROUP_FOR_BACKUP=${CURR_SERVER_TYPE}_pool

# Continue migration conf directories/files
CONT_MIG_DIR=/var/tmp/continue_migration
CONT_USER_CONF=${CONT_MIG_DIR}/migration_input.conf

# Flag to check if features are selected or not
NO_FEATURE_SELECTED=${VAR_TMP_DIR}/no_features
}

### Function: setup_SMF_scripts ###
# 
# Set up SMF start/stop scripts
# 
# Arguments:
#   none
# Return Values:
#   none
setup_SMF_scripts()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling setup_SMF_scripts stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s setup_SMF_scripts ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - setup_SMF_scripts"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: set_next_stage ###
#
# Set up the stage to be run
#
# Arguments:
#   $1 : Stage to be set to. Either numeric value or last stage of stagefile
# Return Values:
#   none
set_next_stage()
{
# Do I have to reset stage
if [ "${USER_STAGE}" -a "${NO_RESET_STAGE}" ]; then
    return 0
fi

_stage_time_=`$DATE '+%Y-%b-%d_%H.%M.%S'`
$ECHO "# Setting new stage at $_stage_time_" > ${STAGEFILE} | $TEE -a ${LOGFILE}
$ECHO "${ENIQ_CORE_STAGES[$1]} " >> ${STAGEFILE} | $TEE -a ${LOGFILE}
}


### Function: show_server_info ###
#
#   Display current server info
#
# Arguments:
#   none
# Return Values:
#   none
show_server_info()
{
if [ ! "${SOLARIS_11}" ];then
    _system_config_=`dmidecode | grep -i Gen | xargs`
    _system_release_=`cat /etc/redhat-release | head -1 | xargs`
else
    _system_config_=`/usr/sbin/prtdiag | head -1`
    _system_release_=`cat /etc/release | head -1 | xargs`
fi

log_msg -s "******* Current System Information *********" -l ${LOGFILE}
$ECHO "=============================================="
log_msg -s "${_system_config_}" -l ${LOGFILE}
log_msg -s "OS Version:   ${_system_release_}" -l ${LOGFILE}

$ECHO "=============================================="
}


### Function: start_eniq_services ###
#
# Start all ENIQ services
#
# Arguments:
#   none
# Return Values:
#   none
start_eniq_services()
{
# Ensure NASd is online
if [ "${STORAGE_TYPE}" == "raw" ]; then
    check_and_manage_smf ${NASd_SMF_ID} enable
fi

# Ensure licensing service is online
if [ "${CO_SERVER}" ];then
    check_and_manage_smf ${SENTINEL_SMF_ID} enable
fi

# Enable all the ENIQ services
log_msg -l ${LOGFILE} -s "Starting the ENIQ services on $HNAME. Please wait..."
$BASH ${ENIQ_ADMIN_DIR}/bin/manage_eniq_services.bsh -a start -s ALL -N >> ${LOGFILE}
if [ $? -ne 0 ]; then
    _err_msg_="Failed to start ENIQ services."
    abort_script "$_err_msg_"
fi
}


### Function: stop_eniq_services ###
#
# Stop all ENIQ services
#
# Arguments:
#   none
# Return Values:
#   none
stop_eniq_services()
{

# Get the System User/Group. All directories are owned by this
SYSUSER=`iniget ENIQ_INSTALL_CONFIG -f ${ENIQ_CONF_DIR}/${SUNOS_INI} -v ENIQ_SYSUSER`
if [ ! "${SYSUSER}" ]; then
    _err_msg_="Could not read SYSUSER param from ${ENIQ_CONF_DIR}/${SUNOS_INI}"
    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

# Ensure NASd is online
if [ "${STORAGE_TYPE}" == "raw" ]; then
    check_and_manage_smf ${NASd_SMF_ID} enable
fi

$BASH ${ENIQ_ADMIN_DIR}/bin/manage_eniq_services.bsh -a list -s ALL -N >> /dev/null 2>&1
if [ $? -eq 0 ];then
   log_msg -s "\nENIQ services need to be stopped before recovery." -l ${LOGFILE}
   # Disable all the ENIQ services
   log_msg -l ${LOGFILE} -s "Stopping the ENIQ services on $HNAME. Please wait..."
   $BASH ${ENIQ_ADMIN_DIR}/bin/manage_eniq_services.bsh -a stop -s ALL -N >> ${LOGFILE}
    if [ $? -ne 0 ]; then
        _err_msg_="Failed to stop ENIQ services."
        abort_script "$_err_msg_"
    fi
else
 # Stopping all ENIQ related processes started using the administrator scripts
    log_msg -t -s "Stopping all ENIQ related processes started using the administrator scripts" -l ${LOGFILE} 
   for _service_ in `$CAT ${ENIQ_ADMIN_DIR}/etc/smf_contract_config |$GREP "${CURR_SERVER_TYPE}"|$GREP -w ENIQ|$GREP -w "Y"|$AWK -F"::" '{print $3}'` 
   do 
    # Check status of the ENIQ services
     _load_status_=`$SYSTEMCTL show -p LoadState eniq-${_service_} | $CUT -f2 -d=` 
     if [ "${_load_status_}" == "loaded" ];then
        if [ "${_service_}" == "fls" -a ! -f "${FLS_CONFIG_FILE}" ]; then
            continue
        else 
            $SU - $SYSUSER -c "/eniq/smf/bin/eniq_smf_start_stop.sh -a stop -s ${_service_}" >> ${LOGFILE}
            if [ $? -ne 0 ]; then
                _err_msg_="Failed to stop ${_service_} using the administrator scripts"
                abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
            fi
        fi
     fi
   done
  
fi
}

### Function: stop_smf_services ###
#
# Stop all SMF services
#
# Arguments:
#   none
# Return Values:
#   none
stop_smf_services()
{
# Get the SMF list to disable
smf_list="${SENTINEL_SMF_ID} ${DDC_SMF_ID} ${HOSTSYNC_SMF_ID}"
if [ "${STORAGE_TYPE}" == "raw" ]; then
    # Disable NAS, hostsync, ddc and auto_lu services
    smf_list="${smf_list} ${NASd_SMF_ID}"
else
    smf_list="${smf_list} ${CRON_SMF_ID}"
fi

for _smf_ in ${smf_list}; do
    $SYSTEMCTL -a |$GREP ${_smf_} |$AWK '{if (NR!=1) {print $2}}' >> /dev/null 2>&1
    if [ $? -ne 0 ];then
        continue
    fi
    log_msg -l ${LOGFILE} -s "Disabling service ${_smf_}"
    check_and_manage_smf ${_smf_} disable
    if [ $? -ne 0 ]; then
        _err_msg_="Failed to stop SMF service ${_smf_}."
        abort_script "$_err_msg_"
    fi
done
}

### Function: truncate_transaction_log ###
#
# Truncates the transaction log for specified database
#
# Arguments: 
#           $1 = Database (dwhdb/repdb)
#           $2 = Database configuration file (dwhdb.cfg/repdb.cfg)
#           $3 = Database configuration file path
#           $4 = Database port
#           $5 = Database DBA password
#           $6 = Database software binary folder
#
# Return Values: none
truncate_transaction_log()
{
local _db_=$1
local _cfg_filename_=$2
local _cfg_path_db_=$3
local _db_port_=$4
local _dba_pass_=$5
local _sw_folder_=$6

local _cfg_full_filename_="${_cfg_path_db_}/${_cfg_filename_}"
local _cfg_backup_filename_="${_db_}_backup.cfg"

# Backup the configuration file
log_msg -t -s "Backing up the original ${_cfg_full_filename_} file" -l ${LOGFILE}
$SU - $SYSUSER -c "$CP -pf ${_cfg_full_filename_} ${_cfg_path_db_}/${_cfg_backup_filename_}"
backup_return=$?
if [ ${backup_return} -ne 0 ]; then
    _err_msg_="Could not backup ${_cfg_full_filename_}"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi 

$SU - $SYSUSER -c ". /eniq/sybase_iq/SYBASE.sh;${_sw_folder_}/bin64/dbping @${conn_str_db_ping_enc}" >> ${LOGFILE} 2>&1
ping_return=$?
if [ ${ping_return} -ne 0 ]; then
    log_msg -t -s "Trying to start ${_db_} as initial ping did not respond."  -l ${LOGFILE}
    log_msg -t -s "Starting Database ${_db_}" -l ${LOGFILE}
    database_start_stop "${_db_}" "start" >> ${LOGFILE}
    start_return=$?
    if [ ${start_return} -ne 0 ]; then
        _err_msg_="Could not start ${_db_}"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi

    $SU - ${SYSUSER} -c ". /eniq/sybase_iq/SYBASE.sh;${sw_folder}/bin64/dbping @${conn_str_db_ping_enc}" >> ${LOGFILE} 2>&1
    ping_return_2=$?
    if [ ${ping_return_2} -ne 0 ]; then
        _err_msg_="Could not ping database. The database should be started to begin truncation of log. Aborting script"
        restore_backup_file "${_cfg_path_db_}" "${_cfg_full_filename_}" "${_cfg_backup_filename_}"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi
fi

# Running SQL to commit changes
log_msg -t -s "Running SQL in the database."  -l ${LOGFILE}
$SU - ${SYSUSER} -c ". /eniq/sybase_iq/SYBASE.sh;dbisql -nogui @${conn_str_db_enc}   \"commit; checkpoint; checkpoint; checkpoint;\" "
sql_return=$?
if [ ${sql_return} -ne 0 ]; then
    _err_msg_="Could not execute sql commands."
    restore_backup_file "${_cfg_path_db_}" "${_cfg_full_filename_}" "${_cfg_backup_filename_}" 
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

log_msg -t -s "Stopping Database ${_db_}" -l ${LOGFILE}
database_start_stop "${_db_}" "stop" >> ${LOGFILE}
stop_return=$?
if [ ${stop_return} -ne 0 ]; then
    _err_msg_="Could not stop ${_db_}"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

# Adding truncate command to cfg for start up
$ECHO -m >> ${_cfg_full_filename_}

# Starting database with -m .cfg file
log_msg -t -s "Starting the database with -m flag to truncate transaction log." -l ${LOGFILE}
log_msg -t -q -s "Starting Database ${_db_}" -l ${LOGFILE}
database_start_stop "${_db_}" "start" >> ${LOGFILE}
start_return=$?
if [ ${start_return} -ne 0 ]; then
    _err_msg_="Could not start ${_db_}"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

# Restoring the original configuration file and restarting database
restore_backup_file "${_cfg_path_db_}" "${_cfg_full_filename_}" "${_cfg_backup_filename_}"

log_msg -t -s "Restarting the database."  -l ${LOGFILE}

log_msg -t -q -s "Stopping Database ${_db_}" -l ${LOGFILE}
database_start_stop "${_db_}" "stop" >> ${LOGFILE}
stop_return=$?
if [ ${stop_return} -ne 0 ]; then
    _err_msg_="Could not stop ${_db_}"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

log_msg -t -q -s "Starting Database ${_db_}" -l ${LOGFILE}
database_start_stop "${_db_}" "start" >> ${LOGFILE}
start_return=$?
if [ ${start_return} -ne 0 ]; then
    _err_msg_="Could not start ${_db_}"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

if [ -f ${_cfg_path_db_}/${_db_}.log ]; then
    log_msg -t -s "Renaming the database transaction log from dwhdb.log to dwhdb.tran."  -l ${LOGFILE}
    log_msg -t -s "Stopping Database ${_db_}" -l ${LOGFILE}
    database_start_stop ${_db_} stop >> ${LOGFILE}
    stop_return=$?
    if [ ${stop_return} -ne 0 ]; then
        _err_msg_="Could not stop ${_db_}"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi

    $SU - $SYSUSER -c ". /eniq/sybase_iq/SYBASE.sh;dblog -t ${_cfg_path_db_}/${_db_}.tran ${_cfg_path_db_}/${_db_}.db"
    if [ $? -ne 0 ]; then
        _err_msg_="Could not rename the transaction log."
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi

    log_msg -t -s "Starting Database ${_db_}" -l ${LOGFILE}
    database_start_stop "${_db_}" "start" >> ${LOGFILE}
    start_return=$?
    if [ ${start_return} -ne 0 ]; then
        _err_msg_="Could not start ${_db_}"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi

    $RM -f ${_cfg_path_db_}/${_db_}.log
else
    log_msg -t -s "The database transaction log has already be renamed."  -l ${LOGFILE}
fi
}

### Function: unmount_lvm ###
#
#   Un-mounting the file-systems
#
# Arguments:
#   none
# Return Values:
#   none
unmount_lvm()
{
_fs_list_file_=`$CAT /etc/fstab |$GREP ${_installed_server_type_}_pool |$AWK '{print $2}' |$GREP -v swap`
for _filesystem_list_ in ${_fs_list_file_}
do
    log_msg -s "Un-mounting the file-system ${_filesystem_list_}\n" -l ${LOGFILE} >> /dev/null 2>&1

    _proc_id_file_=`$LSOF |$GREP ${_filesystem_list_} |$AWK '{print $2}'`
    if [ ! -z "${_proc_id_file_}" ]; then
        for  _processid_ in ${_proc_id_file_}
        do
            $KILL -9 ${_processid_} >> /dev/null 2>&1
            if [ $? -ne 0 ]; then
                _err_msg_="Could not kill process of ${_filesystem_list_}"
                abort_script "${_err_msg_}"
            fi
        done
    fi
    $UMOUNT  ${_filesystem_list_} >> /dev/null 2>&1
    if [ $? -ne 0 ]; then
        _err_msg_="Could not unmount ${_filesystem_list_}"
        mount_lvm
        abort_script "${_err_msg_}"
    else
        log_msg -s "Successfully un-mounted the file-system ${_filesystem_list_}\n" -l ${LOGFILE}
    fi
done
}

### Function: update_attributes ###
#
#   Update attributes of ini file according to the template
#
# Arguments:
#   $1 : Copy of real ini file present in config directory
#   $2 : Copy of template ini file
# Return Values:
#   0 success 1 error
update_attributes()
{
unset INI_FILE TMPL_FILE
if [ "$1" -a "$2" ]; then
    INI_FILE=`$ECHO $1 | $SED 's/ //g'`
    TMPL_FILE=`$ECHO $2 | $SED 's/ //g'`
else
    _error_msg_="Argument has a null value. Unable to update attributes."
    abort_script "${_error_msg_}"
fi

# Find blocks present in template file
_block_list_=`$CAT ${TEM_DIR}/${TMPL_FILE} | $GREP '\[.*\]' | $EGREP -v 'SunOS_DIRECTORY|SunOS_ZFS_FS' | ${CUT} -f 2 -d [ | ${CUT} -f 1 -d ]`
if [ ! "${_block_list_}" ]; then
    _error_msg_="Could not fetch block list from ${TEM_DIR}/${TMPL_FILE} file."
    abort_script "${_error_msg_}"
fi

# Check if any duplicate block is present in the template
$ECHO ${_block_list_} | $TR ' ' '\n' > ${TEM_DIR}/block_list
_duplicate_blocks_=`$CAT ${TEM_DIR}/block_list | $SORT | $UNIQ -d`
if [ "${_duplicate_blocks_}" != "" ];then
    log_msg -l ${LOGFILE} -q -s "Duplicate blocks: ${_duplicate_blocks_}"
    _err_msg_="Duplicate entry of blocks found in ${INI_FILE} template file."
    abort_script "$_err_msg_"
else
    log_msg -l ${LOGFILE} -q -s "No Duplicate Block found in ${INI_FILE} file."
fi

# Copy the whole template to temporary ini file
$CP ${TEM_DIR}/${TMPL_FILE} ${TEM_DIR}/${INI_FILE}.tmp
if [ $? -ne 0 ]; then
    _error_msg_="Could not create ${TEM_DIR}/${INI_FILE}.tmp file."
    abort_script "${_error_msg_}"
fi

# Ensure everything in template is present in real file
# - preserve existing settings in real file
# - and set in real file anything extra found in template (additional blocks/attributes)
for _block_ in ${_block_list_}; do
    log_msg -l ${LOGFILE} -q -s "Checking attributes of block ${_block_} in ${TEM_DIR}/${INI_FILE}.tmp"
    # Get the attibutes of a block in template, and check each is set in real file
    _template_attribs_=`iniget ${_block_} -f "${TEM_DIR}/${TMPL_FILE}"`
    for _name_value_ in ${_template_attribs_}; do
        if [[ ${_name_value_} == *=* ]]; then
            _name_=`$ECHO ${_name_value_} | $CUT -f 1 -d "="`
            _template_value_=`$ECHO ${_name_value_} | $CUT -f 2 -d "="`
            _real_value_=`iniget ${_block_} -f ${TEM_DIR}/${INI_FILE} -v ${_name_}`
            if [ "${_template_value_}" != "${_real_value_}" ]; then
                # Attribute is not set in real file
                if [ ! "${_real_value_}" ]; then
                    # Real file doesn't have a value
                    log_msg -l ${LOGFILE} -q -s "Setting template value ${_template_value_} of parameter ${_name_} in ${TEM_DIR}/${INI_FILE}.tmp"
                    iniset ${_block_} -f ${TEM_DIR}/${INI_FILE}.tmp "${_name_}=${_template_value_}"
                    if [ $? -ne 0 ]; then
                        _error_msg_="Could not set \"${_name_}=${_template_value_}\" ${TEM_DIR}/${INI_FILE}.tmp file."
                        abort_script "${_error_msg_}"
                    fi
                else
                    # Real file has a value; set real value
                    log_msg -l ${LOGFILE} -q -s "Setting real value ${_real_value_} of parameter ${_name_} in ${TEM_DIR}/${INI_FILE}.tmp"
                    iniset ${_block_} -f ${TEM_DIR}/${INI_FILE}.tmp "${_name_}=${_real_value_}"
                    if [ $? -ne 0 ]; then
                        _error_msg_="Could not set \"${_name_}=${_real_value_}\" ${TEM_DIR}/${INI_FILE}.tmp file."
                        abort_script "${_error_msg_}"
                    fi
                fi
            fi
        else
            log_msg -l ${LOGFILE} -q -s "Sub-block ${_name_value_} should be copied from template file."
        fi
    done


    # Check if real file has any extra attribute
    # Fetch the contents of the current block from real and temp ini file
    $RM -rf ${TEM_DIR}/realini_attribs ${TEM_DIR}/tempini_attribs
    iniget ${_block_} -f ${TEM_DIR}/${INI_FILE} >> ${TEM_DIR}/realini_attribs
    iniget ${_block_} -f ${TEM_DIR}/${INI_FILE}.tmp >> ${TEM_DIR}/tempini_attribs

    diff ${TEM_DIR}/realini_attribs ${TEM_DIR}/tempini_attribs > /dev/null 2>&1
    if [ $? -eq 1 ]; then
        while read _entry_ ; do
            if [[ ${_entry_} == *=* ]]; then
                $CAT ${TEM_DIR}/tempini_attribs | $GREP "$_entry_" >> /dev/null 2>&1
                if [ $? -ne 0 ]; then
                    log_msg -l ${LOGFILE} -q -s "Adding new attribute $_entry_ to ${TEM_DIR}/${INI_FILE}.tmp"
                    # Append the extra attribute in new file
                    $ECHO "${_entry_}" >> ${TEM_DIR}/tempini_attribs
                    # Remove the block's existing content
                    # Copy the whole content of the updated new file
                    iniset $_block_ -f ${TEM_DIR}/${INI_FILE}.tmp del
                    while read _line_; do
                        iniset ${_block_} -f ${TEM_DIR}/${INI_FILE}.tmp "$_line_"
                    done < ${TEM_DIR}/tempini_attribs
                    # To solve the space issue with the next block header
                    $CP ${TEM_DIR}/${INI_FILE}.tmp ${TEM_DIR}/${INI_FILE}.tmp1
                    iniset ${_block_} -f ${TEM_DIR}/${INI_FILE}.tmp1 " "
                    $CAT ${TEM_DIR}/${INI_FILE}.tmp1 | $SED "s/ = //g" > ${TEM_DIR}/${INI_FILE}.tmp
                fi
            fi
        done < ${TEM_DIR}/realini_attribs
        log_msg -l ${LOGFILE} -q -s "Successfully updated block ${_block_} in ${TEM_DIR}/${INI_FILE}.tmp"
    else
        log_msg -l ${LOGFILE} -q -s "No extra attribute present for the block ${_block_} in ${INI_FILE}"
    fi
done

# Check for new blocks present in real file
# Append the extra block to the temp ini file
_real_block_list_=`$CAT ${TEM_DIR}/${INI_FILE} | $GREP '\[.*\]' | $EGREP -v 'SunOS_DIRECTORY|SunOS_ZFS_FS' | ${CUT} -f 2 -d [ | ${CUT} -f 1 -d ]`

if [ "${_real_block_list_}" != "${_block_list_}" ]; then
    for _item_ in ${_real_block_list_}; do
        $ECHO ${_block_list_} | $GREP ${_item_} >> /dev/null 2>&1
        if [ $? -ne 0 ]; then
            # Check if block has parent block
            # if it has then parent block should contain ${_item_} as attribute
            _parent_block_arg_=""
            $CAT ${TEM_DIR}/${INI_FILE} | $GREP -w "${_item_}" >> /dev/null 2>&1
            if [ $? -eq 0 ]; then
                # Parent block exists. Need to set block name in parent block
                _parent_block_arg_=""
                for _block_value_ in ${_real_block_list_}; do
                    _real_attribs_=`iniget ${_block_value_} -f "${TEM_DIR}/${INI_FILE}"`
                    for _name_value_ in ${_real_attribs_}; do
                        if [ "${_name_value_}" == "${_item_}" ];then
                            _parent_block_arg_="-g ${_block_value_}"
                            break
                        fi
                    done
                    if [ "${_parent_block_arg_}" ]; then
                        break
                    fi
                done
            fi
            # Add the extra real ini block
            log_msg -l ${LOGFILE} -s "Adding extra block ${_item_} in ${TEM_DIR}/${INI_FILE}.tmp"
            $RM -rf ${TEM_DIR}/block_attribs ${TEM_DIR}/${INI_FILE}.iniadd
            $ECHO "[${_item_}]" > ${TEM_DIR}/block_attribs
            iniget ${_item_} -f ${TEM_DIR}/${INI_FILE} >> ${TEM_DIR}/block_attribs
            log_msg -l ${LOGFILE} -q -s "Executing command: \n$INIADD ${_parent_block_arg_} -p ${_item_} -i ${TEM_DIR}/${INI_FILE}.tmp -d ${TEM_DIR}/block_attribs -o ${TEM_DIR}/${INI_FILE}.iniadd"
            $INIADD ${_parent_block_arg_} -p ${_item_} -i ${TEM_DIR}/${INI_FILE}.tmp -d ${TEM_DIR}/block_attribs -o ${TEM_DIR}/${INI_FILE}.iniadd
            if [ $? -ne 0 ]; then
                _err_msg_="Error in adding extra block ${_item_} from ${TEM_DIR}/${INI_FILE}.tmp."
                abort_script "$_err_msg_"
            fi
            $CP ${TEM_DIR}/${INI_FILE}.iniadd ${TEM_DIR}/${INI_FILE}.tmp
            log_msg -l ${LOGFILE} -s "Successfully set block ${_item_} in ${TEM_DIR}/${INI_FILE}.tmp"
        fi
    done
fi

$CP ${TEM_DIR}/${INI_FILE}.tmp ${TEM_DIR}/${INI_FILE}
if [ $? -ne 0 ]; then
    _err_msg_ "Unable to merge attributes/blocks in ${INI_FILE} file from template."
    abort_script "$_err_msg_"
fi
$ECHO "INFO: Successfully merged attributes/blocks in ${INI_FILE} file from template."

return 0
}

### Function: update_dboptions ###
#
# Updates database options
#
# Arguments:
#           $1 = Database (dwhdb/repdb)
#
# Return Values: none
update_dboptions()
{
local _db_=$1

# Change ownership of dboptions file
$CHOWN $SYSUSER:$SYSGRP ${ENIQ_ADMIN_DIR}/sql/*
if [ $? -ne 0 ]; then
     _err_msg_="${SCRIPTHOME}/dboptions_${_db_}.bsh was not successful\n" 
     abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

$SU - $SYSUSER -c "$BASH ${SCRIPTHOME}/dboptions_${_db_}.bsh -l ${LOGFILE} -c ${CLI_CONF_DIR} -d ${CLI_CONF_DIR}/${ENIQ_INI}"
if [ $? -ne 0 ]; then
     _err_msg_="${SCRIPTHOME}/dboptions_${_db_}.bsh was not successful\n" 
     abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi
}

### Function: update_ENIQ_env_files ###
#
# Update ENIQ env file
#
# Arguments:
#   none
# Return Values:
#   none
update_ENIQ_env_files()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling update_ENIQ_env_files stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s update_ENIQ_env_files -u ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - update_ENIQ_env_files"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: update_disk_partition ###
#
# To update disk partitions file
#
# Arguments:
#   none
# Return Values:
#   none
update_disk_partition()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

# Getting the disks which are already partitioned
if [ "${STORAGE_TYPE}" == "raw" ]; then
    for (( _count_=0;${_count_}<2;_count_++ ));do
        $RM -f ${TEM_DIR}/listluns.txt
        ${_stor_api_cmd_} --action listluns | $GREP -vw "${SAN_DEVICE_NAME}@${RECREATED_LUN_ID}" | $AWK -F";" '{print $2}' > ${TEM_DIR}/partition_disk_list
        if [ $? -ne 0 ]; then
            # exit from script if return code non-zero
            _err_msg_="Couldn't get list of partitioned disks."
            abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
        else
            # check if listluns.txt has content in case return code is zero
             if [ ! -s ${TEM_DIR}/partition_disk_list ]; then
                continue
            fi
        fi
        break
    done

#check if blkcli listing the partitioned disks
    if [ ! -s ${TEM_DIR}/partition_disk_list ]; then
        _err_msg_="No SAN luns are visible. blkcli output is empty"
        abort_script "${_err_msg_}"
    fi

fi

# Check if there are disks for which mpath value is not assigned
$CAT ${TEM_DIR}/partition_disk_list | $GREP -v mpath >> /dev/null 2>&1
if [ $? -eq 0 ]; then
    if [ ! -f ${VAR_TMP_DIR}/reboot_required ]; then
        ## Adding multipath module to initramfs before reboot
        log_msg -s "Adding multipath module to initramfs" -l ${LOGFILE}

        $DRACUT --force --add multipath --include /etc/multipath >> /dev/null 2>&1
        if [ $? -ne 0 ]; then
            _err_msg_="Failed to add multipath module to initramfs using DRACUT"
            abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
        fi
        
        $TOUCH ${VAR_TMP_DIR}/reboot_required
        log_msg -s  "Rebooting the server to assign mpath value for the disk" -l ${LOGFILE}
        $REBOOT
    else
         $RM -rf ${VAR_TMP_DIR}/reboot_required
        _err_msg_="For some disks mpath value is not assigned"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi
fi

# Updating partitioned data disks
if [ -f ${TEM_DIR}/partition_disk_list ]; then
    log_msg -s "Updating partitioned data disks in ${ENIQ_CONF_DIR}/disks_partitioned file" -l ${LOGFILE}
    $CAT ${TEM_DIR}/partition_disk_list > ${ENIQ_CONF_DIR}/disks_partitioned
    if [ $? -ne 0 ]; then
        _err_msg_="Could not update ${ENIQ_CONF_DIR}/disks_partitioned"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: update_database_config_file
#
# Migrate SQL Anywhere Database
#
# Arguments:
#       none
# Return Values:
#    none 
update_database_config_file()
{
local _db_=$1
local _db_dir_=$2

log_msg -s "\nDeploying ${_db_} configuration files..." -l ${LOGFILE}

if [ -f ${ENIQ_ADMIN_DIR}/sybase_conf/${_db_}.cfg ]; then
    log_msg -t -q -s "Copying ${_db_}.cfg from ${ENIQ_ADMIN_DIR}/sybase_conf to ${_db_dir_}" -l ${LOGFILE}
    $CP ${ENIQ_ADMIN_DIR}/sybase_conf/${_db_}.cfg ${_db_dir_}/${_db_}.cfg
    if [ $? -ne 0 ]; then
         _err_msg_="Could not copy ${_db_dir_}/${_db_}.cfg"
         abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi

    if [ "${_db_}" == "dwhdb" ]; then
         _tmp_cfg_=${_db_dir_}/${_db_}.cfg.tmp
         $CAT ${_db_dir_}/${_db_}.cfg | $SED -e "s|@@path_to_log@@|${IQLOGDIR}|" -e "s|@@dwh_instance@@|dwhdb|g" > ${_tmp_cfg_}
         if [ $? -ne 0 ]; then
             _err_msg_="Could not update ${_db_dir_}/${_db_}.cfg"
             abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
         fi
         
         $MV ${_tmp_cfg_} ${_db_dir_}/${_db_}.cfg
         if [ $? -ne 0 ]; then
             _err_msg_="Could not set ${_db_dir_}/${_db_}.cfg"
             abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
         fi
    fi

    log_msg -t -q -s "Changing permission of ${_db_dir_}/${_db_}.cfg to -r--r-----" -l ${LOGFILE}
    $CHMOD 440 ${_db_dir_}/${_db_}.cfg | $TEE -a ${LOGFILE}
    if [ $? -ne 0 ]; then
        _err_msg_="Could not change permissions of ${_db_dir_}/${_db_}.cfg to -r--r-----"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi

    log_msg -t -q -s "Changing ownership of ${_db_dir_}/${_db_}.cfg to ${SYSUSER}:${SYSGRP}" -l ${LOGFILE}
    $CHOWN ${SYSUSER}:${SYSGRP} ${_db_dir_}/${_db_}.cfg
    if [ $? -ne 0 ]; then
        _err_msg_="Could not change ownership of ${_db_dir_}/${_db_}.cfg to ${SYSUSER}:${SYSGRP}"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi
else
    _err_msg_="File ${ENIQ_ADMIN_DIR}/sybase_conf/${_db_}.cfg does not exist"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi
}

### Function: update_dns_files ###
#
# Updates DNS files
#
# Arguments:
#   none
# Return Values:
#   none
update_dns_files()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling update_dns_files stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s update_dns_files ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - update_dns_files"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: update_ipmp_group_info ###
#
#   Update interfaces in ipmp.ini for migration
#
# Arguments:
#           $1 = Interface Group Block in ipmp.ini i.e IPMP_INTF_1 or IPMP_INTF_2 or IPMP_INTF_3
#           $2 = Interfaces pertaining to each interface group i.e PM Services, Storage VLAN or Backup VLAN
#           $3 = IP Address pertaining to each interface group i.e PM Services, Storage VLAN or Backup VLAN
#           $4 = Netmask IP Address pertaining to each interface group i.e PM Services, Storage VLAN or Backup VLAN
#           $5 = DaGateway IP Address pertaining to each interface group i.e PM Services, Storage VLAN or Backup VLAN
#           $6 = ARP Target IPs pertaining to each interface group i.e PM Services, Storage VLAN or Backup VLAN
# Return Values: none
update_ipmp_group_info()
{
local _interface_group_block_=$1
local _interfaces_=$2
local _ip_address_=$3
local _netmask_ip_=$4
local _gateway_ip_=$5
local _arp_target_=$6

if [ "${_interface_group_block_}" == "IPMP_INTF_2" -o "${_interface_group_block_}" == "IPMP_INTF_3" -o "${_interface_group_block_}" == "IPMP_INTF_4" ]; then
      iniset ${_interface_group_block_} -f ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} BONDING_ENABLE="Y"
      if [ $? -ne 0 ]; then
          _err_msg_="Could not set BONDING_ENABLE="Y" in ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}"
          abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
      fi
fi

if [ "${_interface_group_block_}" == "IPMP_INTF_4" ]; then
      iniset ${_interface_group_block_} -f ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} IPMP_Group_Name="enm_stor_grp"
      if [ $? -ne 0 ]; then
          _err_msg_="Could not set BONDING_ENABLE="Y" in ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}"
          abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
      fi

      iniset ${_interface_group_block_} -f ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} IPMP_VLAN_Group_Name="ENM Storage Group"
      if [ $? -ne 0 ]; then
          _err_msg_="Could not set BONDING_ENABLE="Y" in ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}"
          abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
      fi
fi

iniset ${_interface_group_block_} -f ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} IPMP_Group_Intf="${_interfaces_}"
if [ $? -ne 0 ]; then
    _err_msg_="Could not set IPMP_Group_Intf="${_interfaces_}" in ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

iniset ${_interface_group_block_} -f ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} IPMP_Group_IP=${_ip_address_}
if [ $? -ne 0 ]; then
    _err_msg_="Could not set IPMP_Group_IP=${_ip_address_} in ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

iniset ${_interface_group_block_} -f ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} IPMP_Group_Netmask=${_netmask_ip_}
if [ $? -ne 0 ]; then
    _err_msg_="Could not set IPMP_Group_Netmask=${_netmask_ip_} in ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

iniset ${_interface_group_block_} -f ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} IPMP_Group_Gateway=${_gateway_ip_}
if [ $? -ne 0 ]; then
    _err_msg_="Could not set IPMP_Group_Gateway=${_gateway_ip_} in ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

iniset ${_interface_group_block_} -f ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} ARP_IP_TARGET="${_arp_target_}"
if [ $? -ne 0 ]; then
    _err_msg_="Could not set ARP_IP_TARGET="${_arp_target_}" in ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi
}

### Function: update_ipmp_ini ###
#
#   Update ipmp.ini for migration
#
# Arguments:
#   none
# Return Values:
#   none
update_ipmp_ini()
{
_enm_storage_confirmation_=`read_value ENM_CONFIGURED ${CONT_USER_CONF}` || abort_script "${_enm_storage_confirmation_}" "${EXEC_SHELL_CMD}"
_sfs_va_confirmation_=`read_value SFS_to_VA ${CONT_USER_CONF}` || abort_script "${_sfs_va_confirmation_}" "${EXEC_SHELL_CMD}"

if [ "${_enm_storage_confirmation_}" == "YES" ]; then
      # Adding fourth block for ENM or VA storage.
      update_ipmp_block
fi

# Getting details of PM Services Group from continue ENIQ migration configuration file
_pm_int_=`read_value PM_INTF ${CONT_USER_CONF}` || abort_script "${_pm_int_}" "${EXEC_SHELL_CMD}"
_pm_ip_=`read_value PM_IP ${CONT_USER_CONF}` || abort_script "${_pm_ip_}" "${EXEC_SHELL_CMD}"
_pm_net_ip_=`read_value PM_NETMASK ${CONT_USER_CONF}` || abort_script "${_pm_net_ip_}" "${EXEC_SHELL_CMD}"
_pm_gateway_=`read_value PM_GATEWAY ${CONT_USER_CONF}` || abort_script "${_pm_gateway_}" "${EXEC_SHELL_CMD}"
_pm_arp_target_=`read_value PM_ARP_TARGET ${CONT_USER_CONF}` || abort_script "${_pm_arp_target_}" "${EXEC_SHELL_CMD}"

update_ipmp_group_info "IPMP_INTF_1" "${_pm_int_}" "${_pm_ip_}" "${_pm_net_ip_}" "${_pm_gateway_}" "${_pm_arp_target_}"

_storage_vlan_confirmation_=`read_value STORAGE_VLAN_CONFIRMATION ${CONT_USER_CONF}` || abort_script "${_storage_vlan_confirmation_}" "${EXEC_SHELL_CMD}"

if [ "${_storage_vlan_confirmation_}" == "YES" ]; then
      if [ "${_enm_storage_confirmation_}" == "YES" ]; then
            if [ "${_sfs_va_confirmation_}" == "YES" ]; then
                  # Getting details of Storage VLAN Group from continue ENIQ migration configuration file
                  _enm_str_int_=`read_value OLD_STOR_VLAN_INTF ${CONT_USER_CONF}` || abort_script "${_enm_str_int_}" "${EXEC_SHELL_CMD}"
                  _storage_ip_=`read_value OLD_STOR_VLAN_IP ${CONT_USER_CONF}` || abort_script "${_storage_ip_}" "${EXEC_SHELL_CMD}"
                  _stor_vlan_netmask_=`read_value OLD_STOR_VLAN_NETMASK ${CONT_USER_CONF}` || abort_script "${_stor_vlan_netmask_}" "${EXEC_SHELL_CMD}"
                  _stor_vlan_gateway_=`read_value OLD_STOR_VLAN_GATEWAY ${CONT_USER_CONF}` || abort_script "${_stor_vlan_gateway_}" "${EXEC_SHELL_CMD}"
                  _storage_vlan_arp_target_=`read_value OLD_STOR_VLAN_ARP ${CONT_USER_CONF}` || abort_script "${_storage_vlan_arp_target_}" "${EXEC_SHELL_CMD}"
                  update_ipmp_group_info "IPMP_INTF_2" "${_enm_str_int_}" "${_storage_ip_}" "${_stor_vlan_netmask_}" "${_stor_vlan_gateway_}" "${_storage_vlan_arp_target_}"

                  _str_int_=`read_value STOR_VLAN_INTF ${CONT_USER_CONF}` || abort_script "${_str_int_}" "${EXEC_SHELL_CMD}"
                  _str_ip_=`read_value STOR_VLAN_IP ${CONT_USER_CONF}` || abort_script "${_str_ip_}" "${EXEC_SHELL_CMD}"
                  _str_net_ip_=`read_value STOR_VLAN_NETMASK ${CONT_USER_CONF}` || abort_script "${_str_net_ip_}" "${EXEC_SHELL_CMD}"
                  _stor_gateway_=`read_value STOR_VLAN_GATEWAY ${CONT_USER_CONF}` || abort_script "${_stor_gateway_}" "${EXEC_SHELL_CMD}"
                  _storage_vlan_arp_target_=`read_value STOR_VLAN_ARP_TARGET ${CONT_USER_CONF}` || abort_script "${_storage_vlan_arp_target_}" "${EXEC_SHELL_CMD}"
                  update_ipmp_group_info "IPMP_INTF_4" "${_str_int_}" "${_str_ip_}" "${_str_net_ip_}" "${_stor_gateway_}" "${_storage_vlan_arp_target_}"
            else
                  _str_int_=`read_value STOR_VLAN_INTF ${CONT_USER_CONF}` || abort_script "${_str_int_}" "${EXEC_SHELL_CMD}"
                  _str_ip_=`read_value STOR_VLAN_IP ${CONT_USER_CONF}` || abort_script "${_str_ip_}" "${EXEC_SHELL_CMD}"
                  _str_net_ip_=`read_value STOR_VLAN_NETMASK ${CONT_USER_CONF}` || abort_script "${_str_net_ip_}" "${EXEC_SHELL_CMD}"
                  _stor_gateway_=`read_value STOR_VLAN_GATEWAY ${CONT_USER_CONF}` || abort_script "${_stor_gateway_}" "${EXEC_SHELL_CMD}"
                  _storage_vlan_arp_target_=`read_value STOR_VLAN_ARP_TARGET ${CONT_USER_CONF}` || abort_script "${_storage_vlan_arp_target_}" "${EXEC_SHELL_CMD}"
                  update_ipmp_group_info "IPMP_INTF_2" "${_str_int_}" "${_str_ip_}" "${_str_net_ip_}" "${_stor_gateway_}" "${_storage_vlan_arp_target_}"

                 _enm_str_int_=`read_value ENM_STOR_VLAN_INTF ${CONT_USER_CONF}` || abort_script "${_enm_str_int_}" "${EXEC_SHELL_CMD}"
                 _enm_ip_=`read_value ENM_STOR_VLAN_IP ${CONT_USER_CONF}` || abort_script "${_enm_ip_}" "${EXEC_SHELL_CMD}"
                 _enm_vlan_netmask_=`read_value ENM_STOR_VLAN_NETMASK ${CONT_USER_CONF}` || abort_script "${_enm_vlan_netmask_}" "${EXEC_SHELL_CMD}"
                 _enm_vlan_gateway_=`read_value ENM_STOR_VLAN_GATEWAY ${CONT_USER_CONF}` || abort_script "${_enm_vlan_gateway_}" "${EXEC_SHELL_CMD}"
                 _enm_vlan_arp_target_=`read_value ENM_STOR_VLAN_ARP ${CONT_USER_CONF}` || abort_script "${_enm_vlan_arp_target_}" "${EXEC_SHELL_CMD}"
                 update_ipmp_group_info "IPMP_INTF_4" "${_enm_str_int_}" "${_enm_ip_}" "${_enm_vlan_netmask_}" "${_enm_vlan_gateway_}" "${_enm_vlan_arp_target_}"
            fi
     else
           _str_int_=`read_value STOR_VLAN_INTF ${CONT_USER_CONF}` || abort_script "${_str_int_}" "${EXEC_SHELL_CMD}"
          _str_ip_=`read_value STOR_VLAN_IP ${CONT_USER_CONF}` || abort_script "${_str_ip_}" "${EXEC_SHELL_CMD}"
          _str_net_ip_=`read_value STOR_VLAN_NETMASK ${CONT_USER_CONF}` || abort_script "${_str_net_ip_}" "${EXEC_SHELL_CMD}"
          _stor_gateway_=`read_value STOR_VLAN_GATEWAY ${CONT_USER_CONF}` || abort_script "${_stor_gateway_}" "${EXEC_SHELL_CMD}"
          _storage_vlan_arp_target_=`read_value STOR_VLAN_ARP_TARGET ${CONT_USER_CONF}` || abort_script "${_storage_vlan_arp_target_}" "${EXEC_SHELL_CMD}"
          update_ipmp_group_info "IPMP_INTF_2" "${_str_int_}" "${_str_ip_}" "${_str_net_ip_}" "${_stor_gateway_}" "${_storage_vlan_arp_target_}"
     fi


fi

_backup_vlan_confirmation_=`read_value BACKUP_VLAN_CONFIRMATION ${CONT_USER_CONF}` || abort_script "${_backup_vlan_confirmation_}" "${EXEC_SHELL_CMD}"
if [ "${_backup_vlan_confirmation_}" == "YES" ]; then
      # Getting details of Backup VLAN Group from continue ENIQ migration and Linux migration configuration files
      _backup_vlan_interface_name_=`read_value BACKUP_VLAN_INTF ${CONT_USER_CONF}` || abort_script "${_backup_vlan_interface_name_}" "${EXEC_SHELL_CMD}"
      _backup_vlan_ip_=`read_value BKUP_VLAN_INTF_IP_${HNAME} ${MIGRATION_CONF}` || abort_script "${_backup_vlan_ip_}" "${EXEC_SHELL_CMD}"
      _backup_vlan_net_ip_=`read_value BKUP_VLAN_INTF_NETMASK_${HNAME} ${MIGRATION_CONF}` || abort_script "${_backup_vlan_net_ip_}" "${EXEC_SHELL_CMD}"
      _backup_vlan_gateway_=`read_value BKUP_VLAN_INTF_GATEWAY_${HNAME} ${MIGRATION_CONF}` || abort_script "${_backup_vlan_gateway_}" "${EXEC_SHELL_CMD}"
      _backup_vlan_arp_target_=`read_value BACKUP_VLAN_ARP_TARGET ${CONT_USER_CONF}` || abort_script "${_backup_vlan_arp_target_}" "${EXEC_SHELL_CMD}"
      
      update_ipmp_group_info "IPMP_INTF_3" "${_backup_vlan_interface_name_}" "${_backup_vlan_ip_}" "${_backup_vlan_net_ip_}" "${_backup_vlan_gateway_}" "${_backup_vlan_arp_target_}"
fi

log_msg -s "Successfully updated ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} with available interfaces." -l ${LOGFILE}
}

### Function: update_ipmp_block ###
#
#   Update ipmp.ini for migration
#
# Arguments:
#   none
# Return Values:
#   none
update_ipmp_block()
{
$ECHO "[IPMP_INTF_4]" > ${TEM_DIR}/intf_template
iniget IPMP_INTF_3 -f ${INI_TEMPLATE_DIR}/${IPMP_INI_TEMPLATE} >> ${TEM_DIR}/intf_template

log_msg -q -l ${LOGFILE} -s "Adding ${TEM_DIR}/intf_template file to ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}"
${INIADD} -g IPMP -p IPMP_INTF_4 -i ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]} -d ${TEM_DIR}/intf_template -o ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}_tmp
if [ $? -ne 0 ]; then
    _err_msg_="Could not add ${TEM_DIR}/intf_template to ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}"
    abort_script "${_err_msg_}"
fi

log_msg -t -l ${LOGFILE} -s "Copying ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}_tmp to ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}"
$CP -f ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}_tmp ${TEM_DIR}/${TEMPLATE_FILE_LIST[i]}
if [ $? -ne 0 ]; then
    _err_msg_="Could not copy ${ENIQ_INST_TEMPL}/stats/${IPMP_INI} to ${TEM_DIR}/${IPMP_INI}"
    abort_script "${_err_msg_}"
fi
}

### Function: update_netmasks_file ###
#
# Updates /etc/inet/netmasks file
#
# Arguments:
#   none
# Return Values:
#   none
update_netmasks_file()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling update_netmasks_file stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s update_netmasks_file ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - update_netmasks_file"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: update_niq_ini ###
#
#   Update niq.ini
#
# Arguments:
#   none
# Return Values:
#   none
update_niq_ini()
{
# Make a copy of niq.ini
$CP ${CLI_CONF_DIR}/${ENIQ_INI} ${ENIQ_CONF_DIR}
if [ $? -ne 0 ]; then
    _err_msg_="Could not copy ${CLI_CONF_DIR}/${ENIQ_INI} to ${ENIQ_CONF_DIR}"
    abort_script "$_err_msg_"
fi

$CP ${CLI_CONF_DIR}/${ENIQ_INI} ${TEM_DIR}
if [ $? -ne 0 ]; then
    _err_msg_="Could not copy ${CLI_CONF_DIR}/${ENIQ_INI} to ${TEM_DIR}"
    abort_script "$_err_msg_"
fi

# Merge the ini file with real and template attributes
update_attributes ${ENIQ_INI} ${NIQ_INI_TEMPLATE}_new

# Overwrite existing real ini file with updated version
$ECHO "Copying the updated ${ENIQ_INI} to ${ENIQ_CONF_DIR}."
$CP ${TEM_DIR}/${ENIQ_INI} ${ENIQ_CONF_DIR}/${ENIQ_INI}
if [ $? -ne 0 ]; then
    _err_msg_="Could not copy the updated ${ENIQ_INI} to ${ENIQ_CONF_DIR}."
    abort_script "$_err_msg_"
fi

if [ "${INSTALL_TYPE}" == "stats" ]; then
    ####### Merge the niq.ini to the sym_links.ini
    $ECHO "\nExecuting ${ENIQ_CORE_INST_DIR}/bin/update_zfs_ini.bsh -f ${TEM_DIR}" | $TEE -a ${LOGFILE}
    $BASH ${ENIQ_CORE_INST_DIR}/bin/update_zfs_ini.bsh -f ${TEM_DIR}
    if [ $? -ne 0 ]; then
        _err_msg_="Failed to merge the ini files"
        abort_script "$_err_msg_"
    fi
fi

if [ "${INSTALL_TYPE}" == "stats" ]; then
####### Merge DWH_READER_SETTINGS and DWH_READER block in niq.ini, if missing.
  local _niq_list_="DWH_READER_SETTINGS DWH_READER"
  for _niq_value_ in ${_niq_list_}; do
    local _tem_attribs_niq_=`iniget ${_niq_value_} -f ${TEM_DIR}/${ENIQ_INI}`
    if [ ! "${_tem_attribs_niq_}" ]; then
         if [ -s ${NEW_TEMPL_DIR}/${ENIQ_INI} ]; then
              local _template_attribs_niq_=`iniget ${_niq_value_} -f ${NEW_TEMPL_DIR}/${ENIQ_INI}`
                    if [ ! "${_template_attribs_niq_}" ]; then
                          if [ ${_niq_value_} == "DWH_READER" ]; then
                               local _dwh_reader_attr_=""
                               $ECHO "" >> ${TEM_DIR}/${ENIQ_INI}
                               iniset ${_niq_value_} -f ${TEM_DIR}/${ENIQ_INI} ${_dwh_reader_attr_}
                               if [ $? -ne 0 ]; then
                                   _err_msg_="Could not set ${_niq_value_} in ${TEM_DIR}/${ENIQ_INI}"
                                   abort_script "$_err_msg_"
                               fi
                          fi
                    else
                          $ECHO "" >> ${TEM_DIR}/${ENIQ_INI}
                          for _name_value_ in ${_template_attribs_niq_}; do
                          iniset ${_niq_value_} -f ${TEM_DIR}/${ENIQ_INI} ${_name_value_}
                          if [ $? -ne 0 ]; then
                                _err_msg_="Could not set ${_niq_value_} in ${TEM_DIR}/${ENIQ_INI}."
                                abort_script "$_err_msg_"
                          fi
                          done
                    $ECHO "ENIQ_INI is updated with ${_niq_value_}" >> ${LOGFILE}
                    fi
             $ECHO "-----------------------------------------------------" | $TEE -a ${LOGFILE}
             $ECHO "Finished updating  values for ${_niq_value_}" | $TEE -a ${LOGFILE}
             $ECHO "-----------------------------------------------------" | $TEE -a ${LOGFILE}
         fi
    else
     $ECHO "\n DWH READER INFORMATION is already set in ${ENIQ_CONF_DIR}/${ENIQ_INI}" | $TEE -a ${LOGFILE}
    fi
   done
fi

# Update the feature info
local _eniq_tp_feat_dir_=${ENIQ_ADMIN_DIR}/managed_oss
local _eniq_feat_output_file_=${_eniq_tp_feat_dir_}/total_feature_install_list

iniset FEATURE_INFO -f ${TEM_DIR}/${ENIQ_INI} Feature_Interface_Dir=${_eniq_tp_feat_dir_}
if [ $? -ne 0 ]; then
    _err_msg_="Could not set Feature_Interface_Dir=${_eniq_tp_feat_dir_} in ${TEM_DIR}/${ENIQ_INI}"
    abort_script "$_err_msg_"
fi

iniset FEATURE_INFO -f ${TEM_DIR}/${ENIQ_INI} Feature_Output_File=${_eniq_feat_output_file_}
if [ $? -ne 0 ]; then
    _err_msg_="Could not set Feature_Output_File=${_eniq_feat_output_file_} in ${TEM_DIR}/${ENIQ_INI}"
    abort_script "$_err_msg_"
fi

local _dwhdb_stopcount_=`iniget DWH -f ${NEW_TEMPL_DIR}/${ENIQ_INI} -v StopCount`
if [ -z "$_dwhdb_stopcount_" ]; then
    _err_msg_="StopCount value not found for DWH in ${NEW_TEMPL_DIR}/${ENIQ_INI}"
    abort_script "$_err_msg_"
fi

iniset DWH -f ${TEM_DIR}/${ENIQ_INI} StopCount=${_dwhdb_stopcount_}
if [ $? -ne 0 ]; then
    _err_msg_="Could not set StopCount for DWH in ${TEM_DIR}/${ENIQ_INI}"
    abort_script "$_err_msg_"
fi

local _connection_timeout_tmpl_=`iniget DWH -f ${NEW_TEMPL_DIR}/${ENIQ_INI} -v QueryUserDropConnectionTimeout`
if [ -z "$_connection_timeout_tmpl_" ]; then
    _err_msg_="QueryUserDropConnectionTimeout value not found for DWH in ${NEW_TEMPL_DIR}/${ENIQ_INI}"
    abort_script "$_err_msg_"
fi

local _connection_timeout_real_=`iniget DWH -f ${TEM_DIR}/${ENIQ_INI} -v QueryUserDropConnectionTimeout`
if [ -z "$_connection_timeout_real_" ]; then
    _err_msg_="QueryUserDropConnectionTimeout value not found for DWH in ${TEM_DIR}/${ENIQ_INI}"
    abort_script "$_err_msg_"
fi

if [ "${_connection_timeout_tmpl_}" -ne "${_connection_timeout_real_}" ]; then
        iniset DWH -f ${TEM_DIR}/${ENIQ_INI} QueryUserDropConnectionTimeout=${_connection_timeout_tmpl_}
        if [ $? -ne 0 ]; then
                _err_msg_="Could not set QueryUserDropConnectionTimeout for DWH in ${TEM_DIR}/${ENIQ_INI}"
                abort_script "$_err_msg_"
        fi
fi

local _dwh_reader_stopcount_=`iniget DWH_READER_SETTINGS -f ${NEW_TEMPL_DIR}/${ENIQ_INI} -v StopCount`
if [ -z "$_dwh_reader_stopcount_" ]; then
    _err_msg_="StopCount value not found for DWH_READER_SETTINGS in ${NEW_TEMPL_DIR}/${ENIQ_INI}"
    abort_script "$_err_msg_"
fi

iniset DWH_READER_SETTINGS -f ${TEM_DIR}/${ENIQ_INI} StopCount=${_dwh_reader_stopcount_}
if [ $? -ne 0 ]; then
    _err_msg_="Could not set StopCount for DWH_READER_SETTINGS in ${TEM_DIR}/${ENIQ_INI}"
    abort_script "$_err_msg_"
fi

local _util_dba_password_=`iniget DB -f ${NEW_TEMPL_DIR}/${ENIQ_INI} -v UtilDBAPASSWORD`
if [ -z "$_util_dba_password_" ]; then
    _err_msg_="UtilDBAPASSWORD value not found for DB in ${NEW_TEMPL_DIR}/${ENIQ_INI}"
    abort_script "$_err_msg_"
fi

iniset DB -f ${TEM_DIR}/${ENIQ_INI} UtilDBAPASSWORD=${_util_dba_password_}
if [ $? -ne 0 ]; then
    _err_msg_="Could not set UtilDBAPASSWORD for DB ${TEM_DIR}/${ENIQ_INI}"
    abort_script "$_err_msg_"
fi

local _last_tp_installed_=`iniget FEATURE_INFO -f ${TEM_DIR}/${ENIQ_INI} -v Last_Tech_Packs_Installed_File`
if [ ! "${_last_tp_installed_}" ]; then
    $ECHO "Adding Last_Tech_Packs_Installed_File=installed_artifacts to ${TEM_DIR}/${ENIQ_INI}" >> ${LOGFILE}
    $ECHO "Last_Tech_Packs_Installed_File=installed_artifacts" > /tmp/ini_insert_new_param
    $SED "/\[FEATURE_INFO\]/ r /tmp/ini_insert_new_param" < ${TEM_DIR}/${ENIQ_INI} > ${TEM_DIR}/${ENIQ_INI}.new
    if [ $? -ne 0 ]; then
        _err_msg_="Could not update Last_Tech_Packs_Installed_File port in ${TEM_DIR}/${ENIQ_INI}"
        abort_script "$_err_msg_"
    fi
    $CP ${TEM_DIR}/${ENIQ_INI}.new ${TEM_DIR}/${ENIQ_INI}
fi

if [ "${INSTALL_TYPE}" == "stats" ]; then
    local _soem_feature_input_file_=`iniget FEATURE_INFO -f ${TEM_DIR}/${ENIQ_INI} -v Soem_Feature_Input_File`
    if [ ! "${_soem_feature_input_file_}" ]; then
        $ECHO "Adding Soem_Feature_Input_File=soem_install_features to ${TEM_DIR}/${ENIQ_INI}" >> ${LOGFILE}
        $ECHO "; These file holds the list of ENIQ SOEM Features that the user will be queried about
; The path is relative to the ENIQ DVD/JUMPSTART top directory
Soem_Feature_Input_File=soem_install_features
" > /tmp/ini_insert_new_param
        $SED "/\[FEATURE_INFO\]/ r /tmp/ini_insert_new_param" < ${TEM_DIR}/${ENIQ_INI} > ${TEM_DIR}/${ENIQ_INI}.new
        if [ $? -ne 0 ]; then
            _err_msg_="Could not update Soem_Feature_Input_File attribute in ${TEM_DIR}/${ENIQ_INI}"
            abort_script "$_err_msg_"
        fi
        $CP ${TEM_DIR}/${ENIQ_INI}.new ${TEM_DIR}/${ENIQ_INI}
    fi
fi

if [ "${CURR_SERVER_TYPE}" == "stats_coordinator" -o "${CURR_SERVER_TYPE}" == "eniq_stats" ]; then
    local _plan_value_=`iniget PARTITION_PLAN -f ${TEM_DIR}/${ENIQ_INI} -v Partition_Plan`
    if [ ! "${_plan_value_}" ]; then
        _err_msg_="Could not read parameter PARTITION_PLAN from ${TEM_DIR}/${ENIQ_INI} file"
        abort_script "$_err_msg_"
    fi

    $ECHO ${_plan_value_} | $EGREP "_plan" >> /dev/null 2>&1
    if [ $? -ne 0 ]; then
        local _partition_plan_=`$ECHO ${_plan_value_} | $TR '[:upper:]' '[:lower:]'`
        local _plan_=${_partition_plan_}_plan
        $ECHO "Updating partition plan value in ${ENIQ_INI} with ${_plan_}" >> ${LOGFILE}
        iniset PARTITION_PLAN -f ${TEM_DIR}/${ENIQ_INI} Partition_Plan=${_plan_}
        if [ $? -ne 0 ]; then
            _err_msg_="Could not update ${TEM_DIR}/${ENIQ_INI} with Partition_Plan=${_plan_}"
            abort_script "$_err_msg_"
        fi
    fi
fi

# Check update the NIQ.ini with new DIRECTORY_STRUCTURE info
$CAT ${TEM_DIR}/${ENIQ_INI} | $EGREP "DIRECTORY_STRUCTURE" >> /dev/null 2>&1
if [ $? -ne 0 ]; then
    $ECHO "
[DIRECTORY_STRUCTURE]
FileSystems=
" >> ${TEM_DIR}/${ENIQ_INI}
    if [ $? -ne 0 ]; then
            _err_msg_="Could not update ${TEM_DIR}/${ENIQ_INI}"
            abort_script "$_err_msg_"
    fi
fi

# update the FileSystem info for Stats raw
if [ "${STORAGE_TYPE}" == "raw" ]; then
    # Set the FileSystem to 4
    iniset DIRECTORY_STRUCTURE -f ${TEM_DIR}/${ENIQ_INI} FileSystems=4
    if [ $? -ne 0 ]; then
        _err_msg_="Could not set FileSystems=4 in ${TEM_DIR}/${ENIQ_INI}"
        abort_script "$_err_msg_"
    fi
fi

# Set the EngineStartCount to 10
iniset ETLC -f ${TEM_DIR}/${ENIQ_INI} EngineStartCount=10
if [ $? -ne 0 ]; then
    _err_msg_="Could not set EngineStartCount=10 in ${TEM_DIR}/${ENIQ_INI}"
    abort_script "$_err_msg_"
fi

# Set the EngineStartDelay to 10
iniset ETLC -f ${TEM_DIR}/${ENIQ_INI} EngineStartDelay=10
if [ $? -ne 0 ]; then
    _err_msg_="Could not set EngineStartDelay=100 in ${TEM_DIR}/${ENIQ_INI}"
    abort_script "$_err_msg_"
fi

if [ "${CURR_SERVER_TYPE}" == "son_coordinator" -o "${CURR_SERVER_TYPE}" == "stats_coordinator" -o "${CURR_SERVER_TYPE}" == "stats_engine" -o "${CURR_SERVER_TYPE}" == "eniq_iqw" -o "${CURR_SERVER_TYPE}" == "eniq_stats" ]; then
    # Set the Heap Memory size of the ENIQ engine.
    
        if [ "${CURR_SERVER_TYPE}" == "stats_engine" ]; then
            local _heap_factor_=2
        else
            local _heap_factor_=18
        fi


    # Set the Heap Memory size of the ENIQ engine.
    update_engine_java_heap_size ${TEM_DIR}/${ENIQ_INI} ${_heap_factor_}
    if [ $? -ne 0 ]; then
        _err_msg_="Could not update engine Heap Memory size in ${TEM_DIR}/${ENIQ_INI}"
        abort_script "$_err_msg_"
    fi
fi

local _rep_mig_path_=`iniget REP_MIGRATION -f ${TEM_DIR}/${ENIQ_INI} -v Location`
if [ ! "${_rep_mig_path_}" ]; then
    _rep_mig_path_=${ENIQ_BASE_DIR}/data/etldata/migration_data
    if [ ! -d ${_rep_mig_path_} ]; then
    $MKDIR -p ${_rep_mig_path_}
    if [ $? -ne 0 ]; then
               _err_msg_="Could not create migration_data directory"
               abort_script "$_err_msg_"
        fi
    fi

    $CHOWN -R ${SYSUSER}:${SYSGRP} ${_rep_mig_path_}
    if [ $? -ne 0 ]; then
        _err_msg_="Could not change the permission of migration_data directory"
        abort_script "$_err_msg_"
    fi
    $ECHO "    -> Adding REP_MIGRATION to ${TEM_DIR}/${ENIQ_INI}"
    $ECHO "" >> ${TEM_DIR}/${ENIQ_INI}
    iniset REP_MIGRATION -f ${TEM_DIR}/${ENIQ_INI} Location=${_rep_mig_path_}
    if [ $? -ne 0 ]; then
           _err_msg_="Could not add REP_MIGRATION to ${TEM_DIR}/${ENIQ_INI}"
           abort_script "$_err_msg_"
    fi
fi

local _dwh_util_ser_=`iniget DB -f ${TEM_DIR}/${ENIQ_INI} -v DWHUtilServerPort`
if [ ! "${_dwh_util_ser_}" ]; then
    $ECHO "Adding DWHUtilServerPort=2639 to ${TEM_DIR}/${ENIQ_INI}" >> ${LOGFILE}
    $ECHO "DWHUtilServerPort=2639" > /tmp/ini_insert_new_param
    $SED "/\[DB\]/ r /tmp/ini_insert_new_param" < ${TEM_DIR}/${ENIQ_INI} > ${TEM_DIR}/${ENIQ_INI}.new
    if [ $? -ne 0 ]; then
        _err_msg_="Could not update DWHUtilServer port in ${TEM_DIR}/${ENIQ_INI}"
        abort_script "$_err_msg_"
    fi
    $CP ${TEM_DIR}/${ENIQ_INI}.new ${TEM_DIR}/${ENIQ_INI}
fi

local _ser_type_=`iniget ETLC -f ${TEM_DIR}/${ENIQ_INI} -v Server_Type`
if [ ! "${_ser_type_}" ]; then
    if [ ${INSTALL_TYPE} == "oss" ]; then
        INSTALL_TYPE=stats
    fi
    $ECHO "Adding Server_Type=${INSTALL_TYPE} to ${TEM_DIR}/${ENIQ_INI}"
    $ECHO "Server_Type=${INSTALL_TYPE}" > /tmp/ini_insert_new_ser_type
    $SED '/\[ETLC\]/ r /tmp/ini_insert_new_ser_type' < ${TEM_DIR}/${ENIQ_INI} > ${TEM_DIR}/${ENIQ_INI}.new
    if [ $? -ne 0 ]; then
        _err_msg_="Could not update Server_Type in ${TEM_DIR}/${ENIQ_INI}"
        abort_script "$_err_msg_"
    else
        $CP ${TEM_DIR}/${ENIQ_INI}.new ${TEM_DIR}/${ENIQ_INI}
     $RM -rf /tmp/ini_insert_new_ser_type
    fi
fi

local _dwh_catalog_cache_=`iniget DWH -f ${TEM_DIR}/${ENIQ_INI} -v CatalogCache`
if [ ! "${_dwh_catalog_cache_}" ]; then
    $ECHO "Adding CatalogCache to ${TEM_DIR}/${ENIQ_INI}" >> ${LOGFILE}
    iniset DWH -f ${TEM_DIR}/${ENIQ_INI} CatalogCache=5000
    if [ $? -ne 0 ]; then
        _err_msg_="Could not update CatalogCache in ${TEM_DIR}/${ENIQ_INI}"
        abort_script "$_err_msg_"
    fi
fi


# Update port number for REPDB validation
local _rep_validation_port_=`iniget REP -f ${TEM_DIR}/${ENIQ_INI} -v Validation_PortNumber`
if [ ! "${_rep_validation_port_}" ]; then
    $ECHO "Adding repdb validation port to REP" >> ${LOGFILE}
    $RM -rf ${TEM_DIR}/${ENIQ_INI}.new >> /dev/null 2>&1
    $ECHO "Validation_PortNumber=2637" > ${TEM_DIR}/rep_validation_update
    $SED "/\[REP\]/ r /${TEM_DIR}/rep_validation_update" < ${TEM_DIR}/${ENIQ_INI} > ${TEM_DIR}/${ENIQ_INI}.new
    if [ $? -ne 0 ]; then
        _err_msg_="Could not update validation port for REP in ${TEM_DIR}/${ENIQ_INI}"
        abort_script "$_err_msg_"
    fi
    $CP ${TEM_DIR}/${ENIQ_INI}.new ${TEM_DIR}/${ENIQ_INI}
fi

local _rep_jconn_driver_=`iniget REP -f ${NEW_TEMPL_DIR}/${ENIQ_INI} -v Driver`
if [ ! "${_rep_jconn_driver_}" ]; then
     _err_msg_="Could not read parameter Driver for REP from ${NEW_TEMPL_DIR}/${ENIQ_INI}"
     abort_script "$_err_msg_"
fi
# Update driver info for REP
local _rep_drv_present_=`iniget REP -f ${TEM_DIR}/${ENIQ_INI} -v Driver`
if [ ! "${_rep_drv_present_}" ]; then
    $ECHO "Adding driver information to REP" >> ${LOGFILE}
    $RM -rf ${TEM_DIR}/${ENIQ_INI}.new >> /dev/null 2>&1
    $ECHO "Driver=${_rep_jconn_driver_}" > ${TEM_DIR}/niq_driver_update
    $SED "/\[REP\]/ r /${TEM_DIR}/niq_driver_update" < ${TEM_DIR}/${ENIQ_INI} > ${TEM_DIR}/${ENIQ_INI}.new
    if [ $? -ne 0 ]; then
            _err_msg_="Could not update Driver info for REP in ${TEM_DIR}/${ENIQ_INI}"
            abort_script "$_err_msg_"
    fi
    $CP ${TEM_DIR}/${ENIQ_INI}.new ${TEM_DIR}/${ENIQ_INI}
else
    $ECHO "Updating driver information for REP" >> ${LOGFILE}
    iniset REP -f ${TEM_DIR}/${ENIQ_INI} Driver=${_rep_jconn_driver_}
    if [ $? -ne 0 ]; then
        _err_msg_="Could not update Driver=${_rep_jconn_driver_} for REP in ${TEM_DIR}/${ENIQ_INI}"
        abort_script "$_err_msg_"
    fi
fi

local _dwh_jconn_driver_=`iniget DWH -f ${NEW_TEMPL_DIR}/${ENIQ_INI} -v Driver`
if [ ! "${_dwh_jconn_driver_}" ]; then
     _err_msg_="Could not read parameter Driver for DWH from ${NEW_TEMPL_DIR}/${ENIQ_INI}"
     abort_script "$_err_msg_"
fi
# Update driver info for DWH
local _dwh_drv_present_=`iniget DWH -f ${TEM_DIR}/${ENIQ_INI} -v Driver`
if [ ! "${_dwh_drv_present_}" ]; then
    $ECHO "Adding driver information to DWH" >> ${LOGFILE}
    $RM -rf ${TEM_DIR}/${ENIQ_INI}.new >> /dev/null 2>&1
    $ECHO "Driver=${_dwh_jconn_driver_}" > ${TEM_DIR}/niq_driver_update
    $SED "/\[DWH\]/ r /${TEM_DIR}/niq_driver_update" < ${TEM_DIR}/${ENIQ_INI} > ${TEM_DIR}/${ENIQ_INI}.new
    if [ $? -ne 0 ]; then
            _err_msg_="Could not update Driver info for DWH in ${TEM_DIR}/${ENIQ_INI}"
            abort_script "$_err_msg_"
        fi
        $CP ${TEM_DIR}/${ENIQ_INI}.new ${TEM_DIR}/${ENIQ_INI}
else
        $ECHO "Updating driver information for DWH" >> ${LOGFILE}
        iniset DWH -f ${TEM_DIR}/${ENIQ_INI} Driver=${_dwh_jconn_driver_}
        if [ $? -ne 0 ]; then
             _err_msg_="Could not update Driver=${_dwh_jconn_driver_} for DWH in ${TEM_DIR}/${ENIQ_INI}"
             abort_script "$_err_msg_"
        fi
fi

# Update driver class for DB
local _db_driver_class_=`iniget DB -f ${NEW_TEMPL_DIR}/${ENIQ_INI} -v DriverClass`
if [ ! "${_db_driver_class_}" ]; then
     _err_msg_="Could not read parameter DriverClass for DB from ${NEW_TEMPL_DIR}/${ENIQ_INI}"
     abort_script "$_err_msg_"
fi

$ECHO "Updating DriverClass information for DB" >> ${LOGFILE}
iniset DB -f ${TEM_DIR}/${ENIQ_INI} DriverClass=${_db_driver_class_}
if [ $? -ne 0 ]; then
    _err_msg_="Could not update DriverClass=${_db_driver_class_} for DB in ${TEM_DIR}/${ENIQ_INI}"
    abort_script "$_err_msg_"
fi

# Update Data Source Class for Glassfish
local _db_datasource_class_=`iniget GLASSFISH_DB -f ${NEW_TEMPL_DIR}/${ENIQ_INI} -v DataSourceClass`
if [ ! "${_db_datasource_class_}" ]; then
     _err_msg_="Could not read parameter DataSourceClass for GLASSFISH_DB from ${NEW_TEMPL_DIR}/${ENIQ_INI}"
     abort_script "$_err_msg_"
fi

$ECHO "Updating DataSourceClass information for GLASSFISH_DB" >> ${LOGFILE}
iniset GLASSFISH_DB -f ${TEM_DIR}/${ENIQ_INI} DataSourceClass=${_db_datasource_class_}
if [ $? -ne 0 ]; then
    _err_msg_="Could not update DataSourceClass=${_db_datasource_class_} for GLASSFISH_DB in ${TEM_DIR}/${ENIQ_INI}"
    abort_script "$_err_msg_"
fi

#Update ETLREPUsername
local _etlrep_user_name_=`iniget REP -f ${TEM_DIR}/${ENIQ_INI} -v ETLREPUsername`
if [ ! "${_etlrep_user_name_}" ]; then
    $ECHO "Adding etlrep user to REP" >> ${LOGFILE}
    $RM -rf ${TEM_DIR}/${ENIQ_INI}.new >> /dev/null 2>&1
    $ECHO "ETLREPUsername=etlrep" > ${TEM_DIR}/etlrep_user_update
    $SED "/\[REP\]/ r /${TEM_DIR}/etlrep_user_update" < ${TEM_DIR}/${ENIQ_INI} > ${TEM_DIR}/${ENIQ_INI}.new
    if [ $? -ne 0 ]; then
        err_msg="Could not update etlrep user for REP in ${TEM_DIR}/${ENIQ_INI}"
        abort_script "$err_msg"
    fi
    $CP ${TEM_DIR}/${ENIQ_INI}.new ${TEM_DIR}/${ENIQ_INI}
fi

# Update DWHREPUsername
local _dwhrep_user_name_=`iniget REP -f ${TEM_DIR}/${ENIQ_INI} -v DWHREPUsername`
if [ ! "${_dwhrep_user_name_}" ]; then
    $ECHO "Adding dwhrep user to REP" >> ${LOGFILE}
    $RM -rf ${TEM_DIR}/${ENIQ_INI}.new >> /dev/null 2>&1
    $ECHO "DWHREPUsername=dwhrep" > ${TEM_DIR}/dwhrep_user_update
    $SED "/\[REP\]/ r /${TEM_DIR}/dwhrep_user_update" < ${TEM_DIR}/${ENIQ_INI} > ${TEM_DIR}/${ENIQ_INI}.new
    if [ $? -ne 0 ]; then
        err_msg="Could not update dwhrep user for REP in ${TEM_DIR}/${ENIQ_INI}"
        abort_script "$err_msg"
    fi
    $CP ${TEM_DIR}/${ENIQ_INI}.new ${TEM_DIR}/${ENIQ_INI}
fi

# Re-write niq.ini
$CP ${TEM_DIR}/${ENIQ_INI} ${CLI_CONF_DIR}
if [ $? -ne 0 ]; then
    _err_msg_="Could not copy ${TEM_DIR}/${ENIQ_INI} to ${CLI_CONF_DIR}"
    abort_script "$_err_msg_"
fi

$CP ${TEM_DIR}/${ENIQ_INI} ${ENIQ_CONF_DIR}
if [ $? -ne 0 ]; then
    _err_msg_="Could not copy ${TEM_DIR}/${ENIQ_INI} to ${ENIQ_CONF_DIR}"
    abort_script "$_err_msg_"
fi

if [ -f ${TEM_DIR}/${SYM_INI} ]; then
    $CP ${TEM_DIR}/${SYM_INI} ${ENIQ_CONF_DIR}
    if [ $? -ne 0 ]; then
        _err_msg_="Could not copy ${TEM_DIR}/${SYM_INI} to ${ENIQ_CONF_DIR}"
        abort_script "$_err_msg_"
    fi
fi

#### set the fs arc and IQ cache values on all blades
$ECHO "Updating FS ARC and IQ cache values" >> ${LOGFILE}
$BASH ${SCRIPTHOME}/set_core_memcache.bsh -d ${ENIQ_CONF_DIR} -m -f -z -l ${LOGFILE}
if [ $? -eq 0 ]; then
    $CP ${ENIQ_CONF_DIR}/${ENIQ_INI} ${CLI_CONF_DIR}/${ENIQ_INI}
    if [ $? -ne 0 ]; then
        _err_msg_="Could not copy ${ENIQ_CONF_DIR}/${ENIQ_INI} to ${CLI_CONF_DIR}/${ENIQ_INI}"
        abort_script "$_err_msg_"
    fi
else
    _err_msg_="Could not update FS_ARC cache values in ${CLI_CONF_DIR}/${ENIQ_INI}"
    abort_script "$_err_msg_"
fi
}

### Function: update_cron_file ###
#
#  Removes Solaris 11 OS specific cron entries  and appends RHEL OS cron entries
#  if performing OS Migration / OS Migration with Blade Replacement 
#
# Arguments:
#   NONE 
# Return Values:
#   NONE 
update_cron_file()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}
# Root user cron file(RHEL OS and application level cron entries)
_mig_root_cron_=${CRONTABS_DIR}/root

# Defining Root cron file 
solaris_root_cronlist=${ENIQ_PORTBACKUP}/${HNAME}/ROOT${CRONTABS_DIR}/crontabs/root

solaris_root_cronlist_new=/tmp/solaris_root_cronlist_new
$CP -p ${solaris_root_cronlist} ${solaris_root_cronlist_new}

    # Check if eniq_solaris_11_cronlist exist
    if [ ! -f ${MIGRATION_ETC}/eniq_solaris_10_cronlist ]; then
        _err_msg_="File ${MIGRATION_ETC}/eniq_solaris_10_cronlist does not exists."
        abort_script "${_err_msg_}"
    fi

# Config file containing Solaris 11 OS level cron entries
dep_root_cronlist=(`$CAT ${MIGRATION_ETC}/eniq_solaris_10_cronlist`)
for _dep_entry_ in "${dep_root_cronlist[@]}"; do
    # Check and remove all Solaris 11 OS level cron entries
    $CAT ${solaris_root_cronlist_new} | $GREP $_dep_entry_ >> /dev/null 2>&1
    if [ $? -eq 0 ]; then
        log_msg -s "Removing cron entry for $_dep_entry_" -l ${LOGFILE} >> /dev/null 2>&1
        $CAT ${solaris_root_cronlist_new} | $GREP -v ${_dep_entry_} > ${solaris_root_cronlist_new}.tmp
        $MV ${solaris_root_cronlist_new}.tmp ${solaris_root_cronlist_new}
    fi
done
$SED -i '/^#/d' ${solaris_root_cronlist_new}

$CP -p ${_mig_root_cron_} ${_mig_root_cron_}_orig

# Copy the temp file to original file
$CP -p ${solaris_root_cronlist_new} ${_mig_root_cron_}
    if [ $? -ne 0 ]; then
        _err_msg_="Unable to save cron file ${_mig_root_cron_}."
        abort_script "${_err_msg_}"
    fi

    if [ ! -s ${_mig_root_cron_} ]; then
        _err_msg_="File ${_mig_root_cron_} is empty."
        abort_script "${_err_msg_}"
    fi

# dcuser cron file(RHEL OS and application level cron entries)
_mig_dcuser_cron_=${CRONTABS_DIR}/dcuser

# Defining dcuser cron file 
solaris_dcuser_cronlist=${ENIQ_PORTBACKUP}/${HNAME}/ROOT${CRONTABS_DIR}/crontabs/dcuser
 
#Check if solaris_dcuser_cronlist exist    
if [ -s ${solaris_dcuser_cronlist} ]; then
    solaris_dcuser_cronlist_new=/tmp/solaris_dcuser_cronlist_new
    $CP -p ${solaris_dcuser_cronlist} ${solaris_dcuser_cronlist_new}

    # Check if eniq_solaris_11_cronlist exist
    if [ ! -f ${MIGRATION_ETC}/eniq_solaris_10_cronlist ]; then
        _err_msg_="File ${MIGRATION_ETC}/eniq_solaris_10_cronlist does not exists."
        abort_script "${_err_msg_}"
    fi

    # Config file containing Solaris 11 OS level cron entries
    dep_dcuser_cronlist=(`$CAT ${MIGRATION_ETC}/eniq_solaris_10_cronlist`)
    for _dep_dcuser_entry_ in "${dep_dcuser_cronlist[@]}"; do
    # Check and remove all Solaris 10 OS level cron entries
    $CAT ${solaris_dcuser_cronlist_new} | $GREP $_dep_dcuser_entry_ >> /dev/null 2>&1
    if [ $? -eq 0 ]; then
        log_msg -s "Removing cron entry for $_dep_dcuser_entry_" -l ${LOGFILE} >> /dev/null 2>&1
        $CAT ${solaris_dcuser_cronlist_new} | $GREP -v ${_dep_dcuser_entry_} > ${solaris_dcuser_cronlist_new}.tmp
        $MV ${solaris_dcuser_cronlist_new}.tmp ${solaris_dcuser_cronlist_new}
    fi
    done
    $SED -i '/^#/d' ${solaris_dcuser_cronlist_new}

    $CP -p ${_mig_dcuser_cron_} ${_mig_dcuser_cron_}_orig
    # Copy the cron file to original file
    $CP -p ${solaris_dcuser_cronlist_new} ${_mig_dcuser_cron_}
    if [ $? -ne 0 ]; then
        _err_msg_="Unable to save cron file ${_mig_dcuser_cron_}."
        abort_script "${_err_msg_}"
    fi

    if [ ! -s ${_mig_dcuser_cron_} ]; then
        _err_msg_="File ${_mig_dcuser_cron_} is empty."
        abort_script "${_err_msg_}"
    fi
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: update_sysuser_file ###
#
# Update the SYSTEM USER profile file
#
# Arguments:
#   none
# Return Values:
#   none
update_sysuser_file()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

# Skip stage if not CO server
if [ "${CO_SERVER}" != "YES" ]; then
    insert_header_footer foot "Skipping ${ACTION_TYPE} stage for ${CURR_SERVER_TYPE} - ${NEXT_STAGE} " ${LOGFILE}
    set_next_stage `$EXPR ${ARRAY_ELEM}+1`
    return 0
fi

_update_=0

# Get the System User/Group. All directories are owned by this
SYSUSER=`iniget ENIQ_INSTALL_CONFIG -f ${ENIQ_CONF_DIR}/${SUNOS_INI} -v ENIQ_SYSUSER`
if [ ! "${SYSUSER}" ]; then
    _err_msg_="Could not read SYSUSER param from ${ENIQ_CONF_DIR}/${SUNOS_INI}"
    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

SYSGRP=`$ID ${SYSUSER}|$AWK '{print $2}'|$AWK -F\( '{print $2}'|$AWK -F\) '{print $1}'`
if [ ! "${SYSGRP}" ]; then
    _err_msg_="Could not read SYSGRP param from ${ENIQ_CONF_DIR}/${SUNOS_INI}"
    abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
fi

_asa_tgt_dir_=`iniget SYBASE_ASA -f ${ENIQ_CONF_DIR}/${SUNOS_INI} -v SYBASE_ASA_TARGET_DIR`
_bin_dir_=`$CAT ${ENIQ_CONF_DIR}/${ENIQ_ENV} | $EGREP '^[[:blank:]]*BIN_DIR=' | $AWK -F\= '{print $2}'`
_cli_conf_dir_=`$CAT ${ENIQ_CONF_DIR}/${ENIQ_ENV} | $EGREP "^[[:blank:]]*CONF_DIR=" | $AWK -F\= '{print $2}' | $SED -e 's|"||g'`
_iq_dir_=`iniget SYBASE_IQ -f ${ENIQ_CONF_DIR}/${SUNOS_INI} -v SYBASE_IQ_TARGET_DIR`
_rt_dir_=`$CAT ${ENIQ_CONF_DIR}/${ENIQ_ENV} | $EGREP '^[[:blank:]]*RT_DIR=' | $AWK -F\= '{print $2}'`

# Check the home area ismounted for raw storage
if [ "${STORAGE_TYPE}" == "raw" ]; then
    _mount_exists_=`$MOUNT | $GREP "${ENIQ_BASE_DIR}/home" | $AWK '{print $1}'`
    if [ ! "${_mount_exists_}" ]; then
        _err_msg_="${ENIQ_BASE_DIR}/home not mounted during $NEXT_STAGE"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi
fi

# Set the system architecture
local _arch_=`$UNAME -p`

# Get a list of users to be updated
_user_list_=`iniget SunOS_USER -f ${ENIQ_CONF_DIR}/${SUNOS_INI}`
for _user_ in ${_user_list_}; do
    _user_name_=`iniget ${_user_} -f ${ENIQ_CONF_DIR}/${SUNOS_INI} -v name`
    $GETENT passwd ${_user_name_} >> /dev/null 2>&1
    if [ $? -ne 0 ]; then
        _err_msg_="User ${_user_name_} not created"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi

    local _sys_home_=`$GETENT passwd ${_user_name_} | $AWK -F\: '{print $6}'`
    if [ ! "${_sys_home_}" ]; then
        _err_msg_="Error reading ${_user_name_} home area from /etc/passwd"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi

    if [ ! -d "${_sys_home_}" ]; then
        _err_msg_="${_sys_home_} is not a directory"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi

    if [ -f ${ENIQ_TEMPL_DIR}/${_arch_}/skel_dir/.bash_profile ]; then
        $CAT ${ENIQ_TEMPL_DIR}/${_arch_}/skel_dir/.bash_profile | $SED -e "s|<CHANGE><IQ_SYB_DIR>|${_iq_dir_}|g"     \
            -e "s|<CHANGE><ASA_SYB_DIR>|${_asa_tgt_dir_}|g"                              \
            -e "s|<CHANGE><CONF_DIR>|${_cli_conf_dir_}|g"                                \
            -e "s|<CHANGE><BIN_DIR>|${_bin_dir_}|g"                                      \
            -e "s|<CHANGE><RT_DIR>|${_rt_dir_}|g" > ${TEM_DIR}/bash_profile

        $CP ${TEM_DIR}/bash_profile ${_sys_home_}/.bash_profile
        if [ $? -ne 0 ]; then
            _err_msg_="Error executing: $CP ${TEM_DIR}/profile ${_sys_home_}/.bash_profile "
            abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
        fi

        $RM -rf ${_sys_home_}/.profile
        if [ -L ${_sys_home_}/.profile ]; then
               _err_msg_="Could not remove .profile symbolic link"
               abort_script "${_err_msg_}"
        fi

        $LN -s ${_sys_home_}/.bash_profile ${_sys_home_}/.profile
        if [ $? -ne 0 ]; then
            _err_msg_="Error executing: $LN -s ${_sys_home_}/.bash_profile ${_sys_home_}/.profile "
            abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
        fi
        _update_=1

       $CHOWN -h $SYSUSER:$SYSGRP ${_sys_home_}/.bash_profile ${_sys_home_}/.profile
       if [ $? -ne 0 ]; then
           _err_msg_="Error executing: $CHOWN $SYSUSER:$SYSGRP ${_sys_home_}/.bash_profile ${_sys_home_}/.profile"
           abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
       fi
    fi
done

if [ ${_update_} -eq 1 ]; then
    insert_header_footer foot "Successfully updated home areas and profiles" ${LOGFILE}
else
    insert_header_footer foot "Successfully completed core install stage - ${NEXT_STAGE}" ${LOGFILE}
fi

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: update_timezone_info ###
#
# Updates TIMEZONE information
#
# Arguments:
#   none
# Return Values:
#   none
update_timezone_info()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling update_timezone_info stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s update_timezone_info ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - update_timezone_info"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: user_confirm ###
#
#   Take user confirmation
#
# Arguments:
#   $1 : User display message
# Return Values:
#   User response : YES/NO
user_confirm()
{
_usr_msg_="\n\nDo you want to proceed? (Yy/Nn)"
unset _response_

while [ 1 ]
do
    $ECHO ${_usr_msg_}
    read ans

    case $ans in
      Y|y|YES|Yes|yes) _response_="YES"
                       break
                       ;;
      N|n|NO|No|no) _response_="NO"
                    break
                    ;;
      *) $ECHO "Invalid input. Enter again."
         ;;
    esac
done

}

### Function: usage_msg ###
#
#   Print out the usage message
#
# Arguments:
#   none
# Return Values:
#   none
usage_msg()
{
clear
$ECHO "
Usage: 

`$BASENAME $0` -a <migration action> 

Optional: [-C] [ -l <path_to_logfile> ] 

-a  : Mandatory parameter specifying either of the migration action types:
      migration    : To migrate the system.
      post_migration: To configure the system after migration
      prerecovery  : To prepare the system for recovery.
      cleanup      : To clear leftovers of migration [Commit step]

-C  : (If invoked from console) Mandatory parameter specifying that 
      the script has been invoked from console. 

-l  : Optional parameter specifying the full path to logfile. If not specified, 
      a logfile will be created in /eniq/local_logs/migration

"
}

### Function: validate_SMF_contracts ###
#
# Validate the SMF scripts and
#
# Arguments:
#   none
# Return Values:
#   none
validate_SMF_contracts()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

#Calling validate_SMF_contracts stage from eniq_core_install.bsh
$BASH ${ENIQ_CORE_INST_SCRIPT} -s validate_SMF_contracts ${ENIQ_CORE_INST_ARG}
if [ $? -ne 0 ]; then
    _err_msg_="Failed in ${ACTION_TYPE} stage - validate_SMF_contracts"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}

set_next_stage `$EXPR ${ARRAY_ELEM}+1`
}

### Function: cleanup_migration ###
#
#   Cleanup Migration flags
#
# Arguments:
#   none
# Return Values:
#   none
cleanup_migration()
{
insert_header_footer head "Entering Linux ${ACTION_TYPE} stage - ${NEXT_STAGE}" ${LOGFILE}

log_msg -s "Cleaning up temporary directory used for migration." -l ${LOGFILE}
$RM -rf ${TEM_DIR} >> /dev/null 2>&1

insert_header_footer foot "Successfully completed - ${NEXT_STAGE}" ${LOGFILE}
}

### Function: clear_data ###
#
#   Clear migration/recovery backup 
#   Files/Directories and Flags from server
#
# Arguments:
#   none
# Return Values:
#   none
clear_data()
{
log_msg -s "\nChecking for unnecessary files/directories to be cleaned up.\n" -l ${LOGFILE}

_flag_list_=`$LS -1 ${VAR_DIR}/tmp/linux_migration_success 2>/dev/null`
if [ "${ACTION_TYPE}" != "cleanup" ]; then
    _flag_list_="${_flag_list_} `$LS -1 ${VAR_DIR}/tmp/linux_migration_in_progress 2>/dev/null`"
fi

# Remove flag files
if [ "${_flag_list_}" ]; then
    log_msg -s "\nRemoving flags used for migration." -l ${LOGFILE}
    for _flag_ in ${_flag_list_}; do
        $RM -rf ${_flag_} >> /dev/null 2>&1
        if [ ! -f "${_flag_}" ]; then
             log_msg -s "Successfully removed ${_flag_} file." -l ${LOGFILE}
        fi
    done
fi

# Directories to be removed
_remove_list_="${CONFIG_BACKUP_DIR} ${MIG_SW_BACKUP_DIR}"
for _dirname_ in ${_remove_list_}; do
    if [ -d ${_dirname_} ]; then
        if [ "${ACTION_TYPE}" == "cleanup" ]; then
            log_msg -s "\nRemoving directory ${_dirname_} used for migration." -l ${LOGFILE}
            $RM -rf ${_dirname_} >> /dev/null 2>&1
            if [ ! -d "${_dirname_}" ]; then
                log_msg -s "Successfully removed ${_dirname_} directory." -l ${LOGFILE}
            fi
        fi
    fi
done

# Cleaning up configuration file
if [ -f ${MIGRATION_CONF} ]; then
    log_msg -s "\nRemoving migration config file used for migration." -l ${LOGFILE}
    $RM -rf ${MIGRATION_CONF} >> /dev/null 2>&1
    if [ ! -f "${MIGRATION_CONF}" ]; then
        log_msg -s "Successfully removed ${MIGRATION_CONF} file." -l ${LOGFILE}
    fi
fi

# Remove ipmp.ini backup file
if [ -f "${ENIQ_CONF_DIR}/${IPMP_INI}.recovery" ];then
    log_msg -s "\nRemoving ${ENIQ_CONF_DIR}/${IPMP_INI}.recovery used for migration." -l ${LOGFILE}
    $RM -rf ${ENIQ_CONF_DIR}/${IPMP_INI}.recovery >> /dev/null 2>&1
    if [ ! -f "${ENIQ_CONF_DIR}/${IPMP_INI}.recovery" ]; then
        log_msg -s "Successfully removed ${ENIQ_CONF_DIR}/${IPMP_INI}.recovery file." -l ${LOGFILE}
    else
        log_msg -s "Remove ${ENIQ_CONF_DIR}/${IPMP_INI}.recovery file manually." -l ${LOGFILE}
    fi
fi

# Remove portbackup directory
if [ -d "${ENIQ_PORTBACKUP}" ];then
    log_msg -s "\nRemoving "${ENIQ_PORTBACKUP}" directory." -l ${LOGFILE}
    ${UMOUNT} -l ${ENIQ_PORTBACKUP} >> /dev/null 2>&1
    $RM -rf "${ENIQ_PORTBACKUP}" >> /dev/null 2>&1
    if [ -d "${ENIQ_PORTBACKUP}" ];then 
        _err_msg_="Failed to remove ${ENIQ_PORTBACKUP} file." -l ${LOGFILE}
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    else
        log_msg -s "Successfully removed "${ENIQ_PORTBACKUP}" "-l ${LOGFILE}
    fi
fi
#cleanup Old Prechecks
log_msg -t -s "Cleaning up old prechecks"
cleanup_old_prechecks

}

# ********************************************************************
#
#   Main body of program
#
# ********************************************************************

RUN_TIME=`$DATE '+%Y-%b-%d_%H:%M:%S'`

# Check that the effective id of the user is root
check_id ${DEFAULT_USER}


while getopts ":a:b:d:Il:NBnCo:s:R" arg; do
  case $arg in
    a) ACTION_TYPE="$OPTARG"
       ;;
    b) ENIQ_BASE_DIR="$OPTARG"
       ;;
    d) BASE_SW_DIR="$OPTARG"
       ;;
    I) INITIATE="YES"
       ;;
    l) LOGFILE="$OPTARG"
       ;;
    N) NO_CONFIRM="YES"
       ;;
    n) NO_RESET_STAGE="YES"
       ;;
    o) OM_SW_DIR="$OPTARG"
       ;;
    C) CONTINUE="YES"
       ;;
    R) REPLACEMENT="YES"
       ;;
    s) USER_STAGE="$OPTARG"
       ;;
    B) BACKUP="YES"
       ;;
   \?) _err_msg_="`$BASENAME $0` -s <stage>"
       abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
       ;;
  esac
done
shift `expr $OPTIND - 1`

# Check Input Params
check_params

# Check hardware
if [ -f /eniq/installation/config/san_details ];then
    STORAGE_TYPE=`$CAT /eniq/installation/config/san_details | $GREP STORAGE_TYPE | $CUT -f 2 -d =`
    if [ "${STORAGE_TYPE}" != "raw" -a "${STORAGE_TYPE}" != "fs" ];then
        _err_msg_="\nHardware type is not supported for Linux Migration."
        abort_script "${_err_msg_}"
    fi
else
    _err_msg_="Could not find the file to get hardware type."
    abort_script "${_err_msg_}"
fi

# Determine absolute path to software
check_absolute_path

# Set up environment variables for script.
setup_env

# Get BASE SW and OM SW directory
if [ "${ACTION_TYPE}" != "cleanup" -a "${ACTION_TYPE}" != "prerecovery" -a "${ACTION_TYPE}" != "post_migration" ];then
     if [ "${STORAGE_TYPE}" = raw ]; then
         if [ ! ${BASE_SW_DIR} -o ! ${OM_SW_DIR} ];then
            BASE_SW_DIR=`read_value ${_base_sw_param_} ${MIGRATION_CONF}` || abort_script "${BASE_SW_DIR}"
            OM_SW_DIR=`read_value ${_om_sw_param_} ${MIGRATION_CONF}` || abort_script "${OM_SW_DIR}"
         fi 
     fi
fi

# Log file
if [ ! "${LOGFILE}" ]; then
    if [ "${ACTION_TYPE}" == "prerecovery" ]; then
        if [ ! -d ${MIGRATION_LOGDIR} ]; then
            $MKDIR -p ${MIGRATION_LOGDIR}
        fi
        CURR_ACTION_LOGFILE="${MIGRATION_LOGDIR}/eniq_linux_${ACTION_TYPE}.log"
        LOGFILE="${CURR_ACTION_LOGFILE}_`$DATE '+%Y-%b-%d'`.log"
    else
        $MKDIR -p ${ENIQ_LOG_DIR}/migration
        LOGFILE="${ENIQ_LOG_DIR}/migration/eniq_linux_${ACTION_TYPE}_`$DATE '+%Y-%b-%d'`.log"
    fi
fi

$TOUCH $LOGFILE
if [ ! -f $LOGFILE ]; then
     _err_msg_="Failed to create $LOGFILE"
     abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi 

$CHMOD 777 $LOGFILE
if [ $? -ne 0 ]; then
     _err_msg_="Could not change the permission of $LOGFILE"
     abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

#ENIQ Core install arguments
ENIQ_CORE_INST_ARG="-n -M -l ${LOGFILE}"

# Create a temporary Directory
TEM_DIR=/tmp/linux_migration.$$.$$
$RM -rf ${TEM_DIR}
$MKDIR -p ${TEM_DIR}
if [ $? -ne 0 ]; then
    _err_msg_="Could not create directory ${TEM_DIR}"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

$CHMOD 777 ${TEM_DIR}
if [ $? -ne 0 ]; then
     _err_msg_="Could not change the permission of ${TEM_DIR}"
     abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

if [[ ${BACKUP} ]] && [[ ${USER_STAGE} == "get_migration_data" ]];then
    if [ -f "${MIGRATION_CONF}" ];then
        $MV "${MIGRATION_CONF}" "${MIGRATION_CONF}"_bkp
    fi
fi

# Call function if cleanup is called
if [ "${ACTION_TYPE}" == "cleanup" ]; then
    # Check if any activity is ongoing
    _flag_list_=`$LS -1 ${VAR_DIR}/tmp/linux_migration_in_progress 2>/dev/null`
    if [ "${_flag_list_}" ]; then
        _err_msg_="Migration Activity is in progress. Can not run \"cleanup\" now."
        log_msg -s "Progress files detected: " -l ${LOGFILE}
        for _flag_ in ${_flag_list_}; do
            log_msg -s "`basename ${_flag_}`" -l ${LOGFILE}
        done
        abort_script "${_err_msg_}"
    fi

    log_msg -h -l ${LOGFILE} -s "Starting ${ACTION_TYPE} activity."

    clear_data

    log_msg -h -l ${LOGFILE} -t -s "Successfully completed ${ACTIVITY}."
    $RM -rf ${TEM_DIR}
    $RM -rf ${conn_str_dba_enc}
    $RM -rf ${conn_str_db_enc}
    $RM -rf ${conn_str_db_stop_ping_enc}
    $RM -rf ${conn_str_db_ping_enc}
                                
    exit 0
fi

# Call function if prerecovery is called
if [ "${ACTION_TYPE}" == "prerecovery" ]; then

    run_prerecovery

    log_msg -h -l ${LOGFILE} -t -s "Successfully completed ${ACTIVITY} on ${HNAME}"
    $RM -rf ${conn_str_dba_enc}
    $RM -rf ${conn_str_db_enc}
    $RM -rf ${conn_str_db_stop_ping_enc}
    $RM -rf ${conn_str_db_ping_enc}                        
    exit 0
fi

# Call function if post_migration is called
if [ "${ACTION_TYPE}" == "post_migration" ]; then

    # To get windows server IPs during post_migration on CO server
    if [ "${CURR_SERVER_TYPE}" == "stats_coordinator" -o "${CURR_SERVER_TYPE}" == "eniq_stats" ]; then
        common_get_windows_server_info ${LOGFILE}
    fi

     # Get the System User/Group. All directories are owned by this
     SYSUSER=`iniget ENIQ_INSTALL_CONFIG -f ${ENIQ_CONF_DIR}/${SUNOS_INI} -v ENIQ_SYSUSER`
     if [ ! "${SYSUSER}" ]; then
         _err_msg_="Could not read SYSUSER param from ${ENIQ_CONF_DIR}/${SUNOS_INI}"
         abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
     fi

     change_engine_scheduler_profile "hold" "NoLoads"

     log_msg -h -l ${LOGFILE} -t -s "Starting to execute $BASH ${ENIQ_ADMIN_BIN_DIR}/encrypt_user_passwords.bsh"

     $BASH ${ENIQ_ADMIN_BIN_DIR}/encrypt_user_passwords.bsh
     if [ $? -ne 0 ]; then
         _err_msg_="Failed to execute ${ENIQ_ADMIN_BIN_DIR}/encrypt_user_passwords.bsh"
         abort_script "$_err_msg_" "${EXEC_SHELL_CMD}"
     fi

     regenerateslots
     
     # Enable OSS mounts
     log_msg -t -s "Enabling OSS mounts" -l ${LOGFILE}
     enable_oss_mounts
    
     change_engine_scheduler_profile "activate" "Normal"
     
     log_msg -h -l ${LOGFILE} -t -s "Successfully completed ${ACTIVITY} on ${HNAME}"
    $RM -rf ${conn_str_dba_enc}
     $RM -rf ${conn_str_db_enc}
     $RM -rf ${conn_str_db_stop_ping_enc}
     $RM -rf ${conn_str_db_ping_enc}                         
     exit 0
fi

# Check if migration action has been re-initialised
if [ "${INITIATE}" ]; then
    log_msg -h -l ${LOGFILE} -s "Starting over ${ACTION_TYPE} activity."
    $RM -rf ${MIGR_PROGRESS} ${MIGR_SUCCESS}
    start_eniq_services
fi

# Show system info in ACTIVITY and ask confirmation for the first time
if [ ! -f "${MIGR_PROGRESS}" -a ! -f "${MIGR_SUCCESS}" ];then
    log_msg -h -l ${LOGFILE} -s "Starting ${ACTION_TYPE} activity."
    $RM -rf ${STAGEFILE}

    # Creating progress flag file
    $TOUCH ${MIGR_PROGRESS}
    if [ ! -f "${RACK_MIGRATION_IN_PROG}" ]; then
        show_server_info
    fi
    if [ ! "${NO_CONFIRM}" ];then
        $ECHO "\nINFO: You are about to start ${ACTIVITY}."
        user_confirm
        if [ "${_response_}" != "YES" ];then
            $RM -rf ${TEM_DIR} >> /dev/null 2>&1
            $RM -rf ${MIGR_PROGRESS} >> /dev/null 2>&1
            log_msg -s "\nExiting from script as user selected NOT to proceed." -l ${LOGFILE}
            $RM -rf ${conn_str_dba_enc}
            $RM -rf ${conn_str_db_enc}
            $RM -rf ${conn_str_db_stop_ping_enc}
            $RM -rf ${conn_str_db_ping_enc}                  
            exit 0
        fi
    fi
fi

log_msg -h -l ${LOGFILE} -t -s "Entering $ACTIVITY."

# Create a stage array
core_install_build_stage_array ${LOGFILE} ${TEM_DIR} eniq_linux ${ACTION_TYPE} ${MIGRATION_CORE}
if [ $? -ne 0 ]; then
    _err_msg_="Could not build a stage array for ${ACTION_TYPE}"
    abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
fi

# If stage specified, make sure it is in the stage list for this server type
if [ "$USER_STAGE" ]; then
    core_install_check_user_stage ${LOGFILE} ${TEM_DIR} ${USER_STAGE}
    if [ $? -ne 0 ]; then
       _err_msg_="The specified stage ${USER_STAGE} is not in the stage list for ${ACTION_TYPE}"
       abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi
fi

if [ "$USER_STAGE" ]; then
    NEXT_STAGE="${USER_STAGE}"
    # Get the element number so we can move along the array
    get_array_element
else
    get_next_stage
fi


# If we read last stage from the stagefile
if [ "$NEXT_STAGE" == "${STOP_STAGE}" ]; then
    # We exit unless the user specified that the stage be run again
    if [ ! "$USER_STAGE" ]; then
        _completion_date_=""
        _completion_date_=`$LS -l ${VAR_DIR}/tmp/linux_${ACTION_TYPE}_success | \
                           $AWK '{print " on " $6, $7, "at " $8}' 2> /dev/null`
        log_msg -s "\nAll Stages of ${ACTION_TYPE} are already completed${_completion_date_}." -l ${LOGFILE}
        $RM -rf ${conn_str_dba_enc}
        $RM -rf ${conn_str_db_enc}
        $RM -rf ${conn_str_db_stop_ping_enc}
        $RM -rf ${conn_str_db_ping_enc}                     
        exit 0
    fi
fi

# Check if stop stage is defined
if [ -s ${ENIQ_CONF_DIR}/extra_params/stop_stage ]; then
    _stop_stage_=`$CAT ${ENIQ_CONF_DIR}/extra_params/stop_stage`
    $ECHO ${ENIQ_CORE_STAGES[*]} | $GREP -w ${_stop_stage_} >> /dev/null 2>&1
    if [ $? -eq 0 ]; then
        log_msg -s "Linux Migration Procedure will stop at stage ${_stop_stage_}" -l ${LOGFILE}
    else
        log_msg -s "User defined stop stage - ${_stop_stage_} not valid.....Ignoring" -l ${LOGFILE}
        unset _stop_stage_
        $RM -f ${ENIQ_CONF_DIR}/extra_params/stop_stage
    fi
fi


# Loop through the stages from stage list 
while :; do
    _nxt_stage_="${NEXT_STAGE}"
    $_nxt_stage_
    if [ $? -ne 0 ]; then
        _err_msg_="Error in Stage ${NEXT_STAGE}"
        abort_script "${_err_msg_}" "${EXEC_SHELL_CMD}"
    fi

    # Exit if the user specified to run a specific stage only
    if [ "$USER_STAGE" ]; then
        break
    fi

    # If we read ${STOP_STAGE} from the stagefile
    if [ "$NEXT_STAGE" == "${STOP_STAGE}" ]; then
        break
    fi

    get_next_stage
done

if [ ! -f "${RACK_MIGRATION_IN_PROG}" ]; then
    log_msg -h -l ${LOGFILE} -t -s "Successfully completed $ACTIVITY. Logfile: ${LOGFILE}" 
fi

$RM -rf ${TEM_DIR}
$RM -rf ${conn_str_dba_enc}
$RM -rf ${conn_str_db_enc}
$RM -rf ${conn_str_db_stop_ping_enc}
$RM -rf ${conn_str_db_ping_enc}
exit 0
